Torch device: cuda
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth
Number of weights: 1946888
Number of trainable weights: 1946888
! Starting training ...
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      0   100          141         50.9      0.00435         89.9         43.5         78.8        0.537        0.729         99.5          105
      0   182          116         25.2       0.0065         90.4         33.6         55.5        0.691         0.89          105          105


  Initialization     #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Initial Validation          0    7.940    0.001         30.1      0.00618         92.2          122         33.4         60.6        0.631        0.869          103          106
Wall time: 7.940435349941254
! Best model        0  122.260
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      1   100         0.51        0.478      0.00158       0.0302         5.24         7.64        0.321        0.439         1.84         1.92
      1   200         0.14        0.135       0.0025       0.0027         2.91         4.06        0.408        0.553         0.39        0.574
      1   300       0.0842        0.081      0.00133      0.00194          2.1         3.14        0.301        0.402        0.391        0.487
      1   400        0.105          0.1      0.00161      0.00331         2.29         3.49        0.328        0.443        0.524        0.636
      1   500       0.0823       0.0459      0.00124       0.0352         1.95         2.37        0.307         0.39          1.9         2.07
      1   600        0.292       0.0883      0.00129        0.202         2.47         3.28        0.287        0.397         4.92         4.97
      1   700       0.0676       0.0555      0.00078       0.0113         1.73          2.6        0.227        0.309         1.13         1.17
      1   800        0.195        0.117      0.00101       0.0766         2.39         3.78        0.263        0.351         3.03         3.06
      1   900        0.105       0.0517     0.000901       0.0524         1.74         2.51        0.248        0.332         2.51         2.53
      1  1000         0.78         0.61     0.000419        0.169         5.36         8.63        0.167        0.226         4.39         4.55
      1  1100        0.143       0.0942     0.000677       0.0483         2.47         3.39         0.22        0.288         2.31         2.43
      1  1200        0.282        0.195     0.000871       0.0861         3.06         4.88        0.256        0.326          3.2         3.24
      1  1300         1.24         1.16      0.00091       0.0829         7.44         11.9         0.25        0.333         2.89         3.18
      1  1400       0.0308       0.0281     0.000566      0.00208         1.23         1.85        0.196        0.263        0.408        0.504
      1  1500        0.476         0.45      0.00078       0.0258         3.41         7.41         0.22        0.309         1.61         1.77
      1  1600        0.249         0.24     0.000477       0.0091         3.62         5.41        0.175        0.241        0.897         1.05
      1  1700        0.118        0.113     0.000385      0.00433         2.16         3.72        0.164        0.217        0.724        0.727
      1  1800         8.89         6.94     0.000572         1.95         16.8         29.1        0.188        0.264         15.3         15.4
      1  1900        0.106        0.104     0.000214      0.00192         1.94         3.56        0.115        0.162        0.471        0.485
      1  2000        0.403        0.351     0.000687       0.0518         3.68         6.54        0.222         0.29         1.95         2.51
      1  2039        0.287        0.286     0.000346      0.00108         2.86         5.91        0.154        0.205        0.303        0.364

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      1   100       0.0416       0.0296     0.000351       0.0117         1.27          1.9        0.157        0.207         1.06         1.19
      1   182        0.107        0.103     0.000261      0.00342         2.23         3.55        0.138        0.178        0.646        0.646


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train               1  110.833    0.001         1.69      0.00114        0.704          2.4         4.18         14.4        0.259        0.373          3.8         9.27
! Validation          1  110.833    0.001        0.055      0.00041       0.0169       0.0724         1.48         2.59        0.166        0.224         1.15         1.44
Wall time: 110.83412753045559
! Best model        1    0.072
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      2   100        0.289       0.0275     0.000248        0.261         1.27         1.83        0.125        0.174          5.6         5.65
      2   200        0.261        0.161     0.000293       0.0996         2.62         4.43        0.143        0.189          3.2         3.49
      2   300         6.22         3.88      0.00022         2.33         12.8         21.8         0.12        0.164         16.8         16.9
      2   400        0.231       0.0239     0.000372        0.207         1.08         1.71        0.161        0.213         4.97         5.03
      2   500         1.36         1.35     0.000322      0.00659         7.78         12.8        0.146        0.198        0.802        0.897
      2   600         0.55        0.523     0.000521       0.0268          4.3         7.99        0.195        0.252          1.8         1.81
      2   700        0.166       0.0386     0.000214        0.127         1.47         2.17        0.117        0.162         3.87         3.94
      2   800       0.0349       0.0137      0.00029        0.021        0.937         1.29        0.147        0.188         1.52          1.6
      2   900        0.242       0.0143     0.000272        0.228        0.876         1.32        0.135        0.182         5.17         5.27
      2  1000        0.148        0.142     0.000336      0.00488         2.72         4.17        0.151        0.202        0.584        0.772
      2  1100        0.574        0.509     0.000333       0.0645         4.67         7.89        0.152        0.202         2.61         2.81
      2  1200        0.318        0.209     0.000463        0.108         3.02         5.06         0.18        0.238         3.14         3.63
      2  1300        0.294        0.244     0.000269       0.0503         3.28         5.45        0.138        0.181          2.2         2.48
      2  1400        0.305       0.0954     0.000347        0.209         1.81         3.41        0.155        0.206         5.01         5.05
      2  1500        0.156        0.151     0.000447      0.00459         2.14          4.3        0.183        0.234        0.634        0.748
      2  1600        0.444          0.3      0.00032        0.144          3.5         6.05        0.147        0.198         4.18          4.2
      2  1700       0.0753       0.0432     0.000304       0.0318         1.51          2.3        0.145        0.193          1.9         1.97
      2  1800        0.251         0.18     0.000216       0.0709         2.62         4.69        0.119        0.163         2.69         2.94
      2  1900       0.0748       0.0411     0.000304       0.0333          1.4         2.24        0.145        0.193            2         2.02
      2  2000         1.12        0.996     0.000322        0.122         6.72           11        0.141        0.198         3.79         3.85
      2  2039         0.06       0.0446      0.00018       0.0152         1.31         2.33        0.109        0.148            1         1.36

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      2   100       0.0375       0.0254      0.00019       0.0119         1.04         1.76        0.106        0.152         1.11         1.21
      2   182        0.271        0.269      0.00022      0.00229         3.47         5.73        0.128        0.164        0.529        0.529


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train               2  210.554    0.001        0.296     0.000337        0.115        0.411         2.98         6.01        0.149        0.203         2.83         3.74
! Validation          2  210.554    0.001       0.0556     0.000229       0.0122        0.068         1.41         2.58        0.121        0.167         1.08         1.22
Wall time: 210.5558309480548
! Best model        2    0.068
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      3   100        0.325        0.197     0.000415        0.128         2.35         4.91        0.141        0.225          3.7         3.95
      3   200         0.08       0.0746     0.000203      0.00522         1.92         3.02        0.117        0.157        0.603        0.798
      3   300        0.211        0.208     0.000235      0.00282         2.95         5.04        0.112        0.169        0.525        0.587
      3   400        0.422         0.28     0.000235        0.142         3.69         5.84        0.124        0.169         4.08         4.16
      3   500        0.123        0.101       0.0002       0.0219         2.01          3.5        0.115        0.156         1.53         1.64
      3   600        0.128       0.0324     0.000208       0.0951         1.36         1.99        0.117        0.159         3.33         3.41
      3   700        0.116       0.0343     0.000192       0.0818         1.31         2.05        0.116        0.153         2.77         3.16
      3   800        0.341        0.185     0.000198        0.156         2.79         4.75        0.113        0.155            4         4.37
      3   900        0.275        0.203     0.000229        0.071         2.91         4.98        0.122        0.167          2.9         2.94
      3  1000       0.0516       0.0453     0.000149      0.00614         1.58         2.35          0.1        0.135        0.828        0.866
      3  1100       0.0875       0.0447     0.000225       0.0426         1.47         2.34        0.126        0.166         2.24         2.28
      3  1200        0.348        0.302     0.000199       0.0455         3.39         6.08         0.12        0.156         2.33         2.36
      3  1300        0.316       0.0316     0.000535        0.284         1.25         1.96        0.192        0.255         4.87         5.89
      3  1400       0.0427       0.0133     0.000201       0.0292        0.913         1.27        0.117        0.157          1.6         1.89
      3  1500        0.141        0.129      0.00029       0.0117         2.61         3.96        0.144        0.188        0.965          1.2
      3  1600        0.454        0.449     0.000218      0.00384         4.42         7.41        0.114        0.163        0.522        0.684
      3  1700       0.0731       0.0712     0.000267      0.00165         1.82         2.95        0.136         0.18        0.421        0.449
      3  1800        0.164        0.133     0.000231        0.031         2.57         4.03        0.126        0.168          1.8         1.95
      3  1900        0.087       0.0266     0.000417       0.0599         1.34          1.8        0.169        0.226         2.17          2.7
      3  2000        0.057       0.0411     0.000187       0.0156         1.47         2.24        0.113        0.151         1.25         1.38
      3  2039       0.0312       0.0167     0.000135       0.0144        0.802         1.43       0.0952        0.128         1.32         1.33

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      3   100       0.0462       0.0284     0.000172       0.0177          1.3         1.86        0.109        0.145         1.39         1.47
      3   182         0.32        0.297     0.000202       0.0221         3.68         6.03        0.125        0.157         1.64         1.64


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train               3  310.174    0.001        0.136     0.000236       0.0622        0.199         2.15         4.08        0.124         0.17         2.15         2.76
! Validation          3  310.174    0.001       0.0532     0.000215        0.021       0.0745         1.38         2.52        0.122        0.162         1.52          1.6
Wall time: 310.1749009862542
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      4   100       0.0732       0.0685     0.000224      0.00445          1.7         2.89        0.124        0.165        0.639        0.737
      4   200         0.38       0.0411     0.000239        0.338         1.53         2.24        0.132        0.171         6.14         6.43
      4   300       0.0296       0.0123     0.000399       0.0169        0.862         1.23         0.16        0.221         1.42         1.43
      4   400         0.13        0.122      0.00026        0.007         2.04         3.87        0.131        0.178        0.895        0.924
      4   500        0.164        0.154     0.000476      0.00995         2.52         4.33        0.183        0.241        0.925          1.1
      4   600       0.0958       0.0834     0.000327       0.0121         2.01         3.19        0.149          0.2         1.11         1.21
      4   700       0.0138       0.0118     0.000142      0.00189        0.737          1.2       0.0956        0.131        0.349         0.48
      4   800       0.0566       0.0335     0.000187        0.023         1.38         2.02        0.108        0.151         1.59         1.67
      4   900        0.206         0.18     0.000245       0.0255         2.84         4.69        0.131        0.173         1.66         1.76
      4  1000        0.118       0.0731     0.000252       0.0444         1.78         2.99        0.129        0.175            2         2.33
      4  1100        0.119       0.0973     0.000241       0.0218         2.05         3.45        0.127        0.172         1.57         1.63
      4  1200       0.0624       0.0461       0.0003        0.016         1.51         2.37        0.148        0.191         1.27          1.4
      4  1300        0.216       0.0356     0.000599         0.18         1.35         2.09        0.202         0.27         4.44         4.69
      4  1400        0.228        0.225     0.000192      0.00335         3.16         5.24        0.107        0.153        0.526        0.639
      4  1500        0.693       0.0572     0.000446        0.635         1.64         2.64        0.169        0.233         8.78          8.8
      4  1600        0.284        0.175     0.000294        0.109         2.56         4.63        0.142         0.19         3.53         3.65
      4  1700       0.0516        0.049     0.000276      0.00233         1.39         2.44        0.132        0.183        0.505        0.533
      4  1800        0.184        0.152     0.000303       0.0317         2.59         4.31         0.14        0.192         1.87         1.97
      4  1900        0.086       0.0408     0.000117       0.0451         1.33         2.23       0.0887         0.12         2.31         2.35
      4  2000       0.0292       0.0179       0.0002       0.0111        0.873         1.48        0.117        0.156        0.983         1.16
      4  2039        0.139        0.131     0.000136       0.0083          2.5            4       0.0905        0.129        0.769         1.01

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      4   100        0.146       0.0718     0.000135       0.0736         1.75         2.96       0.0932        0.128         2.59            3
      4   182        0.507        0.415     0.000158       0.0915         4.25         7.12         0.11        0.139         3.34         3.34


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train               4  409.563    0.001        0.112      0.00028       0.0585        0.171         1.93          3.7        0.134        0.185            2         2.67
! Validation          4  409.563    0.001       0.0753     0.000178       0.0505        0.126         1.76            3        0.108        0.147         2.29         2.48
Wall time: 409.5643063336611
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      5   100        0.157        0.143     0.000379       0.0133         2.38         4.18        0.155        0.215         1.07         1.27
      5   200       0.0927       0.0848     0.000215      0.00762         1.85         3.22        0.124        0.162        0.953        0.964
      5   300        0.111        0.103     0.000145      0.00801         2.23         3.55       0.0985        0.133        0.717        0.989
      5   400       0.0624       0.0507     0.000357       0.0114          1.5         2.49        0.149        0.209         1.12         1.18
      5   500       0.0211      0.00326     0.000204       0.0176        0.519        0.631        0.119        0.158         1.38         1.47
      5   600       0.0391        0.019     0.000321       0.0197         1.06         1.52         0.14        0.198         1.12         1.55
      5   700       0.0304        0.021     0.000256      0.00912        0.801          1.6        0.133        0.177        0.727         1.06
      5   800        0.125       0.0976     0.000273       0.0272         1.88         3.45        0.137        0.183         1.44         1.82
      5   900       0.0313       0.0256      0.00015      0.00552         1.11         1.77        0.101        0.135        0.686        0.821
      5  1000       0.0593       0.0581     0.000203     0.000989         1.64         2.66        0.115        0.158        0.337        0.347
      5  1100        0.247       0.0962     0.000381         0.15         2.21         3.43        0.167        0.216         3.99         4.28
      5  1200       0.0764       0.0377     0.000165       0.0385         1.22         2.15        0.105        0.142         1.89         2.17
      5  1300       0.0254       0.0144     0.000185       0.0108        0.962         1.33        0.112         0.15         1.09         1.15
      5  1400       0.0297       0.0244     7.82e-05       0.0052         1.09         1.73       0.0749       0.0977         0.62        0.797
      5  1500       0.0954       0.0289     0.000345       0.0662         1.22         1.88        0.146        0.205         2.63         2.84
      5  1600         0.18        0.167     0.000167        0.013         2.15         4.52        0.105        0.143        0.988         1.26
      5  1700        0.178        0.106     0.000166       0.0715          2.1          3.6        0.106        0.142         2.92         2.95
      5  1800       0.0553       0.0344     0.000165       0.0208         1.33         2.05       0.0991        0.142         1.39         1.59
      5  1900       0.0831       0.0592     0.000253       0.0237         1.76         2.69        0.115        0.176         1.69          1.7
      5  2000        0.019      0.00462     0.000153       0.0142        0.503        0.751          0.1        0.137         1.25         1.32
      5  2039       0.0175       0.0117     0.000146       0.0057        0.863         1.19       0.0999        0.134        0.823        0.834

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      5   100        0.108       0.0888     0.000144       0.0195         2.07         3.29       0.0968        0.132         1.38         1.54
      5   182       0.0709       0.0706     8.19e-05     0.000139         1.81         2.94       0.0767          0.1         0.13         0.13


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train               5  508.986    0.001       0.0654     0.000187       0.0273       0.0928         1.54         2.83         0.11        0.151         1.42         1.83
! Validation          5  508.986    0.001       0.0974     0.000173       0.0177        0.115         1.92         3.45        0.107        0.145         1.27         1.47
Wall time: 508.98711370676756
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      6   100       0.0665       0.0394     0.000135        0.027         1.37         2.19       0.0925        0.128         1.58         1.82
      6   200        0.137        0.102     9.89e-05       0.0343         2.25         3.54       0.0839         0.11         1.71         2.05
      6   300        0.231        0.173     0.000152       0.0577         2.85          4.6        0.103        0.136         2.08         2.65
      6   400        0.044       0.0378     0.000138      0.00605         1.39         2.15          0.1         0.13        0.648         0.86
      6   500       0.0362       0.0226     0.000107       0.0135        0.963         1.66       0.0803        0.114         1.12         1.28
      6   600       0.0597       0.0406     0.000108        0.019         1.34         2.23        0.087        0.115         1.24         1.52
      6   700       0.0204       0.0152     0.000224      0.00498         1.06         1.36        0.127        0.165        0.647        0.779
      6   800       0.0475       0.0135     8.35e-05       0.0339        0.891         1.28       0.0757        0.101         1.91         2.03
      6   900       0.0515       0.0203       0.0001       0.0311         1.03         1.57       0.0828        0.111         1.85         1.95
      6  1000       0.0448       0.0324     0.000196       0.0122         1.24         1.99        0.121        0.155         1.19         1.22
      6  1100       0.0533       0.0297     0.000261       0.0233         1.29         1.91        0.133        0.178          1.6         1.69
      6  1200        0.035      0.00875     0.000159       0.0261        0.785         1.03        0.106        0.139         1.75         1.78
      6  1300       0.0512       0.0369      0.00013       0.0143         1.33         2.12       0.0979        0.126         1.31         1.32
      6  1400        0.137        0.131     0.000287       0.0061         2.28            4        0.137        0.187        0.764        0.863
      6  1500        0.145        0.141      0.00014      0.00351         1.84         4.15       0.0936        0.131        0.619        0.655
      6  1600       0.0743       0.0617      0.00014       0.0125         1.57         2.74       0.0975        0.131        0.756         1.24
      6  1700       0.0147      0.00663     0.000159      0.00795        0.686          0.9        0.106        0.139        0.896        0.985
      6  1800        0.147         0.14     0.000138      0.00723         2.32         4.13       0.0949         0.13        0.825        0.939
      6  1900        0.116        0.107     0.000111      0.00834         1.71         3.62       0.0828        0.117        0.959         1.01
      6  2000       0.0143       0.0133     4.18e-05     0.000984        0.849         1.27       0.0512       0.0714        0.294        0.347
      6  2039       0.0256      0.00687     7.75e-05       0.0187        0.622        0.916       0.0708       0.0972         1.51         1.51

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      6   100       0.0258      0.00998     5.91e-05       0.0157        0.755          1.1       0.0648        0.085         0.96         1.39
      6   182        0.277        0.274     7.15e-05      0.00207         3.58         5.79       0.0757       0.0934        0.502        0.502


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train               6  608.453    0.001       0.0539     0.000162       0.0196       0.0737         1.38         2.57        0.102        0.141         1.17         1.55
! Validation          6  608.453    0.001       0.0353     8.71e-05       0.0106        0.046         1.12         2.05       0.0757        0.103         0.82         1.14
Wall time: 608.4537829235196
! Best model        6    0.046
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      7   100       0.0118      0.00559     7.62e-05      0.00617        0.641        0.826       0.0709       0.0965        0.718        0.868
      7   200       0.0473       0.0317     6.57e-05       0.0156         1.24         1.97       0.0644       0.0895         1.26         1.38
      7   300       0.0577       0.0502     0.000179      0.00727         1.49         2.48        0.112        0.148        0.664        0.942
      7   400       0.0182       0.0126     0.000146      0.00545        0.842         1.24        0.104        0.134        0.746        0.816
      7   500       0.0292       0.0198     0.000152      0.00928         0.88         1.55        0.106        0.136        0.746         1.06
      7   600       0.0446       0.0381     5.95e-05      0.00642         1.38         2.16       0.0573       0.0852        0.737        0.885
      7   700        0.134       0.0843     9.22e-05       0.0494         2.05         3.21       0.0796        0.106         2.24         2.46
      7   800        0.167         0.13     0.000133       0.0368         2.17         3.98       0.0933        0.127         1.91         2.12
      7   900       0.0751       0.0703     7.51e-05      0.00465         1.51         2.93       0.0651       0.0958         0.54        0.753
      7  1000       0.0172       0.0126     0.000111      0.00449        0.728         1.24       0.0892        0.116        0.631         0.74
      7  1100       0.0223       0.0186     7.59e-05      0.00369         0.95         1.51       0.0712       0.0963        0.522        0.671
      7  1200       0.0181       0.0147     0.000109      0.00323        0.938         1.34       0.0862        0.116        0.523        0.628
      7  1300       0.0465       0.0414     6.73e-05      0.00498         1.14         2.25       0.0689       0.0906         0.63         0.78
      7  1400       0.0256       0.0178     8.34e-05      0.00766         1.14         1.48       0.0778        0.101        0.751        0.967
      7  1500       0.0321       0.0216     0.000142       0.0104         1.03         1.62       0.0966        0.132         1.07         1.12
      7  1600       0.0361      0.00765     0.000119       0.0284        0.688        0.966       0.0893         0.12         1.64         1.86
      7  1700       0.0893       0.0876     9.37e-05      0.00166         1.53         3.27       0.0784        0.107        0.382         0.45
      7  1800       0.0266       0.0214     0.000126      0.00506        0.847         1.62        0.087        0.124        0.766        0.786
      7  1900       0.0533       0.0415     0.000154       0.0117          1.3         2.25        0.104        0.137        0.975         1.19
      7  2000        0.138        0.136     0.000329      0.00245         2.29         4.07        0.151          0.2        0.468        0.547
      7  2039       0.0144      0.00504     0.000105      0.00928        0.613        0.784       0.0842        0.113        0.774         1.06

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      7   100       0.0334       0.0152     7.36e-05       0.0181        0.926         1.36       0.0697       0.0948         1.27         1.49
      7   182        0.299        0.258     0.000156       0.0409         3.53         5.61        0.112        0.138         2.23         2.23


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train               7  707.950    0.001       0.0461     0.000129       0.0142       0.0604         1.25         2.37       0.0894        0.125        0.979         1.32
! Validation          7  707.950    0.001       0.0359     0.000132       0.0373       0.0733         1.11         2.06       0.0917        0.127          1.7         2.13
Wall time: 707.9518127813935
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      8   100       0.0292       0.0243     5.79e-05      0.00483         1.02         1.72       0.0601       0.0841        0.754        0.768
      8   200       0.0568        0.043     0.000104       0.0137         1.21         2.29        0.081        0.113        0.985         1.29
      8   300       0.0388       0.0284     0.000139       0.0102         1.05         1.86        0.083         0.13        0.996         1.11
      8   400       0.0233       0.0141     0.000105      0.00909        0.962         1.31       0.0816        0.113        0.865         1.05
      8   500        0.016      0.00958     0.000166      0.00628        0.848         1.08        0.108        0.142        0.712        0.875
      8   600       0.0141      0.00174     0.000123       0.0122        0.365         0.46       0.0886        0.122         1.13         1.22
      8   700       0.0337       0.0298      8.8e-05      0.00376         1.03         1.91       0.0769        0.104        0.662        0.677
      8   800       0.0866       0.0551     6.14e-05       0.0315         1.02         2.59       0.0593       0.0866         1.84         1.96
      8   900        0.021        0.011     7.55e-05      0.00998        0.745         1.16       0.0689        0.096         1.09          1.1
      8  1000        0.104       0.0769     6.65e-05       0.0266         1.65         3.06       0.0584       0.0901         1.59          1.8
      8  1100       0.0266        0.015     6.88e-05       0.0115         0.81         1.35       0.0691       0.0916         1.05         1.18
      8  1200       0.0264       0.0227     7.89e-05       0.0036        0.987         1.67       0.0706       0.0981         0.49        0.663
      8  1300       0.0757       0.0703     0.000131      0.00536         1.43         2.93        0.093        0.127        0.641        0.809
      8  1400       0.0258       0.0157     7.37e-05      0.00995        0.884         1.39       0.0643       0.0948         1.01          1.1
      8  1500       0.0426       0.0112      0.00013       0.0313        0.658         1.17       0.0969        0.126         1.67         1.95
      8  1600       0.0317       0.0213     8.29e-05       0.0103        0.857         1.61       0.0762        0.101         1.12         1.12
      8  1700       0.0178       0.0168     9.95e-05     0.000907        0.931         1.43       0.0823         0.11        0.304        0.333
      8  1800        0.031       0.0245     0.000106      0.00639        0.935         1.73       0.0859        0.114        0.763        0.883
      8  1900       0.0154       0.0147     7.09e-05      0.00066        0.813         1.34       0.0658        0.093        0.195        0.284
      8  2000       0.0156       0.0102     9.12e-05       0.0053        0.852         1.12        0.075        0.106        0.701        0.804
      8  2039      0.00687      0.00315     6.27e-05      0.00365        0.455         0.62       0.0652       0.0875        0.646        0.668

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      8   100       0.0199       0.0111     5.02e-05      0.00867        0.681         1.17       0.0565       0.0783        0.959         1.03
      8   182        0.255        0.241     6.62e-05       0.0142         3.31         5.43       0.0708       0.0899         1.32         1.32


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train               8  807.253    0.001       0.0394     0.000109      0.00774       0.0473         1.14         2.19       0.0816        0.115        0.731        0.972
! Validation          8  807.253    0.001       0.0346     8.91e-05       0.0123       0.0469         1.08         2.03        0.073        0.104         1.06         1.22
Wall time: 807.2543220221996
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      9   100       0.0369       0.0205     7.82e-05       0.0163        0.905         1.58       0.0723       0.0977         1.18         1.41
      9   200       0.0116       0.0102     0.000104      0.00135        0.685         1.11       0.0772        0.113        0.353        0.406
      9   300       0.0429         0.04      6.3e-05      0.00278         1.11         2.21       0.0639       0.0877        0.571        0.582
      9   400       0.0672        0.065     0.000113       0.0021         1.64         2.82       0.0787        0.118        0.466        0.506
      9   500      0.00843      0.00363     6.23e-05      0.00474        0.494        0.665        0.067       0.0872         0.63        0.761
      9   600       0.0159       0.0148     7.24e-05      0.00104        0.733         1.35       0.0667        0.094         0.33        0.356
      9   700       0.0073      0.00365     9.09e-05      0.00356        0.445        0.668       0.0711        0.105        0.548        0.659
      9   800       0.0144      0.00899     0.000155      0.00527        0.818         1.05        0.105        0.138        0.648        0.802
      9   900       0.0149       0.0132     9.36e-05      0.00169        0.887         1.27       0.0689        0.107        0.417        0.454
      9  1000       0.0268       0.0219     9.15e-05      0.00477         1.09         1.63        0.071        0.106        0.692        0.763
      9  1100       0.0293       0.0274      7.9e-05      0.00185         1.22         1.83       0.0657       0.0982        0.396        0.475
      9  1200      0.00869      0.00537     0.000156      0.00316        0.555         0.81       0.0952        0.138        0.484        0.621
      9  1300        0.111       0.0988     0.000114       0.0123         1.91         3.47       0.0773        0.118         1.18         1.23
      9  1400        0.121        0.111     0.000109       0.0101         1.51         3.68       0.0622        0.115        0.826         1.11
      9  1500       0.0347       0.0342     7.78e-05     0.000475         1.11         2.04        0.073       0.0974        0.208        0.241
      9  1600       0.0233       0.0218      0.00017      0.00135         1.05         1.63        0.108        0.144        0.276        0.407
      9  1700       0.0612       0.0508     8.38e-05       0.0103         1.41         2.49       0.0686        0.101        0.961         1.12
      9  1800        0.105          0.1     0.000135      0.00522         1.83          3.5       0.0892        0.129        0.729        0.798
      9  1900       0.0435       0.0376     6.62e-05      0.00583         1.02         2.14       0.0621       0.0899        0.811        0.844
      9  2000       0.0523       0.0516      0.00015     0.000537         1.29         2.51        0.102        0.135        0.221        0.256
      9  2039      0.00842      0.00712     0.000164      0.00114        0.595        0.932        0.101        0.142        0.312        0.373

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
      9   100       0.0113      0.00843     0.000144       0.0027        0.794         1.01       0.0942        0.132         0.47        0.574
      9   182         0.18        0.171     7.16e-05      0.00923         2.74         4.57       0.0671       0.0935         1.06         1.06


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train               9  906.613    0.001       0.0361     9.55e-05      0.00671       0.0429         1.07          2.1       0.0752        0.108        0.667        0.905
! Validation          9  906.613    0.001       0.0368     0.000172      0.00575       0.0427         1.09          2.1       0.0997        0.145        0.637        0.836
Wall time: 906.6144451573491
! Best model        9    0.043
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     10   100       0.0255       0.0193     0.000131      0.00607        0.933         1.53       0.0864        0.127        0.766        0.861
     10   200       0.0216        0.015     0.000106      0.00654        0.734         1.35       0.0752        0.114        0.707        0.894
     10   300       0.0538       0.0502     0.000168      0.00341         1.46         2.48       0.0997        0.143        0.557        0.645
     10   400        0.154        0.151     9.93e-05      0.00281         1.82          4.3       0.0813         0.11        0.506        0.586
     10   500       0.0861       0.0622     0.000124       0.0238         1.25         2.76        0.082        0.123         1.51          1.7
     10   600       0.0199      0.00343     7.66e-05       0.0164        0.479        0.648       0.0669       0.0967         1.37         1.41
     10   700       0.0361       0.0349     5.55e-05      0.00119         1.16         2.06       0.0568       0.0823        0.375        0.381
     10   800       0.0302       0.0161     5.74e-05        0.014        0.654          1.4       0.0598       0.0837         1.15         1.31
     10   900       0.0448       0.0395     0.000149      0.00515         1.29          2.2        0.101        0.135        0.699        0.793
     10  1000       0.0551       0.0538     0.000114      0.00122         1.22         2.56       0.0816        0.118        0.349        0.386
     10  1100       0.0681        0.063     0.000109      0.00497         1.45         2.77       0.0852        0.115        0.764        0.779
     10  1200       0.0132        0.011     5.31e-05      0.00219        0.859         1.16       0.0595       0.0805        0.478        0.517
     10  1300       0.0134      0.00819     0.000121      0.00507        0.689            1       0.0844        0.122        0.623        0.786
     10  1400       0.0241       0.0234     5.06e-05     0.000725        0.686         1.69       0.0512       0.0786        0.288        0.298
     10  1500       0.0331      0.00469     6.35e-05       0.0284        0.503        0.757       0.0631        0.088         1.34         1.86
     10  1600       0.0394       0.0357     0.000148      0.00349         1.11         2.09        0.098        0.134        0.633        0.653
     10  1700      0.00601      0.00494     4.42e-05      0.00102        0.499        0.777       0.0538       0.0734        0.317        0.352
     10  1800        0.112        0.109     4.36e-05      0.00291         1.56         3.65       0.0488       0.0729        0.419        0.596
     10  1900       0.0903       0.0874     0.000117      0.00284         1.68         3.27       0.0871        0.119        0.507        0.589
     10  2000      0.00796      0.00572      4.4e-05      0.00219        0.586        0.836        0.053       0.0733        0.443        0.517
     10  2039        0.183        0.176     0.000167      0.00618         3.01         4.64        0.108        0.143        0.774        0.868

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     10   100       0.0383       0.0262     7.73e-05        0.012        0.946         1.79       0.0688       0.0972        0.797         1.21
     10   182        0.206        0.206     4.85e-05     0.000566         3.03         5.01       0.0544       0.0769        0.263        0.263


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              10 1006.558    0.001       0.0339     8.84e-05      0.00555       0.0395         1.02         2.03       0.0714        0.104        0.615        0.823
! Validation         10 1006.558    0.001       0.0354     0.000117       0.0052       0.0407         1.05         2.06       0.0833        0.119        0.614        0.798
Wall time: 1006.559213295579
! Best model       10    0.041
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     11   100       0.0308       0.0275     0.000104      0.00321         1.03         1.83       0.0761        0.113        0.533        0.626
     11   200       0.0266       0.0233     2.57e-05      0.00332        0.727         1.69       0.0363        0.056        0.583        0.636
     11   300      0.00833      0.00714     6.34e-05      0.00113        0.613        0.934       0.0621        0.088        0.347        0.371
     11   400       0.0597       0.0578      5.8e-05      0.00182         1.41         2.66       0.0583       0.0841        0.395        0.472
     11   500       0.0209       0.0195     6.15e-05       0.0014        0.838         1.54       0.0628       0.0866        0.337        0.414
     11   600       0.0127      0.00941      5.1e-05      0.00324        0.662         1.07       0.0591       0.0789        0.604        0.629
     11   700       0.0217       0.0121     0.000172      0.00936        0.762         1.22        0.108        0.145        0.712         1.07
     11   800       0.0357       0.0307     4.26e-05      0.00496        0.943         1.94       0.0491       0.0721        0.665        0.778
     11   900       0.0307       0.0275     7.74e-05      0.00311        0.928         1.83       0.0677       0.0972        0.506        0.616
     11  1000        0.079       0.0765     7.63e-05      0.00245         1.38         3.06       0.0635       0.0965        0.416        0.547
     11  1100       0.0419       0.0415     7.73e-05     0.000293          1.1         2.25       0.0664       0.0972        0.154        0.189
     11  1200      0.00623      0.00472     7.51e-05      0.00143        0.504        0.759        0.069       0.0958        0.339        0.418
     11  1300       0.0218       0.0207     3.47e-05      0.00105        0.754         1.59       0.0494       0.0651        0.326        0.357
     11  1400       0.0266       0.0243     8.31e-05       0.0022        0.901         1.72       0.0688        0.101        0.381        0.518
     11  1500      0.00446      0.00301      5.1e-05       0.0014        0.466        0.606       0.0573       0.0789         0.39        0.414
     11  1600      0.00851      0.00753     8.34e-05     0.000896        0.673        0.959       0.0741        0.101         0.31        0.331
     11  1700       0.0186      0.00887     5.64e-05      0.00971        0.693         1.04       0.0608        0.083         1.03         1.09
     11  1800      0.00286      0.00244     3.47e-05     0.000386        0.374        0.545       0.0451       0.0651        0.167        0.217
     11  1900       0.0399       0.0365     6.15e-05      0.00331        0.986         2.11       0.0569       0.0866          0.6        0.636
     11  2000       0.0656       0.0565     9.49e-05      0.00899         1.39         2.63       0.0743        0.108        0.858         1.05
     11  2039       0.0081      0.00752     6.67e-05     0.000516        0.685        0.958       0.0616       0.0903         0.25        0.251

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     11   100       0.0147       0.0055     3.14e-05      0.00915        0.588        0.819       0.0435       0.0619        0.781         1.06
     11   182        0.171        0.169     3.83e-05      0.00182         2.74         4.54        0.049       0.0684        0.471        0.471


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              11 1106.124    0.001       0.0322     8.25e-05       0.0044       0.0367        0.974         1.98       0.0684          0.1        0.556        0.733
! Validation         11 1106.124    0.001       0.0261     6.06e-05      0.00524       0.0314        0.864         1.76       0.0571       0.0861        0.619        0.801
Wall time: 1106.1258630752563
! Best model       11    0.031
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     12   100       0.0441       0.0375     7.12e-05       0.0066         1.26         2.14       0.0606       0.0932        0.815        0.898
     12   200       0.0214       0.0194     7.14e-05      0.00192        0.874         1.54       0.0619       0.0934        0.368        0.484
     12   300       0.0391       0.0364     5.98e-05       0.0026         1.16         2.11       0.0591       0.0854        0.477        0.564
     12   400       0.0162       0.0149     7.79e-05       0.0012        0.812         1.35       0.0663       0.0975        0.324        0.382
     12   500       0.0337       0.0264        8e-05      0.00722        0.733         1.79       0.0626       0.0988        0.802        0.939
     12   600      0.00294      0.00166     5.68e-05      0.00122        0.352         0.45       0.0604       0.0833        0.299        0.386
     12   700       0.0588       0.0506     9.58e-05      0.00807          1.2         2.49       0.0709        0.108        0.904        0.992
     12   800       0.0677       0.0672     9.46e-05     0.000471         1.39         2.86        0.074        0.107        0.235         0.24
     12   900       0.0147       0.0142     8.42e-05     0.000474        0.709         1.32       0.0724        0.101        0.215        0.241
     12  1000      0.00547      0.00205     6.02e-05      0.00336        0.314        0.501       0.0586       0.0857        0.468        0.641
     12  1100       0.0961       0.0958     7.06e-05     0.000251          1.9         3.42       0.0617       0.0928        0.156        0.175
     12  1200         0.11        0.108     0.000135      0.00181         2.23         3.63       0.0861        0.128        0.336         0.47
     12  1300       0.0746       0.0677     7.97e-05      0.00681         1.58         2.87        0.065       0.0987        0.801        0.912
     12  1400       0.0225       0.0198     3.13e-05      0.00267         0.89         1.56       0.0445       0.0618        0.478        0.571
     12  1500       0.0324         0.03     9.93e-05      0.00225         1.05         1.91       0.0762         0.11        0.517        0.525
     12  1600        0.037       0.0362      6.2e-05     0.000701         1.14          2.1       0.0597        0.087        0.217        0.293
     12  1700       0.0303       0.0255     5.67e-05      0.00472        0.837         1.76        0.056       0.0832        0.641        0.759
     12  1800      0.00394      0.00218      4.7e-05      0.00172        0.421        0.515       0.0566       0.0758        0.434        0.458
     12  1900       0.0306       0.0251     0.000138      0.00543         1.18         1.75       0.0965         0.13         0.79        0.814
     12  2000       0.0148       0.0134     7.51e-05      0.00125        0.873         1.28       0.0663       0.0958        0.384         0.39
     12  2039       0.0799         0.07     5.31e-05      0.00988         1.61         2.92       0.0571       0.0805         1.09          1.1

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     12   100       0.0195      0.00816     4.81e-05       0.0113        0.667        0.998       0.0544       0.0766        0.769         1.17
     12   182        0.131        0.127     4.65e-05      0.00338         2.42         3.94       0.0548       0.0753        0.642        0.642


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              12 1205.803    0.001       0.0317     7.55e-05       0.0038       0.0356        0.958         1.97        0.065        0.096         0.52        0.681
! Validation         12 1205.803    0.001       0.0278      8.3e-05      0.00417       0.0321        0.886         1.83       0.0693        0.101        0.556        0.714
Wall time: 1205.8036470711231
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     13   100        0.158        0.153     0.000136      0.00559          2.6         4.32       0.0924        0.129         0.82        0.826
     13   200       0.0841       0.0746     7.78e-05      0.00944         1.95         3.02       0.0703       0.0975        0.814         1.07
     13   300        0.041        0.031     5.96e-05      0.00991        0.992         1.95       0.0605       0.0853        0.779          1.1
     13   400       0.0424       0.0389     5.09e-05      0.00343         1.14         2.18       0.0549       0.0788        0.541        0.647
     13   500        0.194        0.191     9.23e-05      0.00314         2.81         4.82        0.073        0.106        0.536        0.619
     13   600      0.00833      0.00739     7.38e-05      0.00087        0.623         0.95       0.0688       0.0949        0.235        0.326
     13   700       0.0386       0.0372     9.02e-05       0.0013         1.23         2.13       0.0709        0.105         0.33        0.399
     13   800      0.00542      0.00195     6.34e-05       0.0034        0.298        0.488       0.0591        0.088        0.531        0.645
     13   900       0.0107      0.00721     5.61e-05      0.00346        0.583        0.938       0.0575       0.0828        0.601         0.65
     13  1000       0.0105       0.0102     3.96e-05     0.000316        0.681         1.11       0.0515       0.0695        0.152        0.197
     13  1100      0.00947      0.00509     4.58e-05      0.00434         0.51        0.788        0.052       0.0748        0.628        0.728
     13  1200       0.0108      0.00911     9.19e-05      0.00163        0.657         1.05       0.0744        0.106         0.41        0.446
     13  1300       0.0478       0.0455      6.3e-05      0.00218         1.22         2.36       0.0602       0.0877        0.466        0.516
     13  1400       0.0139       0.0112     5.92e-05      0.00258        0.746         1.17       0.0543        0.085        0.525        0.561
     13  1500       0.0306       0.0203     6.34e-05       0.0102        0.825         1.58       0.0608        0.088         1.07         1.12
     13  1600        0.011      0.00705     0.000107      0.00381        0.652        0.928       0.0852        0.114        0.647        0.682
     13  1700       0.0316       0.0281     5.88e-05      0.00349         1.09         1.85       0.0576       0.0847        0.609        0.653
     13  1800      0.00667      0.00307     6.34e-05      0.00354         0.47        0.612       0.0643        0.088        0.595        0.657
     13  1900       0.0188       0.0181     5.24e-05     0.000687         1.02         1.49       0.0571         0.08        0.255         0.29
     13  2000        0.035       0.0332     7.19e-05      0.00167         1.26         2.01         0.07       0.0937        0.424        0.452
     13  2039       0.0123      0.00783     0.000217       0.0043        0.786        0.977        0.121        0.163        0.722        0.724

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     13   100       0.0134      0.00676     4.83e-05      0.00656        0.618        0.908       0.0554       0.0768        0.867        0.895
     13   182        0.167        0.167     4.69e-05     1.92e-05         2.75         4.52       0.0533       0.0757       0.0484       0.0484


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              13 1305.354    0.001       0.0311     7.76e-05      0.00347       0.0346        0.943         1.95       0.0661       0.0973        0.498        0.651
! Validation         13 1305.354    0.001       0.0262     7.73e-05      0.00694       0.0332        0.851         1.77       0.0666       0.0972        0.788        0.923
Wall time: 1305.3553131520748
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     14   100        0.014       0.0119     4.73e-05      0.00204        0.888         1.21       0.0559        0.076        0.404        0.499
     14   200       0.0217         0.02     0.000103      0.00157        0.881         1.56       0.0807        0.112        0.294        0.438
     14   300       0.0218       0.0197     9.27e-05      0.00202        0.882         1.55       0.0693        0.106        0.478        0.497
     14   400       0.0121      0.00703     5.44e-05        0.005        0.642        0.926       0.0551       0.0815        0.583        0.781
     14   500      0.00503      0.00233     0.000103       0.0026        0.399        0.533        0.084        0.112        0.444        0.564
     14   600       0.0318       0.0306     5.78e-05      0.00115        0.991         1.93       0.0601        0.084        0.321        0.374
     14   700       0.0119       0.0116     4.07e-05     0.000276        0.654         1.19       0.0496       0.0705        0.168        0.184
     14   800       0.0139      0.00852     7.15e-05      0.00528        0.716         1.02       0.0678       0.0934        0.697        0.803
     14   900       0.0881       0.0868     0.000107      0.00111          1.7         3.26       0.0755        0.115        0.345        0.367
     14  1000      0.00958      0.00833     8.11e-05      0.00117        0.589         1.01       0.0637       0.0995        0.301        0.378
     14  1100      0.00786      0.00489     4.22e-05      0.00293        0.477        0.772       0.0516       0.0718        0.487        0.598
     14  1200      0.00339      0.00236     2.89e-05        0.001        0.366        0.537       0.0431       0.0594        0.291         0.35
     14  1300       0.0706        0.069     8.05e-05      0.00157         1.48          2.9       0.0686       0.0991        0.344        0.438
     14  1400      0.00439      0.00257      5.1e-05      0.00177        0.392         0.56       0.0556       0.0789        0.362        0.464
     14  1500       0.0372       0.0307      8.3e-05      0.00636        0.969         1.94       0.0691        0.101        0.714        0.881
     14  1600       0.0443       0.0428      5.8e-05      0.00147         1.09         2.29       0.0566       0.0842         0.35        0.423
     14  1700        0.008      0.00461     5.48e-05      0.00334        0.483         0.75        0.059       0.0818        0.555        0.638
     14  1800       0.0188       0.0166     6.78e-05      0.00215        0.745         1.42       0.0591        0.091        0.469        0.512
     14  1900       0.0199       0.0181     0.000151       0.0016         0.86         1.49       0.0893        0.136        0.394        0.442
     14  2000       0.0153       0.0143     5.88e-05        0.001        0.859         1.32       0.0607       0.0847        0.264         0.35
     14  2039       0.0285       0.0283      3.4e-05     0.000135        0.897         1.86         0.05       0.0645        0.125        0.128

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     14   100      0.00842      0.00739     4.64e-05     0.000988        0.624         0.95       0.0528       0.0752        0.279        0.347
     14   182        0.167        0.167     4.41e-05     0.000175         2.75         4.51       0.0531       0.0734        0.146        0.146


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              14 1404.796    0.001       0.0304     7.53e-05      0.00325       0.0337        0.919         1.93       0.0648       0.0959        0.481         0.63
! Validation         14 1404.796    0.001       0.0262     7.49e-05      0.00146       0.0277        0.864         1.77       0.0648       0.0957        0.319        0.423
Wall time: 1404.7967877686024
! Best model       14    0.028
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     15   100       0.0674       0.0648     0.000111      0.00248         1.23         2.81       0.0777        0.116        0.511        0.551
     15   200       0.0122       0.0105     0.000143      0.00155        0.764         1.13       0.0934        0.132        0.388        0.435
     15   300      0.00684      0.00606      3.9e-05     0.000746        0.558         0.86       0.0506        0.069        0.239        0.302
     15   400        0.119        0.117     7.97e-05      0.00104         1.87         3.79       0.0592       0.0987          0.3        0.356
     15   500        0.031        0.026     8.74e-05      0.00488        0.976         1.78       0.0747        0.103        0.606        0.772
     15   600        0.243         0.24     0.000102      0.00302         2.36         5.41       0.0808        0.111        0.507        0.607
     15   700       0.0419       0.0378      7.6e-05      0.00404         1.07         2.15         0.07       0.0963        0.474        0.702
     15   800       0.0138      0.00731     7.41e-05      0.00637         0.57        0.945       0.0642       0.0951        0.657        0.882
     15   900       0.0407       0.0384     7.03e-05      0.00231        0.931         2.16       0.0605       0.0927        0.394        0.531
     15  1000       0.0351       0.0333     8.95e-05      0.00163         1.17         2.02       0.0674        0.105        0.423        0.446
     15  1100       0.0297       0.0287     7.85e-05     0.000992         1.14         1.87       0.0649       0.0979        0.288        0.348
     15  1200       0.0324       0.0293     8.15e-05      0.00296        0.863         1.89       0.0613       0.0997        0.511        0.601
     15  1300      0.00507      0.00423     3.86e-05     0.000802        0.466        0.718       0.0485       0.0686          0.2        0.313
     15  1400       0.0422       0.0399     9.34e-05      0.00213         1.31         2.21       0.0699        0.107        0.392         0.51
     15  1500      0.00747      0.00685     8.82e-05     0.000534        0.634        0.914       0.0681        0.104        0.219        0.255
     15  1600      0.00834      0.00683     9.23e-05      0.00142        0.622        0.913       0.0759        0.106        0.313        0.416
     15  1700        0.035        0.032     6.26e-05      0.00286         1.06         1.98       0.0617       0.0874        0.559        0.591
     15  1800       0.0062      0.00575     6.15e-05     0.000386         0.49        0.838       0.0512       0.0867        0.201        0.217
     15  1900       0.0407        0.035     0.000104      0.00558         1.17         2.07       0.0796        0.112        0.787        0.825
     15  2000       0.0244      0.00949     0.000148       0.0147        0.667         1.08       0.0889        0.134         1.17         1.34
     15  2039       0.0772        0.075      6.8e-05      0.00216         1.42         3.03       0.0563       0.0911        0.426        0.514

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     15   100       0.0104      0.00438     3.49e-05      0.00598        0.507        0.731       0.0454       0.0653        0.802        0.855
     15   182        0.175        0.168     3.45e-05      0.00772          2.8         4.52       0.0479       0.0649        0.971        0.971


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              15 1504.302    0.001       0.0301     7.83e-05      0.00301       0.0332        0.916         1.92       0.0663       0.0977        0.464        0.606
! Validation         15 1504.302    0.001       0.0278     5.82e-05      0.00642       0.0343        0.859         1.82       0.0561       0.0844        0.756        0.885
Wall time: 1504.303014613688
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     16   100       0.0896       0.0878     9.06e-05      0.00165         1.72         3.27       0.0664        0.105        0.384        0.448
     16   200       0.0316         0.03     9.13e-05      0.00148         1.09         1.91       0.0753        0.106        0.373        0.425
     16   300       0.0112      0.00878     8.09e-05      0.00231        0.727         1.04       0.0683       0.0994        0.472        0.531
     16   400       0.0557       0.0544     9.39e-05      0.00124         1.54         2.58       0.0728        0.107        0.308        0.389
     16   500       0.0582       0.0581     5.63e-05     6.67e-05         1.21         2.66       0.0531       0.0829       0.0592       0.0902
     16   600       0.0285       0.0228     3.79e-05      0.00572        0.901         1.67       0.0472        0.068        0.756        0.836
     16   700       0.0155       0.0152     5.05e-05     0.000299        0.686         1.36       0.0544       0.0785        0.178        0.191
     16   800        0.041       0.0403     5.45e-05     0.000563         1.11         2.22       0.0559       0.0815        0.218        0.262
     16   900      0.00636      0.00265     8.23e-05      0.00364        0.417        0.568       0.0643          0.1        0.654        0.666
     16  1000       0.0287       0.0257     9.47e-05      0.00295            1         1.77       0.0786        0.108        0.518          0.6
     16  1100      0.00464      0.00377     4.91e-05     0.000816        0.403        0.678       0.0539       0.0774        0.266        0.316
     16  1200       0.0258       0.0226     7.87e-05      0.00316        0.941         1.66        0.068        0.098        0.599        0.621
     16  1300       0.0375       0.0363     8.54e-05      0.00107        0.979         2.11       0.0709        0.102        0.307        0.361
     16  1400       0.0474       0.0428     7.13e-05      0.00454         1.09         2.29       0.0643       0.0933        0.669        0.744
     16  1500       0.0408        0.038     5.66e-05      0.00277         1.07         2.15       0.0555       0.0831        0.546        0.582
     16  1600       0.0215       0.0173     9.74e-05      0.00413        0.798         1.45       0.0722        0.109        0.658         0.71
     16  1700       0.0286       0.0252     5.62e-05      0.00337        0.744         1.75       0.0563       0.0828        0.587        0.641
     16  1800       0.0831       0.0821     8.29e-05     0.000968         1.33         3.17       0.0676        0.101        0.297        0.344
     16  1900       0.0342       0.0327     0.000113      0.00134         1.06            2       0.0772        0.117        0.302        0.404
     16  2000         0.12        0.114      0.00013      0.00571         2.26         3.73       0.0824        0.126        0.758        0.835
     16  2039      0.00828      0.00556     6.02e-05      0.00267        0.455        0.824       0.0655       0.0857        0.569         0.57

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     16   100       0.0119      0.00903     6.65e-05      0.00278          0.7         1.05       0.0639       0.0901        0.553        0.582
     16   182        0.131        0.131      5.9e-05     0.000109         2.41            4       0.0633       0.0849        0.116        0.116


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              16 1603.728    0.001       0.0299     7.54e-05      0.00304        0.033        0.911         1.91       0.0648       0.0959        0.464        0.609
! Validation         16 1603.728    0.001       0.0263       0.0001        0.003       0.0294        0.893         1.77       0.0773        0.111        0.498        0.606
Wall time: 1603.7294059693813
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     17   100      0.00634      0.00577     5.95e-05     0.000516        0.598        0.839       0.0604       0.0852        0.219        0.251
     17   200      0.00916      0.00242     2.64e-05      0.00672        0.429        0.543       0.0402       0.0567        0.778        0.906
     17   300        0.067       0.0646     7.81e-05      0.00238         1.63         2.81       0.0642       0.0976        0.496        0.539
     17   400       0.0842       0.0786     6.65e-05      0.00552         1.39          3.1       0.0594       0.0901        0.547        0.821
     17   500      0.00994      0.00869      7.7e-05      0.00117        0.688         1.03       0.0653       0.0969        0.317        0.378
     17   600        0.012      0.00482      7.8e-05      0.00711          0.5        0.767       0.0691       0.0976        0.815        0.932
     17   700       0.0086       0.0068     5.57e-05      0.00175        0.518        0.911        0.058       0.0825        0.413        0.463
     17   800       0.0461       0.0449     7.87e-05      0.00112         1.12         2.34       0.0704        0.098        0.345         0.37
     17   900      0.00982      0.00846     5.11e-05      0.00131        0.571         1.02       0.0523        0.079        0.328          0.4
     17  1000      0.00848      0.00741     6.75e-05        0.001        0.592        0.951       0.0611       0.0908        0.317         0.35
     17  1100      0.00817      0.00384     5.03e-05      0.00429        0.495        0.684       0.0598       0.0784        0.707        0.723
     17  1200        0.179        0.178     8.26e-05     0.000713         1.75         4.66        0.062          0.1        0.256        0.295
     17  1300       0.0144        0.012      5.1e-05      0.00235         0.72         1.21        0.054       0.0789         0.39        0.535
     17  1400       0.0378        0.037     6.17e-05     0.000757          1.2         2.13        0.056       0.0868        0.287        0.304
     17  1500      0.00475      0.00243      4.3e-05      0.00228        0.416        0.544       0.0509       0.0724        0.455        0.528
     17  1600       0.0354       0.0301     9.69e-05      0.00521         1.07         1.92       0.0764        0.109        0.695        0.798
     17  1700      0.00983      0.00927     0.000116     0.000445        0.766         1.06       0.0742        0.119        0.197        0.233
     17  1800       0.0278       0.0266     7.45e-05      0.00111        0.835          1.8       0.0661       0.0953        0.362        0.369
     17  1900       0.0394       0.0374     5.65e-05      0.00201         1.05         2.14       0.0547        0.083        0.369        0.496
     17  2000       0.0891       0.0871     0.000112      0.00192         1.66         3.26        0.084        0.117        0.384        0.484
     17  2039       0.0072      0.00703     6.26e-05     0.000108        0.686        0.927       0.0616       0.0874        0.111        0.115

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     17   100      0.00738      0.00662     5.45e-05     0.000705        0.558        0.899        0.056       0.0815        0.228        0.293
     17   182        0.128        0.128     3.81e-05     0.000156         2.41         3.95       0.0497       0.0682        0.138        0.138


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              17 1702.980    0.001       0.0297     7.79e-05      0.00257       0.0324        0.906          1.9       0.0658       0.0975        0.425         0.56
! Validation         17 1702.980    0.001       0.0269     8.33e-05      0.00172       0.0287        0.882          1.8       0.0681        0.101        0.361         0.46
Wall time: 1702.9816209301353
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     18   100       0.0257        0.024     8.87e-05       0.0016        0.846         1.71       0.0731        0.104        0.357        0.442
     18   200        0.135        0.134      0.00013     0.000396         2.42         4.05       0.0878        0.126        0.214         0.22
     18   300       0.0328       0.0318     9.33e-05     0.000907         1.05         1.97        0.076        0.107        0.266        0.333
     18   400       0.0184       0.0136     9.42e-05      0.00467        0.868         1.29       0.0781        0.107        0.519        0.755
     18   500       0.0408         0.04     6.79e-05     0.000667          1.1         2.21       0.0625       0.0911        0.246        0.285
     18   600       0.0225       0.0198     6.26e-05      0.00259        0.665         1.56        0.059       0.0874        0.513        0.562
     18   700       0.0233       0.0219     9.42e-05      0.00133         0.97         1.63       0.0647        0.107        0.299        0.404
     18   800      0.00806      0.00777     4.55e-05     0.000251        0.625        0.974       0.0538       0.0745        0.152        0.175
     18   900       0.0632       0.0621     6.75e-05     0.000945         1.31         2.75       0.0645       0.0908        0.288         0.34
     18  1000       0.0266       0.0255        9e-05      0.00107        0.884         1.76       0.0777        0.105        0.307        0.362
     18  1100      0.00639      0.00562     5.07e-05     0.000714        0.553        0.829       0.0552       0.0786        0.255        0.295
     18  1200       0.0178       0.0142     6.24e-05      0.00348        0.791         1.32       0.0593       0.0873        0.478        0.652
     18  1300       0.0889       0.0882     9.75e-05     0.000647         1.45         3.28        0.076        0.109        0.215        0.281
     18  1400       0.0859       0.0842     0.000238      0.00141         1.32         3.21        0.111        0.171         0.36        0.415
     18  1500       0.0113      0.00979     8.33e-05      0.00142        0.677         1.09       0.0722        0.101        0.329        0.417
     18  1600       0.0361       0.0352     4.24e-05     0.000901        0.898         2.07        0.051        0.072        0.272        0.332
     18  1700       0.0126      0.00603     4.56e-05      0.00652        0.568        0.858       0.0519       0.0746        0.697        0.892
     18  1800       0.0489       0.0483     8.62e-05      0.00045         1.29         2.43       0.0675        0.103        0.223        0.234
     18  1900       0.0109      0.00719     7.91e-05       0.0036        0.604        0.937       0.0672       0.0983        0.528        0.663
     18  2000       0.0208       0.0115     5.65e-05      0.00931        0.647         1.18       0.0578        0.083        0.999         1.07
     18  2039      0.00598      0.00386     0.000113      0.00201         0.53        0.686       0.0879        0.118        0.495        0.495

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     18   100      0.00969      0.00557     5.62e-05      0.00407        0.531        0.824       0.0583       0.0829        0.473        0.705
     18   182         0.11        0.109     4.07e-05     0.000486         2.21         3.65       0.0497       0.0705        0.244        0.244


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              18 1801.846    0.001       0.0297     8.16e-05      0.00236       0.0321        0.904          1.9       0.0676       0.0998        0.416        0.537
! Validation         18 1801.846    0.001       0.0263     7.83e-05      0.00216       0.0286        0.827         1.78       0.0659       0.0979        0.401        0.515
Wall time: 1801.84728333354
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     19   100       0.0681       0.0664     8.79e-05      0.00162         1.23         2.85       0.0721        0.104        0.332        0.445
     19   200       0.0222       0.0189     6.66e-05      0.00317         0.81         1.52       0.0545       0.0901        0.579        0.622
     19   300       0.0312       0.0297     8.17e-05       0.0014        0.919          1.9       0.0675       0.0999        0.359        0.413
     19   400      0.00226      0.00159     4.65e-05     0.000628        0.336         0.44       0.0545       0.0753        0.226        0.277
     19   500       0.0316       0.0306     0.000115      0.00088         1.12         1.93       0.0825        0.118        0.238        0.328
     19   600       0.0617        0.057     9.75e-05      0.00456          1.5         2.64       0.0712        0.109        0.721        0.746
     19   700       0.0694        0.068     8.18e-05       0.0013          1.5         2.88        0.066       0.0999        0.363        0.399
     19   800      0.00649      0.00531     6.16e-05      0.00112        0.573        0.805       0.0623       0.0867        0.329         0.37
     19   900       0.0396       0.0381     7.39e-05      0.00139        0.878         2.16       0.0619        0.095        0.363        0.412
     19  1000       0.0449       0.0398     8.67e-05      0.00501         1.23          2.2       0.0763        0.103        0.614        0.782
     19  1100      0.00705      0.00674       0.0001      0.00021        0.553        0.907       0.0748         0.11         0.14         0.16
     19  1200      0.00792      0.00234     4.32e-05      0.00554        0.405        0.534       0.0478       0.0726        0.793        0.822
     19  1300       0.0257       0.0248      6.9e-05     0.000747        0.846         1.74       0.0596       0.0918        0.181        0.302
     19  1400       0.0865       0.0826      0.00012      0.00383         1.84         3.18       0.0847        0.121        0.567        0.684
     19  1500        0.083       0.0818     0.000144      0.00101         1.82         3.16        0.087        0.133         0.32        0.351
     19  1600       0.0576       0.0251     0.000192       0.0323          1.1         1.75        0.111        0.153         1.34         1.98
     19  1700      0.00895      0.00555     0.000106      0.00329        0.526        0.823       0.0787        0.114        0.548        0.634
     19  1800      0.00952      0.00747     6.57e-05      0.00198        0.674        0.955       0.0618       0.0895        0.471        0.492
     19  1900      0.00743      0.00365      0.00011      0.00367        0.468        0.668       0.0852        0.116        0.511         0.67
     19  2000       0.0648       0.0626     0.000103      0.00206         1.79         2.76       0.0831        0.112        0.343        0.501
     19  2039      0.00559      0.00288     3.71e-05      0.00267        0.475        0.593       0.0472       0.0673        0.474        0.571

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     19   100      0.00855      0.00439     6.51e-05       0.0041        0.515        0.732       0.0561       0.0891        0.494        0.708
     19   182        0.189        0.189     3.48e-05     0.000194         2.88          4.8       0.0479       0.0652        0.154        0.154


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              19 1900.860    0.001       0.0293     8.25e-05      0.00247       0.0318        0.894         1.89       0.0671          0.1         0.42        0.549
! Validation         19 1900.860    0.001       0.0267     8.53e-05      0.00245       0.0292         0.88         1.78       0.0657        0.102        0.411        0.548
Wall time: 1900.860594496131
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     20   100       0.0101      0.00792     0.000114      0.00211        0.723        0.983       0.0775        0.118        0.494        0.508
     20   200       0.0513       0.0402     6.91e-05       0.0111        0.963         2.22       0.0595       0.0918        0.848         1.16
     20   300       0.0263       0.0254     9.93e-05     0.000761         1.01         1.76       0.0764         0.11        0.252        0.305
     20   400      0.00608      0.00222     8.72e-05      0.00377         0.38        0.521       0.0756        0.103        0.574        0.679
     20   500       0.0602       0.0597     0.000108     0.000316         1.65          2.7       0.0795        0.115        0.143        0.197
     20   600      0.00759        0.005     3.78e-05      0.00256        0.439        0.781       0.0464        0.068         0.46        0.559
     20   700       0.0461        0.042     7.87e-05      0.00411         1.25         2.26        0.068        0.098        0.633        0.708
     20   800       0.0134       0.0111     0.000134      0.00217        0.684         1.17       0.0895        0.128        0.481        0.515
     20   900       0.0389       0.0375      0.00011      0.00132         1.22         2.14       0.0805        0.116        0.371        0.401
     20  1000       0.0539       0.0526     0.000141      0.00117         1.49         2.53       0.0872        0.131        0.264        0.379
     20  1100        0.029       0.0274      0.00011      0.00146         1.15         1.83       0.0824        0.116        0.363        0.422
     20  1200       0.0448       0.0425     8.95e-05      0.00225         1.18         2.28       0.0743        0.104        0.485        0.524
     20  1300        0.011       0.0102     7.77e-05      0.00072        0.682         1.12       0.0689       0.0974        0.241        0.296
     20  1400       0.0212       0.0206     5.66e-05     0.000552        0.823         1.59       0.0547       0.0831        0.203         0.26
     20  1500       0.0118       0.0111     4.61e-05     0.000646        0.689         1.16       0.0511        0.075        0.237        0.281
     20  1600       0.0208       0.0194     7.93e-05      0.00133        0.836         1.54       0.0648       0.0984        0.261        0.402
     20  1700       0.0215       0.0206     0.000135     0.000787         1.04         1.58       0.0936        0.128        0.283         0.31
     20  1800       0.0691       0.0658     0.000196      0.00309         1.61         2.83        0.107        0.155        0.596        0.614
     20  1900       0.0174       0.0168     3.92e-05     0.000546         0.81         1.43       0.0497       0.0692        0.238        0.258
     20  2000       0.0105      0.00856     5.26e-05      0.00184        0.585         1.02       0.0534       0.0801        0.442        0.474
     20  2039      0.00291      0.00191     0.000104     0.000887        0.372        0.483        0.083        0.113        0.322        0.329

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     20   100      0.00912      0.00843     9.58e-05     0.000589        0.687         1.01       0.0716        0.108          0.2        0.268
     20   182        0.126        0.125     4.56e-05      0.00147         2.37          3.9       0.0536       0.0746        0.424        0.424


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              20 1999.662    0.001       0.0293     8.78e-05      0.00226       0.0316        0.894         1.89       0.0693        0.104        0.402        0.526
! Validation         20 1999.662    0.001       0.0269     0.000115      0.00146       0.0285         0.87          1.8       0.0786        0.119        0.322        0.422
Wall time: 1999.6631759256124
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     21   100       0.0116      0.00758     0.000133       0.0039        0.674        0.962       0.0859        0.127        0.592         0.69
     21   200       0.0302       0.0289     5.24e-05      0.00118         1.08         1.88       0.0587         0.08        0.335         0.38
     21   300      0.00634      0.00462     7.09e-05      0.00165        0.547        0.751       0.0632        0.093        0.393        0.449
     21   400       0.0111      0.00677      9.9e-05      0.00427        0.686        0.909       0.0748         0.11        0.675        0.722
     21   500       0.0202        0.015     6.31e-05      0.00523        0.827         1.35       0.0624       0.0878        0.633        0.799
     21   600        0.015       0.0118     9.95e-05      0.00314        0.885          1.2       0.0711         0.11        0.445        0.619
     21   700        0.014       0.0138     5.52e-05      0.00017        0.704          1.3       0.0547       0.0821        0.141        0.144
     21   800       0.0698       0.0685     9.35e-05      0.00117         1.29         2.89       0.0693        0.107        0.332        0.378
     21   900      0.00594      0.00391     0.000112      0.00193        0.466        0.691       0.0827        0.117        0.443        0.485
     21  1000       0.0293       0.0254     0.000117       0.0038         1.09         1.76       0.0794        0.119        0.588        0.681
     21  1100       0.0117      0.00432     9.51e-05      0.00731        0.473        0.726       0.0731        0.108        0.771        0.945
     21  1200       0.0303         0.03     6.87e-05     0.000184        0.847         1.91        0.061       0.0916        0.144         0.15
     21  1300       0.0055      0.00498      5.4e-05     0.000473        0.517        0.779       0.0563       0.0812        0.204         0.24
     21  1400       0.0614       0.0598      0.00012      0.00149         1.56          2.7       0.0794        0.121        0.388        0.426
     21  1500        0.134        0.132     8.69e-05      0.00178         2.22         4.02        0.073        0.103        0.366        0.467
     21  1600       0.0276       0.0269     4.32e-05      0.00061         1.07         1.81       0.0525       0.0726        0.229        0.273
     21  1700       0.0131       0.0059     8.36e-05      0.00712        0.495        0.848       0.0686        0.101        0.708        0.932
     21  1800        0.012       0.0106     0.000119      0.00121          0.7         1.14        0.078        0.121        0.372        0.385
     21  1900       0.0194       0.0188     6.47e-05     0.000563        0.902         1.51       0.0571       0.0889         0.24        0.262
     21  2000       0.0342       0.0306     9.16e-05      0.00352         1.12         1.93       0.0714        0.106        0.452        0.655
     21  2039       0.0721       0.0526     0.000233       0.0193         1.51         2.53        0.106        0.169         1.16         1.53

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     21   100      0.00576      0.00536     6.63e-05     0.000339        0.532        0.809       0.0624         0.09        0.154        0.203
     21   182        0.141         0.14     4.79e-05      0.00118          2.5         4.14       0.0547       0.0765         0.38         0.38


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              21 2098.567    0.001       0.0292     9.03e-05      0.00226       0.0315        0.891         1.89         0.07        0.105        0.394        0.525
! Validation         21 2098.567    0.001       0.0257     8.54e-05      0.00148       0.0272         0.83         1.75       0.0689        0.102        0.322        0.425
Wall time: 2098.56802868098
! Best model       21    0.027
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     22   100      0.00344      0.00269     8.83e-05     0.000667        0.404        0.573       0.0739        0.104         0.28        0.285
     22   200        0.053        0.052     0.000116     0.000888         1.13         2.52       0.0723        0.119        0.279        0.329
     22   300       0.0375       0.0371     7.78e-05     0.000296         1.01         2.13       0.0657       0.0975        0.173         0.19
     22   400       0.0263       0.0253     7.74e-05      0.00094        0.873         1.76       0.0702       0.0972        0.323        0.339
     22   500      0.00322      0.00184     5.31e-05      0.00133        0.359        0.474       0.0563       0.0805        0.317        0.402
     22   600      0.00286      0.00217     6.25e-05     0.000629        0.339        0.515       0.0619       0.0873        0.231        0.277
     22   700      0.00325      0.00278     4.04e-05     0.000426        0.403        0.583       0.0454       0.0703        0.174        0.228
     22   800        0.155        0.153     8.37e-05      0.00193         1.71         4.32        0.059        0.101        0.379        0.486
     22   900        0.037       0.0358     9.37e-05      0.00116         1.08         2.09       0.0695        0.107        0.305        0.376
     22  1000      0.00326      0.00122     6.22e-05      0.00197        0.255        0.387       0.0517       0.0871        0.423        0.491
     22  1100      0.00696      0.00667     7.41e-05     0.000213        0.589        0.902       0.0651       0.0951        0.144        0.161
     22  1200        0.016        0.014     0.000129       0.0019        0.899         1.31       0.0888        0.125        0.408        0.481
     22  1300      0.00367      0.00322      7.3e-05     0.000381        0.363        0.627        0.063       0.0944        0.194        0.216
     22  1400      0.00757      0.00413     8.45e-05      0.00336         0.45         0.71       0.0671        0.102        0.585         0.64
     22  1500       0.0148       0.0115     9.46e-05      0.00321        0.662         1.18       0.0674        0.107        0.527        0.626
     22  1600       0.0115       0.0102     5.28e-05      0.00123        0.685         1.12       0.0562       0.0803        0.311        0.388
     22  1700       0.0338       0.0314     0.000123      0.00231        0.858         1.96       0.0735        0.122        0.481        0.531
     22  1800       0.0101      0.00921     0.000155     0.000697        0.589         1.06       0.0942        0.138        0.233        0.292
     22  1900      0.00568      0.00491     9.96e-05     0.000676        0.542        0.774       0.0809         0.11        0.246        0.287
     22  2000       0.0465       0.0454     8.77e-05        0.001         1.08         2.36       0.0687        0.103        0.312         0.35
     22  2039      0.00771      0.00481     0.000155      0.00274        0.589        0.767       0.0918        0.137        0.435        0.579

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     22   100       0.0101      0.00831     7.18e-05      0.00176        0.623         1.01       0.0629       0.0936        0.402        0.464
     22   182        0.121         0.12     4.32e-05      0.00153         2.32         3.82       0.0517       0.0726        0.432        0.432


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              22 2197.472    0.001        0.029     9.19e-05      0.00199       0.0311        0.884         1.88       0.0703        0.106         0.37        0.493
! Validation         22 2197.472    0.001       0.0267     9.12e-05      0.00181       0.0286        0.856         1.79       0.0703        0.106        0.386         0.47
Wall time: 2197.472708195448
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     23   100      0.00748      0.00658      5.5e-05     0.000851        0.514        0.896       0.0532       0.0819         0.29        0.322
     23   200       0.0519       0.0508     0.000135     0.000906         1.43         2.49       0.0747        0.128        0.297        0.333
     23   300      0.00324       0.0024     9.18e-05     0.000753        0.408        0.541       0.0738        0.106        0.234        0.303
     23   400       0.0136       0.0127     0.000108     0.000823        0.714         1.25       0.0845        0.115        0.276        0.317
     23   500       0.0118       0.0105     9.61e-05       0.0012        0.738         1.13       0.0696        0.108        0.264        0.383
     23   600        0.023        0.015     0.000133      0.00787        0.886         1.35       0.0959        0.127        0.938         0.98
     23   700       0.0683       0.0619     0.000225      0.00626         1.75         2.75        0.119        0.166        0.677        0.874
     23   800       0.0174       0.0164     0.000116      0.00088        0.792         1.42       0.0848        0.119        0.298        0.328
     23   900      0.00478      0.00259     6.59e-05      0.00212        0.366        0.562       0.0547       0.0897        0.477        0.509
     23  1000       0.0771       0.0769     8.09e-05     9.02e-05         1.46         3.06       0.0652       0.0994        0.102        0.105
     23  1100       0.0158       0.0135     8.12e-05      0.00222        0.714         1.28       0.0658       0.0996          0.4        0.521
     23  1200      0.00804      0.00696     0.000116     0.000958        0.739        0.922        0.078        0.119        0.311        0.342
     23  1300       0.0264       0.0243     0.000176      0.00188         1.05         1.72       0.0979        0.146        0.365        0.479
     23  1400       0.0356       0.0347     9.99e-05     0.000719         1.03         2.06       0.0734         0.11        0.277        0.296
     23  1500       0.0425       0.0416     7.38e-05     0.000818         1.01         2.25        0.063       0.0949        0.265        0.316
     23  1600       0.0472       0.0452     9.22e-05       0.0019         1.09         2.35       0.0703        0.106        0.429        0.482
     23  1700       0.0123       0.0112      6.3e-05      0.00105         0.72         1.17       0.0589       0.0877        0.354        0.358
     23  1800       0.0157       0.0154     8.19e-05     0.000278        0.806         1.37       0.0645          0.1        0.172        0.184
     23  1900        0.124        0.124     8.45e-05     0.000481         1.85         3.88        0.065        0.102        0.228        0.242
     23  2000       0.0158       0.0144     8.02e-05      0.00132        0.737         1.33       0.0643        0.099        0.302        0.402
     23  2039       0.0126      0.00822     6.65e-05      0.00434        0.747            1        0.063       0.0901        0.619        0.728

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     23   100       0.0072      0.00611     8.92e-05     0.000997        0.599        0.864        0.068        0.104        0.298        0.349
     23   182        0.143        0.143        5e-05     2.46e-05         2.55         4.17       0.0568       0.0781       0.0548       0.0548


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              23 2296.380    0.001        0.029     9.53e-05      0.00187       0.0309        0.885         1.88       0.0714        0.108        0.366        0.478
! Validation         23 2296.380    0.001       0.0265       0.0001      0.00167       0.0282        0.859         1.78       0.0727        0.111        0.363        0.452
Wall time: 2296.3809211701155
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     24   100       0.0162       0.0154     7.89e-05     0.000739        0.655         1.37       0.0634       0.0981        0.235          0.3
     24   200       0.0688       0.0678     8.67e-05     0.000905         1.25         2.88       0.0638        0.103         0.31        0.332
     24   300       0.0267       0.0249     0.000124      0.00165         1.08         1.74       0.0836        0.123        0.371        0.448
     24   400       0.0421       0.0405      0.00013       0.0015         1.19         2.22       0.0852        0.126        0.354        0.428
     24   500      0.00498      0.00279     4.21e-05      0.00215        0.414        0.583       0.0459       0.0717        0.484        0.513
     24   600       0.0165       0.0122     6.79e-05       0.0042        0.807         1.22       0.0562       0.0911        0.601        0.716
     24   700        0.014       0.0136     9.61e-05     0.000341        0.698         1.29       0.0694        0.108        0.193        0.204
     24   800       0.0217       0.0185     0.000136      0.00306        0.672          1.5       0.0889        0.129        0.413        0.611
     24   900       0.0154       0.0132     6.99e-05       0.0021        0.741         1.27       0.0626       0.0924        0.376        0.507
     24  1000       0.0274       0.0267     9.46e-05     0.000624        0.896          1.8        0.067        0.107        0.241        0.276
     24  1100      0.00526      0.00392     0.000155      0.00118        0.444        0.692       0.0978        0.138        0.368        0.379
     24  1200      0.00424       0.0024     5.19e-05      0.00179         0.38        0.542       0.0507       0.0796        0.462        0.467
     24  1300       0.0256       0.0235     6.12e-05      0.00204        0.889         1.69       0.0587       0.0865        0.483        0.499
     24  1400      0.00831      0.00792     5.28e-05     0.000329        0.662        0.983       0.0582       0.0803        0.166        0.201
     24  1500      0.00419      0.00313     7.76e-05     0.000985        0.352        0.618       0.0638       0.0974        0.294        0.347
     24  1600       0.0468       0.0463     4.74e-05      0.00044        0.863         2.38       0.0534       0.0761        0.229        0.232
     24  1700       0.0263       0.0254     0.000117     0.000777         0.88         1.76       0.0829        0.119        0.253        0.308
     24  1800        0.101          0.1     0.000162     0.000397         1.64          3.5       0.0863        0.141        0.209         0.22
     24  1900       0.0399       0.0389     9.39e-05     0.000909         1.25         2.18       0.0742        0.107        0.295        0.333
     24  2000        0.016       0.0153     5.89e-05      0.00065         0.86         1.36       0.0548       0.0848         0.21        0.282
     24  2039      0.00434     0.000705      6.7e-05      0.00357        0.235        0.293        0.061       0.0904        0.659         0.66

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     24   100      0.00745      0.00539     6.82e-05      0.00199        0.567        0.812       0.0619       0.0912        0.372        0.493
     24   182        0.173        0.171     4.32e-05      0.00191         2.74         4.57       0.0529       0.0726        0.483        0.483


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              24 2395.312    0.001       0.0289     9.36e-05      0.00176       0.0308        0.884         1.88       0.0708        0.107        0.358        0.463
! Validation         24 2395.312    0.001       0.0255     8.93e-05      0.00187       0.0274        0.836         1.74       0.0685        0.105        0.375        0.478
Wall time: 2395.3130925297737
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     25   100       0.0547       0.0541     0.000135     0.000425         1.49         2.57       0.0871        0.128        0.227        0.228
     25   200       0.0168       0.0149     9.04e-05      0.00177        0.595         1.35       0.0646        0.105        0.363        0.465
     25   300       0.0228       0.0193     8.48e-05      0.00345        0.976         1.53       0.0754        0.102        0.477        0.649
     25   400      0.00373       0.0033      9.7e-05     0.000326         0.41        0.635       0.0747        0.109        0.159          0.2
     25   500        0.011      0.00978     0.000105      0.00108        0.696         1.09       0.0779        0.113        0.348        0.362
     25   600       0.0396       0.0379     8.13e-05      0.00166        0.988         2.15       0.0669       0.0996        0.424         0.45
     25   700       0.0103      0.00908     7.54e-05       0.0011        0.709         1.05       0.0703        0.096        0.305        0.366
     25   800       0.0269       0.0233     7.02e-05      0.00355        0.875         1.69       0.0624       0.0926        0.536        0.658
     25   900       0.0308       0.0304     8.46e-05      0.00031         1.01         1.93        0.063        0.102        0.171        0.194
     25  1000       0.0485        0.046      7.8e-05       0.0024         1.28         2.37       0.0698       0.0976        0.413        0.542
     25  1100        0.012      0.00996     6.16e-05        0.002        0.599          1.1       0.0557       0.0867        0.481        0.494
     25  1200      0.00262      0.00219     0.000114     0.000311        0.372        0.518       0.0736        0.118        0.166        0.195
     25  1300       0.0233       0.0111     5.05e-05       0.0122        0.706         1.16       0.0526       0.0785         1.11         1.22
     25  1400        0.044       0.0433     0.000125     0.000622         1.18          2.3       0.0853        0.124        0.205        0.276
     25  1500      0.00686      0.00553     9.55e-05      0.00124         0.51        0.821       0.0721        0.108        0.364        0.389
     25  1600      0.00862      0.00443     6.57e-05      0.00413        0.424        0.735       0.0633       0.0895         0.61         0.71
     25  1700      0.00386      0.00356     7.38e-05     0.000217        0.417         0.66       0.0586       0.0949        0.144        0.163
     25  1800       0.0317       0.0305     9.55e-05      0.00115            1         1.93       0.0734        0.108        0.307        0.374
     25  1900        0.021       0.0191     0.000101      0.00183        0.784         1.53       0.0681        0.111        0.469        0.473
     25  2000       0.0371       0.0348     6.46e-05      0.00222        0.834         2.06       0.0594       0.0888        0.427         0.52
     25  2039        0.162        0.161     0.000173     0.000995         2.14         4.43       0.0911        0.145        0.314        0.348

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     25   100       0.0127       0.0121     8.89e-05     0.000466        0.781         1.22       0.0661        0.104        0.202        0.238
     25   182        0.205        0.205     4.28e-05     9.16e-05            3            5       0.0529       0.0723        0.106        0.106


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              25 2494.106    0.001       0.0289     9.61e-05      0.00168       0.0306         0.88         1.88       0.0714        0.108        0.348        0.453
! Validation         25 2494.106    0.001        0.031     0.000104      0.00111       0.0322         1.03         1.92       0.0733        0.113        0.285        0.369
Wall time: 2494.1070553436875
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     26   100        0.061       0.0596       0.0001      0.00126         1.04          2.7       0.0698        0.111        0.331        0.393
     26   200      0.00323      0.00242     7.36e-05     0.000735        0.355        0.544        0.062       0.0948         0.27        0.299
     26   300       0.0581        0.057     8.12e-05     0.000987         1.23         2.64       0.0688       0.0996        0.332        0.347
     26   400      0.00429      0.00365     4.05e-05     0.000596        0.376        0.668       0.0533       0.0703        0.214         0.27
     26   500      0.00297      0.00162     7.19e-05      0.00127        0.337        0.445       0.0571       0.0937        0.347        0.394
     26   600       0.0277       0.0267     0.000108     0.000917         1.09          1.8       0.0757        0.115        0.322        0.334
     26   700       0.0862       0.0836     0.000112      0.00249         1.61         3.19        0.082        0.117        0.506        0.551
     26   800       0.0441       0.0415     6.12e-05      0.00254        0.991         2.25       0.0595       0.0865        0.472        0.557
     26   900       0.0219       0.0187     0.000135      0.00309        0.937         1.51        0.087        0.129        0.472        0.614
     26  1000       0.0815       0.0804     0.000111      0.00105         1.49         3.13       0.0717        0.116        0.267        0.359
     26  1100       0.0186        0.017     0.000157      0.00146        0.777         1.44        0.104        0.138        0.383        0.422
     26  1200       0.0232       0.0227     0.000128     0.000335        0.999         1.66       0.0886        0.125         0.16        0.202
     26  1300      0.00693      0.00445     6.58e-05      0.00241        0.466        0.737       0.0623       0.0896        0.452        0.543
     26  1400        0.138        0.137       0.0001     0.000689         1.89         4.09       0.0775        0.111        0.249         0.29
     26  1500      0.00146      0.00073     5.56e-05     0.000678        0.213        0.299       0.0509       0.0824        0.268        0.288
     26  1600       0.0313       0.0273     0.000109      0.00387        0.905         1.83       0.0791        0.115        0.587        0.687
     26  1700      0.00629      0.00514     5.13e-05       0.0011        0.576        0.792       0.0564       0.0791        0.353        0.366
     26  1800       0.0219       0.0213      5.7e-05     0.000544        0.984         1.61       0.0558       0.0834         0.24        0.258
     26  1900       0.0257       0.0245     5.21e-05      0.00105        0.845         1.73       0.0565       0.0798        0.305        0.359
     26  2000        0.124        0.119     0.000148      0.00488         1.89         3.81       0.0894        0.134        0.615        0.771
     26  2039       0.0793       0.0786     0.000113     0.000579         2.01          3.1        0.079        0.117        0.234        0.266

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     26   100      0.00723      0.00562     6.09e-05      0.00155        0.596        0.829       0.0552       0.0862        0.377        0.435
     26   182        0.151         0.15     4.05e-05     0.000712          2.6         4.28       0.0515       0.0703        0.295        0.295


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              26 2592.928    0.001       0.0289      9.4e-05      0.00192       0.0309         0.88         1.88        0.071        0.107        0.368        0.485
! Validation         26 2592.928    0.001       0.0269      7.9e-05      0.00179       0.0288        0.885          1.8       0.0629       0.0983        0.374        0.468
Wall time: 2592.9292424693704
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     27   100       0.0147       0.0142     5.23e-05     0.000422        0.733         1.32       0.0544       0.0799        0.199        0.227
     27   200       0.0189        0.018     7.05e-05     0.000858        0.655         1.48       0.0629       0.0928        0.285        0.324
     27   300       0.0208         0.02     9.94e-05     0.000703        0.818         1.56        0.074         0.11        0.277        0.293
     27   400         0.03       0.0296     8.38e-05      0.00025        0.867          1.9       0.0686        0.101        0.155        0.175
     27   500       0.0356       0.0339     8.55e-05      0.00158         1.05         2.03       0.0649        0.102        0.375        0.439
     27   600        0.113        0.111     9.73e-05      0.00132         2.16         3.68        0.072        0.109         0.37        0.401
     27   700       0.0598       0.0583     0.000118      0.00138         1.44         2.67       0.0795         0.12        0.313        0.411
     27   800       0.0136        0.011     0.000101      0.00252        0.593         1.16       0.0719        0.111        0.484        0.554
     27   900       0.0312         0.03     6.66e-05      0.00117         1.01         1.91       0.0605       0.0901        0.318        0.378
     27  1000       0.0048      0.00349     9.78e-05      0.00121        0.392        0.652       0.0708        0.109        0.361        0.384
     27  1100       0.0661        0.063     0.000139      0.00292         1.55         2.77       0.0886         0.13         0.55        0.597
     27  1200      0.00767      0.00557     7.03e-05      0.00202        0.488        0.825        0.067       0.0926        0.453        0.497
     27  1300       0.0479       0.0459     9.73e-05      0.00191        0.927         2.37       0.0733        0.109        0.442        0.482
     27  1400      0.00219      0.00115     6.07e-05     0.000974        0.262        0.375       0.0583        0.086        0.327        0.345
     27  1500      0.00919      0.00746     7.58e-05      0.00165         0.51        0.954       0.0625       0.0962        0.354        0.449
     27  1600       0.0132       0.0123     0.000143     0.000723        0.615         1.23       0.0786        0.132        0.229        0.297
     27  1700      0.00383      0.00346     0.000122     0.000244         0.48         0.65       0.0785        0.122        0.111        0.173
     27  1800      0.00489      0.00382     0.000118     0.000952        0.449        0.683       0.0847         0.12        0.291        0.341
     27  1900       0.0354       0.0326     0.000105       0.0027         1.32         1.99       0.0791        0.113        0.546        0.575
     27  2000       0.0201       0.0199     6.35e-05     0.000119        0.842         1.56       0.0608       0.0881        0.088        0.121
     27  2039       0.0219       0.0203     7.11e-05      0.00159         1.01         1.57       0.0668       0.0932        0.396         0.44

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     27   100      0.00946      0.00771     5.72e-05      0.00169        0.589         0.97       0.0577       0.0835        0.399        0.454
     27   182        0.153        0.153     3.99e-05     5.29e-05          2.6         4.32       0.0511       0.0698       0.0804       0.0804


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              27 2691.784    0.001       0.0287     9.61e-05      0.00173       0.0305        0.875         1.87       0.0716        0.108        0.351        0.459
! Validation         27 2691.784    0.001       0.0261     7.89e-05      0.00259       0.0288        0.844         1.77       0.0658       0.0982        0.469        0.564
Wall time: 2691.7846239879727
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     28   100       0.0523       0.0434     8.48e-05       0.0088         1.24          2.3       0.0709        0.102        0.837         1.04
     28   200        0.156        0.154     0.000108      0.00138         2.14         4.34       0.0796        0.115        0.339         0.41
     28   300       0.0181       0.0172     0.000165     0.000678        0.909         1.45       0.0884        0.142        0.236        0.288
     28   400       0.0178       0.0164     6.35e-05      0.00136        0.605         1.42       0.0591       0.0881        0.349        0.408
     28   500      0.00796      0.00587     0.000104      0.00199        0.545        0.846       0.0751        0.113        0.372        0.492
     28   600       0.0098      0.00758     0.000107      0.00211        0.646        0.962       0.0788        0.114        0.501        0.508
     28   700       0.0506       0.0496       0.0001     0.000883         1.12         2.46       0.0756        0.111        0.301        0.328
     28   800       0.0057      0.00464     0.000141     0.000917        0.479        0.753        0.085        0.131        0.305        0.335
     28   900       0.0852       0.0849     0.000117     0.000141         1.91         3.22       0.0774         0.12         0.13        0.131
     28  1000       0.0133      0.00959     0.000113      0.00356        0.687         1.08       0.0802        0.117        0.549        0.659
     28  1100        0.052       0.0518     0.000128       0.0001         1.41         2.51       0.0758        0.125        0.101        0.111
     28  1200       0.0106      0.00872     5.06e-05      0.00178        0.658         1.03       0.0519       0.0786        0.378        0.467
     28  1300       0.0264       0.0254     5.65e-05     0.000985        0.866         1.76       0.0591       0.0831        0.298        0.347
     28  1400       0.0194       0.0167     7.42e-05      0.00259        0.984         1.43       0.0667       0.0952        0.431        0.562
     28  1500      0.00299      0.00213     6.02e-05     0.000796        0.336         0.51       0.0508       0.0857        0.271        0.312
     28  1600       0.0173       0.0172     8.63e-05     7.25e-05        0.687         1.45       0.0713        0.103       0.0876       0.0941
     28  1700        0.055       0.0534     0.000108      0.00143         1.38         2.55       0.0753        0.115        0.401        0.417
     28  1800       0.0204         0.02     7.85e-05     0.000285        0.897         1.56        0.066       0.0979        0.157        0.187
     28  1900      0.00369      0.00299     0.000114     0.000588        0.355        0.604       0.0656        0.118        0.256        0.268
     28  2000       0.0187       0.0185     5.51e-05     9.24e-05        0.672          1.5       0.0526        0.082       0.0787        0.106
     28  2039       0.0409       0.0391     5.52e-05      0.00178          1.2         2.18       0.0572       0.0821        0.422        0.466

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     28   100      0.00939      0.00883     7.44e-05     0.000485          0.7         1.04       0.0653       0.0953        0.198        0.243
     28   182        0.146        0.146     4.85e-05     9.65e-05         2.54         4.22       0.0582       0.0769        0.109        0.109


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              28 2790.565    0.001       0.0286     9.68e-05      0.00162       0.0303        0.873         1.87       0.0721        0.109        0.337        0.445
! Validation         28 2790.565    0.001       0.0256     9.47e-05     0.000914       0.0266        0.866         1.75       0.0726        0.108        0.258        0.335
Wall time: 2790.566424280405
! Best model       28    0.027
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     29   100       0.0178       0.0158     7.62e-05      0.00188        0.811         1.39       0.0705       0.0964        0.395        0.478
     29   200       0.0164       0.0154     8.73e-05     0.000918         0.82         1.37       0.0707        0.103        0.292        0.335
     29   300       0.0421       0.0411     7.83e-05      0.00091          1.2         2.24       0.0634       0.0978        0.292        0.333
     29   400         0.01      0.00801     3.79e-05      0.00197        0.607        0.989       0.0491       0.0681        0.458         0.49
     29   500       0.0532       0.0521     7.66e-05     0.000971         1.26         2.52       0.0658       0.0967         0.31        0.344
     29   600       0.0962       0.0949     0.000101      0.00121         1.53          3.4       0.0712        0.111        0.312        0.384
     29   700       0.0359       0.0342     8.88e-05      0.00161        0.928         2.04        0.063        0.104        0.419        0.444
     29   800        0.059       0.0574     0.000159      0.00145         1.24         2.65       0.0954        0.139        0.334        0.421
     29   900       0.0142       0.0135     9.75e-05     0.000641        0.776         1.28       0.0673        0.109         0.24         0.28
     29  1000       0.0718       0.0692     0.000107      0.00253         1.38         2.91       0.0744        0.114        0.513        0.556
     29  1100       0.0584       0.0557     0.000121      0.00255          1.4         2.61        0.083        0.121        0.505        0.558
     29  1200      0.00301     0.000657     5.38e-05       0.0023        0.219        0.283       0.0502        0.081        0.478         0.53
     29  1300      0.00489      0.00294     0.000129      0.00182        0.399        0.599       0.0775        0.125        0.445        0.471
     29  1400       0.0218       0.0214     9.94e-05     0.000341         1.08         1.62       0.0688         0.11        0.141        0.204
     29  1500       0.0522       0.0514     0.000174      0.00064         1.49          2.5        0.086        0.146        0.194         0.28
     29  1600      0.00973      0.00925     8.05e-05     0.000401        0.765         1.06       0.0663       0.0991        0.177        0.221
     29  1700       0.0518       0.0503     0.000115      0.00142         1.28         2.48       0.0805        0.119        0.369        0.416
     29  1800        0.101        0.099     0.000172      0.00162         1.87         3.48       0.0972        0.145        0.363        0.444
     29  1900       0.0305        0.029     6.26e-05      0.00144        0.941         1.88       0.0581       0.0874        0.398        0.419
     29  2000       0.0227       0.0192     8.46e-05      0.00338        0.917         1.53       0.0695        0.102        0.585        0.643
     29  2039      0.00609      0.00382     0.000105      0.00216        0.461        0.683       0.0799        0.113        0.365        0.514

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     29   100      0.00792      0.00591     8.41e-05      0.00193        0.566        0.849       0.0688        0.101        0.429        0.485
     29   182        0.109        0.108     5.35e-05     0.000807         2.21         3.63       0.0615       0.0808        0.314        0.314


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              29 2889.531    0.001       0.0288     9.67e-05       0.0016       0.0305        0.874         1.87       0.0714        0.109        0.337        0.441
! Validation         29 2889.531    0.001       0.0259     0.000101      0.00199        0.028        0.828         1.77       0.0758        0.111        0.402        0.494
Wall time: 2889.531605243683
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     30   100      0.00272      0.00202     4.91e-05     0.000653        0.332        0.496        0.054       0.0774        0.239        0.282
     30   200      0.00738      0.00594      8.1e-05      0.00136        0.504        0.852       0.0666       0.0994        0.339        0.407
     30   300      0.00378      0.00174     0.000102      0.00194        0.326        0.461       0.0713        0.112        0.407        0.487
     30   400       0.0208       0.0202     9.45e-05      0.00051         0.76         1.57        0.075        0.107        0.242         0.25
     30   500       0.0483       0.0473      0.00013     0.000861         1.23          2.4       0.0863        0.126        0.301        0.324
     30   600      0.00451        0.003     7.84e-05      0.00143        0.433        0.605       0.0624       0.0978        0.412        0.418
     30   700       0.0139      0.00922     0.000185      0.00448        0.644         1.06        0.103         0.15        0.583         0.74
     30   800      0.00781      0.00736     8.87e-05      0.00036        0.657        0.948       0.0707        0.104        0.199         0.21
     30   900      0.00246      0.00119     0.000133      0.00113        0.299        0.382        0.086        0.128        0.298        0.372
     30  1000       0.0101      0.00753     0.000103      0.00249        0.676        0.959       0.0754        0.112        0.538        0.551
     30  1100      0.00481      0.00395     4.86e-05     0.000808        0.426        0.695       0.0504        0.077        0.271        0.314
     30  1200       0.0163        0.012      0.00018      0.00416        0.645         1.21        0.104        0.148        0.593        0.712
     30  1300       0.0134       0.0126     0.000145     0.000641        0.842         1.24       0.0864        0.133        0.207         0.28
     30  1400      0.00788      0.00667     0.000113      0.00109        0.568        0.903       0.0771        0.117        0.305        0.364
     30  1500       0.0898       0.0891     0.000121     0.000654         1.81          3.3       0.0787        0.122        0.224        0.283
     30  1600        0.013       0.0127     5.34e-05     0.000314        0.631         1.24       0.0553       0.0807        0.139        0.196
     30  1700       0.0139       0.0125     8.44e-05       0.0013        0.693         1.23       0.0611        0.101        0.336        0.399
     30  1800      0.00844       0.0066     7.93e-05      0.00175        0.642        0.898       0.0675       0.0984         0.36        0.463
     30  1900       0.0604       0.0596     7.25e-05     0.000674         1.29          2.7        0.067       0.0941        0.259        0.287
     30  2000       0.0379       0.0367     9.39e-05      0.00109          1.1         2.12       0.0649        0.107        0.309        0.365
     30  2039      0.00542      0.00523     0.000158     3.76e-05        0.519        0.799        0.083        0.139       0.0558       0.0677

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     30   100      0.00964      0.00892      9.3e-05     0.000634        0.707         1.04       0.0728        0.107        0.225        0.278
     30   182        0.129        0.129      4.8e-05     0.000447         2.42         3.96       0.0575       0.0765        0.234        0.234


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              30 2988.346    0.001       0.0286     9.82e-05      0.00148       0.0302        0.875         1.87       0.0723        0.109        0.328        0.426
! Validation         30 2988.346    0.001       0.0279     0.000116      0.00102        0.029        0.917         1.83       0.0804        0.119         0.26        0.354
Wall time: 2988.346793010831
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     31   100      0.00948      0.00733     9.98e-05      0.00205        0.597        0.946       0.0771         0.11        0.422          0.5
     31   200       0.0113       0.0104     6.53e-05     0.000831        0.542         1.13       0.0615       0.0893        0.242        0.319
     31   300       0.0442       0.0426     9.63e-05      0.00155         0.88         2.28       0.0777        0.108        0.411        0.435
     31   400       0.0148       0.0143     6.48e-05     0.000464        0.799         1.32       0.0632        0.089        0.233        0.238
     31   500       0.0229       0.0207     0.000119       0.0021        0.952         1.59       0.0804         0.12        0.402        0.506
     31   600       0.0175       0.0169     7.11e-05     0.000566        0.793         1.44       0.0647       0.0931        0.239        0.263
     31   700       0.0331       0.0297     6.13e-05      0.00335         1.03          1.9       0.0555       0.0865        0.555        0.639
     31   800      0.00686      0.00617     0.000101      0.00059        0.547        0.868       0.0722        0.111        0.256        0.268
     31   900       0.0354       0.0348     8.66e-05     0.000474        0.989         2.06       0.0666        0.103        0.192        0.241
     31  1000       0.0519       0.0516     9.31e-05       0.0002         1.22         2.51       0.0724        0.107        0.137        0.156
     31  1100       0.0485       0.0482     9.16e-05     0.000213         1.38         2.43       0.0692        0.106        0.139        0.161
     31  1200      0.00276      0.00184     3.48e-05     0.000885        0.328        0.474       0.0445       0.0652        0.231        0.329
     31  1300       0.0257       0.0213     7.47e-05      0.00435        0.863         1.61       0.0629       0.0955        0.558        0.729
     31  1400       0.0183       0.0179     0.000111     0.000283        0.923         1.48       0.0754        0.116         0.15        0.186
     31  1500      0.00862       0.0077     4.95e-05      0.00087        0.645         0.97       0.0534       0.0778        0.255        0.326
     31  1600       0.0294       0.0259     8.98e-05      0.00346         1.07         1.78       0.0722        0.105        0.536        0.649
     31  1700       0.0133       0.0118     0.000105      0.00144        0.566          1.2       0.0741        0.113        0.386        0.419
     31  1800       0.0682       0.0673      8.6e-05     0.000873         1.46         2.87       0.0706        0.102          0.3        0.326
     31  1900       0.0368       0.0365     9.53e-05     0.000221        0.978         2.11       0.0745        0.108        0.137        0.164
     31  2000       0.0372       0.0367     0.000168     0.000307          1.2         2.12       0.0859        0.143        0.171        0.193
     31  2039        0.072       0.0702      0.00013      0.00167         1.51         2.93       0.0846        0.126        0.342        0.451

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     31   100         0.02        0.012     0.000122       0.0079        0.772         1.21       0.0818        0.122        0.866        0.982
     31   182        0.151        0.151     5.45e-05     1.27e-05         2.56         4.29       0.0613       0.0816       0.0394       0.0394


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              31 3087.188    0.001       0.0286     9.83e-05      0.00155       0.0302        0.873         1.87       0.0723         0.11        0.334        0.435
! Validation         31 3087.188    0.001       0.0278     0.000138      0.00559       0.0336        0.935         1.83        0.087         0.13        0.679        0.828
Wall time: 3087.1888581886888
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     32   100      0.00507      0.00327     8.44e-05      0.00171        0.494        0.632       0.0608        0.102         0.34        0.457
     32   200       0.0573       0.0565     8.93e-05     0.000764         1.13         2.63       0.0681        0.104        0.233        0.305
     32   300      0.00331      0.00142     6.11e-05      0.00184        0.315        0.416       0.0586       0.0863        0.371        0.473
     32   400      0.00327      0.00183     4.12e-05      0.00141         0.35        0.472       0.0496       0.0709         0.36        0.414
     32   500       0.0409       0.0404     9.69e-05     0.000411         1.11         2.22       0.0729        0.109        0.179        0.224
     32   600       0.0773       0.0755     0.000125      0.00171         1.59         3.04       0.0824        0.124        0.375        0.457
     32   700       0.0489       0.0485     0.000131     0.000194         1.31         2.43       0.0786        0.126        0.101        0.154
     32   800        0.031       0.0289     7.89e-05      0.00202        0.909         1.88       0.0675       0.0981        0.449        0.496
     32   900      0.00596      0.00565     7.99e-05     0.000232        0.525         0.83       0.0646       0.0988        0.118        0.168
     32  1000      0.00246     0.000988     8.95e-05      0.00138        0.234        0.347       0.0691        0.105        0.331        0.411
     32  1100       0.0195        0.019     0.000128     0.000358        0.782         1.52       0.0813        0.125        0.196        0.209
     32  1200      0.00183      0.00167     5.63e-05     0.000106        0.366        0.452       0.0573       0.0829        0.103        0.114
     32  1300       0.0178       0.0173     7.22e-05     0.000354        0.741         1.46       0.0621       0.0939        0.202        0.208
     32  1400       0.0578       0.0556     7.51e-05      0.00208          1.3         2.61        0.067       0.0957        0.424        0.504
     32  1500      0.00912      0.00853     3.79e-05      0.00056        0.625         1.02       0.0484       0.0681        0.203        0.261
     32  1600       0.0112       0.0104     9.33e-05     0.000681        0.763         1.13       0.0695        0.107        0.243        0.288
     32  1700       0.0366       0.0342     9.79e-05      0.00231         1.06         2.04       0.0663        0.109        0.498        0.531
     32  1800      0.00459      0.00141     8.91e-05      0.00309        0.237        0.415       0.0651        0.104        0.505        0.614
     32  1900       0.0125       0.0116     0.000109     0.000778        0.703         1.19        0.077        0.115         0.27        0.308
     32  2000       0.0189       0.0157     0.000101      0.00313        0.724         1.38       0.0779        0.111        0.397        0.618
     32  2039        0.005      0.00434     9.06e-05     0.000571        0.486        0.728       0.0722        0.105        0.238        0.264

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     32   100        0.015       0.0141     8.72e-05     0.000792        0.807         1.31       0.0656        0.103        0.292        0.311
     32   182        0.159        0.156     3.64e-05      0.00334         2.59         4.36       0.0484       0.0666        0.638        0.638


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              32 3185.953    0.001       0.0285     0.000101      0.00154       0.0301        0.871         1.87       0.0732        0.111        0.334        0.434
! Validation         32 3185.953    0.001       0.0285     9.97e-05       0.0012       0.0298        0.948         1.85       0.0708         0.11        0.297        0.381
Wall time: 3185.9542192593217
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     33   100       0.0114       0.0111     0.000114     0.000135        0.638         1.16       0.0804        0.118         0.11        0.129
     33   200       0.0183       0.0162     0.000105      0.00195        0.866         1.41       0.0773        0.113        0.424        0.488
     33   300      0.00966      0.00862     0.000124     0.000917        0.703         1.03       0.0854        0.123        0.286        0.335
     33   400       0.0104      0.00669     9.72e-05      0.00359        0.603        0.904       0.0764        0.109        0.501        0.662
     33   500       0.0289       0.0276     0.000107       0.0012         1.12         1.83       0.0812        0.114        0.309        0.383
     33   600      0.00858      0.00738     0.000155      0.00104        0.619        0.949        0.089        0.138        0.335        0.357
     33   700       0.0533       0.0514      0.00012      0.00171         1.37         2.51       0.0764        0.121         0.41        0.457
     33   800      0.00657      0.00374     0.000103      0.00272        0.492        0.676       0.0731        0.112         0.39        0.577
     33   900       0.0343       0.0337     8.29e-05     0.000543         1.03         2.03       0.0662        0.101         0.18        0.257
     33  1000      0.00821      0.00762     8.03e-05     0.000511        0.568        0.965       0.0673        0.099        0.238         0.25
     33  1100       0.0341       0.0314      0.00012      0.00258         1.08         1.96       0.0823        0.121         0.54        0.562
     33  1200        0.014       0.0127     9.99e-05      0.00119        0.831         1.24       0.0715         0.11        0.328        0.382
     33  1300      0.00714      0.00678     0.000147     0.000212        0.624         0.91       0.0913        0.134        0.151        0.161
     33  1400       0.0828       0.0822     0.000112     0.000451         1.13         3.17       0.0733        0.117        0.194        0.235
     33  1500       0.0304       0.0288     7.95e-05      0.00155        0.952         1.87       0.0645       0.0985        0.342        0.435
     33  1600       0.0441       0.0427     0.000111      0.00133         1.26         2.28       0.0681        0.116        0.356        0.403
     33  1700        0.023       0.0213     6.87e-05      0.00166        0.865         1.61       0.0656       0.0916        0.358         0.45
     33  1800       0.0253       0.0246     0.000105     0.000497         0.95         1.73       0.0683        0.113        0.163        0.246
     33  1900       0.0144       0.0136     7.65e-05     0.000719        0.704         1.29       0.0609       0.0967        0.287        0.296
     33  2000        0.389        0.385     8.34e-05      0.00388         2.34         6.85       0.0659        0.101        0.638        0.689
     33  2039      0.00336      0.00326      8.8e-05     1.67e-05         0.52         0.63       0.0678        0.104       0.0447       0.0452

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     33   100      0.00562      0.00465     7.85e-05     0.000882        0.547        0.754        0.066       0.0979        0.289        0.328
     33   182        0.144        0.143     4.81e-05      0.00162         2.52         4.17        0.058       0.0766        0.445        0.445


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              33 3284.901    0.001       0.0284     0.000102      0.00142       0.0299        0.871         1.86       0.0735        0.112        0.324        0.416
! Validation         33 3284.901    0.001       0.0249     9.75e-05      0.00191       0.0269        0.805         1.73       0.0736        0.109        0.364        0.483
Wall time: 3284.9016026332974
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     34   100       0.0221       0.0214     5.45e-05     0.000666         1.01         1.62       0.0599       0.0815        0.233        0.285
     34   200       0.0636       0.0612     0.000114       0.0023         1.49         2.73       0.0792        0.118        0.375         0.53
     34   300      0.00517      0.00457     7.69e-05     0.000519        0.476        0.747       0.0619       0.0969        0.237        0.252
     34   400       0.0151       0.0136     0.000101      0.00135        0.626         1.29       0.0788        0.111        0.342        0.405
     34   500       0.0308       0.0304     0.000155     0.000216         1.14         1.93       0.0893        0.137        0.128        0.162
     34   600      0.00885      0.00673     9.85e-05      0.00203        0.608        0.906       0.0725         0.11        0.441        0.497
     34   700       0.0592        0.057     0.000102      0.00207         1.33         2.64       0.0786        0.111        0.472        0.503
     34   800        0.126        0.125     0.000115     0.000414         2.07         3.91       0.0748        0.118        0.203        0.225
     34   900      0.00305      0.00242     5.46e-05     0.000577        0.372        0.544       0.0547       0.0817        0.208        0.265
     34  1000      0.00567      0.00513     0.000132     0.000409        0.508        0.791       0.0817        0.127        0.209        0.223
     34  1100       0.0228        0.021     0.000106      0.00171        0.921          1.6       0.0745        0.114        0.338        0.457
     34  1200      0.00576      0.00393     0.000189      0.00164        0.517        0.693        0.103        0.152        0.398        0.447
     34  1300       0.0993       0.0985     8.88e-05     0.000764         1.71         3.47        0.067        0.104        0.252        0.305
     34  1400       0.0613       0.0596     0.000184      0.00148          1.5          2.7        0.102         0.15        0.351        0.425
     34  1500      0.00629      0.00487     9.06e-05      0.00134        0.569        0.771       0.0694        0.105        0.333        0.404
     34  1600       0.0315       0.0304     0.000157      0.00094        0.908         1.93       0.0718        0.139        0.291        0.339
     34  1700      0.00143      0.00128     3.48e-05     0.000114        0.272        0.396       0.0468       0.0652       0.0903        0.118
     34  1800       0.0119       0.0117     7.53e-05     0.000133        0.583          1.2       0.0701       0.0959        0.101        0.128
     34  1900       0.0104      0.00896     9.33e-05      0.00133        0.695         1.05       0.0679        0.107        0.337        0.403
     34  2000       0.0145       0.0134     9.44e-05      0.00101        0.751         1.28        0.072        0.107        0.267        0.351
     34  2039       0.0061      0.00537     0.000109     0.000621        0.513         0.81       0.0823        0.115        0.235        0.275

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     34   100      0.00997      0.00812     8.28e-05      0.00177        0.665        0.996       0.0718        0.101        0.335        0.464
     34   182        0.114        0.112     5.33e-05      0.00108          2.2         3.71       0.0598       0.0807        0.362        0.362


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              34 3383.724    0.001       0.0283     0.000104      0.00135       0.0298        0.874         1.86       0.0735        0.113        0.313        0.406
! Validation         34 3383.724    0.001       0.0265     0.000104       0.0012       0.0278        0.888         1.79       0.0788        0.113        0.288        0.382
Wall time: 3383.7253721803427
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     35   100      0.00435        0.001     8.26e-05      0.00326        0.249         0.35       0.0668          0.1        0.576        0.631
     35   200      0.00866      0.00706     7.74e-05      0.00153        0.506        0.928        0.067       0.0972        0.378        0.432
     35   300       0.0311       0.0305     0.000112     0.000464         1.12         1.93       0.0747        0.117        0.211        0.238
     35   400       0.0371       0.0321     8.39e-05      0.00494         1.05         1.98       0.0708        0.101        0.506        0.776
     35   500      0.00193      0.00167     6.77e-05     0.000191        0.302        0.452       0.0613       0.0909       0.0879        0.153
     35   600       0.0107       0.0103     8.51e-05     0.000375        0.642         1.12        0.065        0.102        0.206        0.214
     35   700       0.0199       0.0197      7.8e-05     0.000177         0.69         1.55       0.0623       0.0976        0.134        0.147
     35   800      0.00474      0.00388     5.83e-05     0.000797        0.478        0.688       0.0535       0.0843        0.267        0.312
     35   900        0.081       0.0799     8.97e-05        0.001          1.5         3.12        0.067        0.105        0.303         0.35
     35  1000       0.0164       0.0152     0.000121      0.00109        0.686         1.36       0.0843        0.121        0.325        0.365
     35  1100       0.0376       0.0361     8.74e-05      0.00148          1.2          2.1       0.0723        0.103        0.341        0.425
     35  1200       0.0148       0.0145     8.41e-05     0.000251        0.789         1.33       0.0705        0.101        0.134        0.175
     35  1300       0.0922         0.09     0.000118      0.00207         1.34         3.31       0.0708         0.12        0.402        0.503
     35  1400       0.0306       0.0265     0.000192      0.00387        0.932          1.8       0.0959        0.153        0.604        0.688
     35  1500       0.0785       0.0752     7.53e-05      0.00325         1.62         3.03       0.0647       0.0959        0.575        0.629
     35  1600       0.0182       0.0164     0.000103      0.00174         0.83         1.41       0.0686        0.112        0.392        0.461
     35  1700       0.0125       0.0104     9.76e-05      0.00201        0.578         1.12       0.0754        0.109        0.471        0.496
     35  1800       0.0907       0.0897      0.00013     0.000875         1.89         3.31        0.087        0.126         0.28        0.327
     35  1900       0.0466       0.0401     0.000122      0.00638         1.01         2.21       0.0834        0.122        0.796        0.883
     35  2000      0.00534      0.00348     7.58e-05      0.00178        0.438        0.652       0.0663       0.0962        0.339        0.466
     35  2039       0.0899       0.0892     5.01e-05     0.000661         1.54          3.3       0.0528       0.0782        0.283        0.284

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     35   100      0.00898      0.00615     8.69e-05      0.00273        0.567        0.867       0.0646        0.103        0.428        0.578
     35   182        0.161         0.16      3.7e-05     0.000816         2.71         4.43       0.0502       0.0672        0.316        0.316


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              35 3482.463    0.001       0.0284     0.000103      0.00137       0.0298         0.87         1.86       0.0736        0.112        0.316        0.409
! Validation         35 3482.463    0.001        0.026     9.84e-05      0.00169       0.0277         0.84         1.76         0.07         0.11        0.355        0.454
Wall time: 3482.4645587056875
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     36   100       0.0268       0.0256     9.29e-05      0.00105         1.01         1.77       0.0789        0.106        0.281        0.358
     36   200        0.012       0.0073        9e-05      0.00462        0.608        0.944        0.079        0.105        0.696        0.751
     36   300       0.0315       0.0287     8.18e-05      0.00272         1.07         1.87       0.0644       0.0999        0.565        0.576
     36   400       0.0359       0.0334     7.15e-05      0.00241         0.85         2.02       0.0659       0.0934        0.332        0.543
     36   500       0.0248       0.0244     8.92e-05     0.000314         1.06         1.73       0.0711        0.104        0.162        0.196
     36   600      0.00711      0.00547     0.000132      0.00151         0.55        0.817       0.0881        0.127        0.343        0.429
     36   700       0.0813       0.0797     0.000173      0.00137         1.53         3.12       0.0957        0.145        0.349         0.41
     36   800       0.0597       0.0582     0.000165      0.00127         1.42         2.67       0.0997        0.142        0.288        0.394
     36   900        0.034       0.0333     8.81e-05     0.000607          1.1         2.02       0.0715        0.104        0.206        0.272
     36  1000       0.0656       0.0641     0.000137      0.00133         1.66          2.8       0.0908        0.129        0.295        0.403
     36  1100      0.00401      0.00272     0.000101      0.00119        0.443        0.576       0.0774        0.111        0.296        0.382
     36  1200       0.0435       0.0417     0.000125       0.0017         1.27         2.26       0.0846        0.123        0.391        0.455
     36  1300       0.0371       0.0357     9.92e-05       0.0013         1.17         2.09       0.0763         0.11        0.336        0.398
     36  1400       0.0323       0.0266     0.000137      0.00556         1.12          1.8       0.0853        0.129        0.762        0.824
     36  1500       0.0432       0.0427     0.000133     0.000283         1.11         2.28       0.0845        0.127        0.182        0.186
     36  1600       0.0233       0.0219     9.68e-05      0.00137        0.822         1.63       0.0698        0.109          0.4        0.409
     36  1700      0.00408      0.00217     9.66e-05      0.00181        0.319        0.515       0.0696        0.109        0.275         0.47
     36  1800       0.0442       0.0429     0.000123      0.00127         1.29         2.29       0.0846        0.123        0.394        0.394
     36  1900       0.0105      0.00957     5.98e-05     0.000845        0.617         1.08       0.0553       0.0854         0.21        0.321
     36  2000        0.033       0.0315     0.000101      0.00142            1         1.96       0.0728        0.111        0.363        0.416
     36  2039       0.0233       0.0216     6.89e-05      0.00163        0.985         1.62       0.0642       0.0917        0.435        0.447

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     36   100      0.00615      0.00489     7.76e-05      0.00118        0.538        0.773       0.0631       0.0973        0.317         0.38
     36   182        0.153        0.153     3.71e-05     9.02e-06          2.6         4.32        0.051       0.0673       0.0332       0.0332


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              36 3581.296    0.001       0.0283     0.000106      0.00137       0.0298        0.868         1.86       0.0748        0.114        0.315        0.409
! Validation         36 3581.296    0.001       0.0261     9.08e-05      0.00131       0.0275        0.847         1.77       0.0688        0.105        0.318        0.401
Wall time: 3581.296707689762
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     37   100       0.0151       0.0145     0.000132     0.000392        0.627         1.33       0.0811        0.127        0.183        0.219
     37   200       0.0996       0.0979     8.41e-05       0.0016         1.64         3.46       0.0672        0.101        0.388        0.441
     37   300       0.0443       0.0426     0.000145      0.00151         1.27         2.28         0.08        0.133        0.398        0.429
     37   400       0.0291       0.0263     8.14e-05      0.00271         1.01         1.79       0.0708       0.0997        0.492        0.575
     37   500       0.0131       0.0127     8.71e-05     0.000291        0.617         1.25       0.0697        0.103        0.177        0.189
     37   600       0.0531       0.0497     7.31e-05      0.00331         1.32         2.46       0.0661       0.0944        0.454        0.635
     37   700      0.00612      0.00292      5.9e-05      0.00314        0.364        0.598        0.057       0.0849        0.584        0.619
     37   800       0.0145       0.0138     0.000123     0.000619        0.596          1.3       0.0817        0.123        0.227        0.275
     37   900       0.0712       0.0698     8.39e-05      0.00132         1.34         2.92       0.0698        0.101         0.36        0.402
     37  1000      0.00151      0.00118     8.17e-05     0.000245        0.292         0.38       0.0606       0.0998        0.107        0.173
     37  1100      0.00157     0.000806     6.24e-05     0.000701        0.211        0.314       0.0627       0.0873        0.259        0.293
     37  1200      0.00171      0.00124     6.13e-05     0.000409        0.291        0.389       0.0549       0.0865        0.216        0.223
     37  1300       0.0269       0.0239      8.8e-05      0.00293         1.01         1.71       0.0746        0.104        0.476        0.598
     37  1400       0.0238       0.0156     0.000124       0.0081         0.76         1.38        0.081        0.123        0.882        0.994
     37  1500       0.0427       0.0422     9.75e-05     0.000406        0.838         2.27       0.0701        0.109        0.192        0.223
     37  1600        0.041       0.0404      0.00012     0.000489         1.07         2.22       0.0781        0.121        0.163        0.244
     37  1700          0.1       0.0992     9.26e-05      0.00082         1.47         3.48       0.0714        0.106        0.271        0.316
     37  1800      0.00657      0.00501     8.64e-05      0.00148        0.528        0.782       0.0715        0.103          0.4        0.425
     37  1900         0.05       0.0491     0.000113     0.000785         1.03         2.45       0.0801        0.117        0.241         0.31
     37  2000       0.0142        0.012     0.000128      0.00204        0.844         1.21       0.0863        0.125        0.402        0.499
     37  2039      0.00298      0.00273     5.93e-05     0.000189        0.347        0.577       0.0542       0.0851        0.136        0.152

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     37   100      0.00488      0.00381     6.88e-05     0.000996         0.48        0.682       0.0592       0.0917        0.305        0.349
     37   182        0.149        0.149     3.38e-05     0.000121         2.57         4.26       0.0476       0.0642        0.122        0.122


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              37 3680.228    0.001       0.0283     0.000104      0.00123       0.0296         0.87         1.86       0.0739        0.113        0.297        0.388
! Validation         37 3680.228    0.001       0.0249     8.47e-05      0.00116       0.0261        0.788         1.72       0.0664        0.102        0.304        0.377
Wall time: 3680.229231528938
! Best model       37    0.026
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     38   100      0.00898      0.00766     9.79e-05      0.00122         0.66        0.967       0.0794        0.109        0.329        0.386
     38   200      0.00166      0.00117     5.89e-05     0.000429        0.282        0.378       0.0549       0.0848        0.165        0.229
     38   300       0.0888       0.0864      0.00015       0.0023         1.49         3.25       0.0901        0.135        0.378         0.53
     38   400       0.0167       0.0163     9.36e-05     0.000344        0.861         1.41       0.0722        0.107        0.176        0.205
     38   500       0.0142       0.0118     5.76e-05      0.00236        0.462          1.2        0.059       0.0839        0.475        0.537
     38   600        0.035       0.0337      0.00016      0.00117         1.16         2.03       0.0927         0.14        0.246        0.379
     38   700       0.0181       0.0159     0.000111      0.00211        0.704         1.39       0.0759        0.117        0.448        0.508
     38   800       0.0307       0.0295     0.000109      0.00102         1.08          1.9       0.0779        0.115        0.285        0.353
     38   900       0.0411       0.0386     0.000108      0.00237         1.13         2.17        0.078        0.115        0.464        0.537
     38  1000       0.0147       0.0143     6.58e-05     0.000271         0.77         1.32       0.0636       0.0896        0.158        0.182
     38  1100       0.0294       0.0228     0.000202      0.00637         1.14         1.67        0.108        0.157        0.759        0.882
     38  1200      0.00747      0.00649     6.43e-05     0.000907        0.512         0.89       0.0562       0.0886        0.303        0.333
     38  1300         0.03       0.0284     0.000116      0.00143        0.861         1.86       0.0687        0.119        0.377        0.418
     38  1400       0.0344       0.0298     0.000173      0.00437         1.04         1.91        0.095        0.146        0.594        0.731
     38  1500       0.0464       0.0447       0.0001      0.00154         1.21         2.34       0.0713        0.111        0.361        0.434
     38  1600       0.0519       0.0513     8.12e-05     0.000465         1.28          2.5       0.0689       0.0996        0.202        0.238
     38  1700       0.0631       0.0623     9.53e-05     0.000671         1.39         2.76       0.0693        0.108        0.238        0.286
     38  1800       0.0612       0.0568     0.000104      0.00429         1.46         2.63       0.0748        0.113        0.714        0.724
     38  1900      0.00326      0.00251     5.69e-05     0.000699        0.353        0.553       0.0541       0.0833        0.242        0.292
     38  2000        0.078       0.0776     8.01e-05     0.000368         1.65         3.08       0.0677       0.0989        0.195        0.212
     38  2039       0.0102      0.00922      6.7e-05     0.000916        0.683         1.06        0.062       0.0904         0.33        0.334

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     38   100       0.0124        0.011     0.000125      0.00128        0.696         1.16       0.0816        0.124        0.384        0.395
     38   182        0.135        0.134     4.71e-05     0.000702         2.44         4.05       0.0551       0.0759        0.293        0.293


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              38 3779.177    0.001       0.0282     0.000105      0.00126       0.0296        0.869         1.86       0.0744        0.113        0.303        0.391
! Validation         38 3779.177    0.001       0.0279     0.000125     0.000921       0.0289        0.943         1.83       0.0825        0.124        0.261        0.335
Wall time: 3779.1785153076053
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     39   100       0.0126        0.009     7.74e-05      0.00349        0.598         1.05       0.0668       0.0972        0.564        0.653
     39   200       0.0412       0.0398     0.000137      0.00126         1.11          2.2       0.0858        0.129        0.365        0.392
     39   300       0.0268       0.0264     0.000153     0.000293        0.916         1.79       0.0884        0.137         0.17        0.189
     39   400       0.0102      0.00957     7.86e-05      0.00056        0.657         1.08       0.0661       0.0979        0.241        0.261
     39   500      0.00507      0.00424     8.78e-05     0.000742        0.556         0.72       0.0726        0.104        0.266        0.301
     39   600      0.00171      0.00125     6.38e-05     0.000397        0.279         0.39       0.0572       0.0882        0.191         0.22
     39   700       0.0241       0.0231     8.89e-05     0.000941        0.856         1.68       0.0676        0.104        0.269        0.339
     39   800      0.00966       0.0092     6.12e-05     0.000396        0.674         1.06       0.0621       0.0864         0.17         0.22
     39   900       0.0217       0.0212     0.000139     0.000336        0.931         1.61       0.0885         0.13        0.175        0.202
     39  1000      0.00148     0.000951      7.5e-05     0.000457         0.27        0.341       0.0708       0.0957        0.184        0.236
     39  1100       0.0334       0.0313     0.000127      0.00204         1.03         1.95       0.0776        0.125        0.432        0.499
     39  1200       0.0319       0.0315     0.000126     0.000338         1.02         1.96       0.0863        0.124        0.203        0.203
     39  1300       0.0256       0.0253     0.000121     0.000146        0.983         1.76       0.0779        0.121        0.105        0.133
     39  1400       0.0211       0.0193     8.74e-05       0.0017        0.805         1.53       0.0695        0.103        0.453        0.456
     39  1500       0.0417       0.0415     7.74e-05     0.000184         1.28         2.25       0.0698       0.0972        0.124         0.15
     39  1600       0.0261       0.0254     9.42e-05     0.000642        0.882         1.76       0.0686        0.107        0.263         0.28
     39  1700      0.00297       0.0026     8.55e-05     0.000279        0.416        0.564       0.0644        0.102         0.12        0.184
     39  1800       0.0207       0.0199     8.19e-05     0.000727        0.768         1.56       0.0629          0.1        0.274        0.298
     39  1900        0.023       0.0175     6.88e-05      0.00545        0.743         1.46       0.0628       0.0917        0.746        0.816
     39  2000        0.072       0.0711     9.24e-05     0.000889         1.15         2.95       0.0683        0.106        0.306        0.329
     39  2039       0.0134        0.013     0.000223     0.000165        0.931         1.26        0.114        0.165        0.118        0.142

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     39   100      0.00856       0.0074     0.000146      0.00102        0.639        0.951       0.0802        0.134        0.332        0.352
     39   182        0.137        0.136      3.7e-05     0.000533         2.44         4.08       0.0493       0.0673        0.255        0.255


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              39 3877.994    0.001       0.0281     0.000105      0.00128       0.0295        0.864         1.85       0.0747        0.113        0.305        0.395
! Validation         39 3877.994    0.001        0.026     0.000157      0.00227       0.0284         0.87         1.77       0.0838        0.139        0.404        0.527
Wall time: 3877.994920298457
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     40   100      0.00348      0.00195     0.000158      0.00137        0.319        0.488       0.0834        0.139        0.368        0.409
     40   200       0.0134       0.0127     0.000147     0.000529        0.679         1.25       0.0867        0.134        0.207        0.254
     40   300       0.0197       0.0176     9.09e-05      0.00199        0.827         1.47       0.0635        0.105        0.395        0.493
     40   400       0.0927       0.0922     8.03e-05     0.000424         1.39         3.36       0.0689        0.099        0.183        0.227
     40   500      0.00608      0.00488     0.000117      0.00108        0.448        0.771       0.0803        0.119        0.304        0.364
     40   600         0.18         0.18     0.000188     0.000305         1.69         4.69       0.0928        0.152        0.163        0.193
     40   700       0.0125       0.0103     0.000105      0.00207        0.619         1.12       0.0756        0.113        0.364        0.503
     40   800       0.0401       0.0394     0.000124     0.000551         1.16         2.19       0.0863        0.123        0.221        0.259
     40   900      0.00514       0.0042     8.61e-05     0.000853        0.481        0.716       0.0696        0.103        0.219        0.323
     40  1000       0.0409       0.0403     0.000123     0.000551         1.16         2.22       0.0832        0.122        0.237        0.259
     40  1100        0.048       0.0445     0.000133      0.00335         1.24         2.33        0.093        0.128        0.613        0.639
     40  1200      0.00327      0.00244     5.05e-05     0.000785         0.33        0.545       0.0518       0.0785        0.262         0.31
     40  1300      0.00307      0.00221     7.71e-05     0.000774         0.34         0.52       0.0658        0.097        0.286        0.307
     40  1400       0.0703       0.0696     0.000124     0.000622         1.75         2.91       0.0789        0.123        0.264        0.276
     40  1500       0.0374       0.0369      0.00012     0.000403         1.27         2.12       0.0817        0.121        0.204        0.222
     40  1600      0.00472      0.00286      9.7e-05      0.00176        0.407        0.591        0.077        0.109        0.379        0.464
     40  1700       0.0258       0.0247     0.000169     0.000926         1.11         1.74       0.0978        0.144        0.333        0.336
     40  1800         0.14        0.139      0.00012     0.000711         1.47         4.13       0.0794        0.121        0.251        0.295
     40  1900       0.0623       0.0605     0.000118      0.00167          1.3         2.72       0.0771         0.12        0.403        0.451
     40  2000       0.0164       0.0156     0.000139     0.000627        0.723         1.38        0.094         0.13        0.262        0.277
     40  2039      0.00524      0.00426     8.33e-05     0.000899        0.492        0.721       0.0546        0.101        0.302        0.331

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     40   100      0.00746      0.00623      9.2e-05      0.00114        0.612        0.872       0.0697        0.106        0.296        0.372
     40   182        0.143        0.142     3.88e-05     0.000831         2.52         4.16       0.0514       0.0688        0.319        0.319


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              40 3976.831    0.001       0.0282     0.000106      0.00118       0.0295        0.865         1.86       0.0745        0.114        0.294        0.379
! Validation         40 3976.831    0.001        0.025     0.000103     0.000793       0.0259        0.826         1.73       0.0741        0.112        0.245        0.311
Wall time: 3976.831864133477
! Best model       40    0.026
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     41   100      0.00635      0.00282     6.61e-05      0.00347         0.47        0.586        0.064       0.0898        0.506        0.651
     41   200      0.00248      0.00113     6.04e-05      0.00129         0.23        0.371        0.061       0.0859        0.329        0.397
     41   300       0.0197       0.0192     6.55e-05     0.000443        0.877         1.53       0.0639       0.0894         0.19        0.233
     41   400       0.0446       0.0441     0.000101     0.000483          1.2         2.32       0.0746        0.111        0.211        0.243
     41   500        0.028       0.0267     0.000103      0.00116         0.91         1.81       0.0684        0.112        0.305        0.377
     41   600       0.0323       0.0288     9.63e-05      0.00334         0.98         1.88       0.0626        0.108        0.585        0.639
     41   700       0.0132       0.0127     9.74e-05     0.000402        0.638         1.25       0.0679        0.109        0.206        0.222
     41   800       0.0262       0.0247     0.000143      0.00129         1.04         1.74       0.0885        0.132        0.359        0.397
     41   900      0.00921      0.00836     0.000138     0.000716        0.566         1.01       0.0839         0.13        0.275        0.296
     41  1000       0.0137       0.0134     6.33e-05     0.000308        0.847         1.28        0.061       0.0879        0.173        0.194
     41  1100       0.0129       0.0122     7.42e-05       0.0006        0.603         1.22       0.0644       0.0952        0.235        0.271
     41  1200        0.105        0.103     0.000158      0.00187         1.63         3.55       0.0945        0.139        0.407        0.478
     41  1300       0.0174       0.0167     5.83e-05     0.000599        0.869         1.43       0.0607       0.0844        0.249         0.27
     41  1400       0.0779       0.0766     0.000113      0.00114         1.57         3.06       0.0734        0.118        0.316        0.374
     41  1500       0.0355       0.0344     0.000115     0.000981         1.01         2.05       0.0707        0.118        0.339        0.346
     41  1600       0.0481       0.0473     7.76e-05      0.00074          1.2          2.4       0.0625       0.0973        0.275        0.301
     41  1700       0.0426       0.0415     0.000142     0.000905         1.27         2.25       0.0842        0.132        0.243        0.332
     41  1800      0.00311      0.00254     0.000161     0.000403        0.385        0.557       0.0945         0.14        0.146        0.222
     41  1900      0.00391       0.0036     9.28e-05     0.000214        0.458        0.663       0.0688        0.106        0.135        0.162
     41  2000       0.0454        0.045     8.61e-05     0.000275         1.16         2.34       0.0731        0.103        0.176        0.183
     41  2039      0.00171      0.00102     7.72e-05     0.000607        0.289        0.353       0.0695       0.0971        0.236        0.272

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     41   100      0.00805      0.00583     9.28e-05      0.00212        0.619        0.844       0.0739        0.106        0.423        0.509
     41   182        0.137        0.135     5.18e-05      0.00129         2.44         4.06       0.0615       0.0795        0.396        0.396


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              41 4075.756    0.001       0.0281     0.000106      0.00123       0.0294        0.864         1.85       0.0742        0.114        0.297        0.387
! Validation         41 4075.756    0.001       0.0247      0.00011      0.00102       0.0258        0.836         1.72       0.0806        0.116        0.267        0.352
Wall time: 4075.7567594498396
! Best model       41    0.026
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     42   100       0.0631        0.062     0.000138     0.000926         1.28         2.75       0.0783         0.13        0.237        0.336
     42   200       0.0474       0.0448     0.000121      0.00252        0.995         2.34       0.0785        0.122        0.437        0.555
     42   300        0.023       0.0215     0.000118      0.00139        0.925         1.62        0.082         0.12        0.388        0.412
     42   400       0.0497       0.0384      0.00022       0.0112         1.26         2.16        0.115        0.164         1.01         1.17
     42   500       0.0939       0.0928     0.000207     0.000909         1.45         3.37       0.0962        0.159        0.286        0.333
     42   600       0.0235        0.023     9.31e-05     0.000409        0.906         1.68       0.0678        0.107        0.128        0.224
     42   700      0.00474      0.00443     0.000123     0.000185        0.447        0.736       0.0806        0.122        0.107         0.15
     42   800      0.00559      0.00518     6.97e-05     0.000346        0.451        0.795       0.0594       0.0922        0.199        0.205
     42   900       0.0101       0.0093     8.56e-05     0.000696        0.638         1.07         0.07        0.102        0.236        0.291
     42  1000       0.0479       0.0469     0.000121     0.000862         1.17         2.39       0.0835        0.121        0.272        0.324
     42  1100       0.0105      0.00517     0.000215      0.00509         0.52        0.794        0.111        0.162        0.523        0.789
     42  1200       0.0267       0.0264     0.000121     0.000207        0.729         1.79       0.0707        0.121        0.125        0.159
     42  1300       0.0237       0.0215     0.000202      0.00195        0.929         1.62       0.0929        0.157        0.446        0.488
     42  1400      0.00587      0.00443     7.96e-05      0.00136        0.421        0.735       0.0655       0.0986        0.365        0.408
     42  1500       0.0253       0.0239     6.96e-05       0.0013        0.964         1.71       0.0667       0.0922        0.312        0.398
     42  1600        0.033       0.0322     6.51e-05     0.000722        0.947         1.98       0.0623       0.0891        0.264        0.297
     42  1700        0.145        0.144     0.000275      0.00035         2.25          4.2        0.113        0.183        0.183        0.207
     42  1800       0.0304       0.0298     8.32e-05     0.000534        0.823         1.91        0.065        0.101        0.249        0.255
     42  1900      0.00748      0.00695     9.79e-05     0.000434        0.608        0.921       0.0696        0.109        0.192         0.23
     42  2000       0.0734       0.0721     0.000141      0.00117         1.26         2.97       0.0806        0.131        0.322        0.377
     42  2039        0.147        0.147     0.000132     0.000118         1.93         4.23       0.0725        0.127       0.0958         0.12

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     42   100      0.00484      0.00349     0.000106      0.00124        0.509        0.653       0.0712        0.114        0.316         0.39
     42   182        0.147        0.147        4e-05     6.64e-06         2.59         4.24       0.0537       0.0698       0.0285       0.0285


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              42 4174.703    0.001        0.028     0.000109      0.00115       0.0293        0.864         1.85        0.076        0.115        0.287        0.375
! Validation         42 4174.703    0.001       0.0249     0.000118     0.000946        0.026        0.832         1.73       0.0778         0.12        0.266        0.341
Wall time: 4174.704434297979
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     43   100       0.0399        0.039     8.64e-05       0.0008         1.28         2.18       0.0713        0.103        0.229        0.312
     43   200       0.0128       0.0126     6.82e-05     7.28e-05        0.614         1.24       0.0571       0.0913       0.0813       0.0943
     43   300      0.00183      0.00144     6.77e-05     0.000324        0.341        0.419       0.0618       0.0909        0.144        0.199
     43   400      0.00451       0.0034     8.79e-05      0.00102        0.428        0.644       0.0688        0.104        0.341        0.353
     43   500       0.0447       0.0441     0.000139     0.000436         1.18         2.32       0.0858         0.13        0.189        0.231
     43   600        0.148        0.148     6.97e-05     0.000185         1.51         4.25       0.0552       0.0923        0.147         0.15
     43   700      0.00376      0.00205     8.41e-05      0.00163        0.314          0.5       0.0613        0.101        0.319        0.446
     43   800       0.0425       0.0415     8.61e-05     0.000894         1.03         2.25        0.068        0.102        0.269         0.33
     43   900      0.00628      0.00596     2.94e-05     0.000294        0.454        0.853       0.0443       0.0599         0.16         0.19
     43  1000      0.00807      0.00685     9.05e-05      0.00112        0.551        0.915       0.0681        0.105        0.345         0.37
     43  1100       0.0497       0.0488      0.00012     0.000773          1.1         2.44       0.0815        0.121        0.206        0.307
     43  1200       0.0368       0.0349     0.000146      0.00179        0.925         2.06       0.0928        0.134        0.402        0.467
     43  1300        0.121        0.119     0.000178      0.00187         2.13         3.81        0.101        0.147        0.327        0.478
     43  1400       0.0926       0.0917     0.000133     0.000753         1.77         3.35       0.0881        0.127         0.25        0.303
     43  1500      0.00643      0.00511     0.000185      0.00113        0.576         0.79        0.107         0.15        0.298        0.372
     43  1600       0.0688       0.0654     8.98e-05      0.00323          1.2         2.83        0.071        0.105        0.478        0.628
     43  1700       0.0309       0.0289     0.000145      0.00189         1.11         1.88       0.0854        0.133        0.451        0.481
     43  1800      0.00482      0.00407     9.43e-05     0.000655        0.515        0.705       0.0747        0.107        0.262        0.283
     43  1900      0.00287      0.00277     5.73e-05     4.62e-05        0.462        0.581       0.0602       0.0836       0.0642       0.0751
     43  2000      0.00636      0.00604     0.000145     0.000177        0.594        0.859       0.0785        0.133         0.12        0.147
     43  2039        0.102          0.1     0.000203      0.00168            2          3.5        0.108        0.157        0.414        0.452

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     43   100      0.00663      0.00543     0.000124      0.00108        0.587        0.814       0.0784        0.123        0.293        0.363
     43   182        0.132        0.132     4.57e-05     0.000239         2.43         4.02        0.057       0.0747        0.171        0.171


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              43 4273.545    0.001        0.028     0.000108      0.00125       0.0293        0.864         1.85       0.0753        0.115          0.3        0.391
! Validation         43 4273.545    0.001       0.0248     0.000122     0.000852       0.0258        0.823         1.72       0.0806        0.122        0.255        0.323
Wall time: 4273.546275950968
! Best model       43    0.026
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     44   100       0.0214        0.021     0.000275     9.02e-05         1.03          1.6       0.0943        0.183       0.0759        0.105
     44   200       0.0717       0.0713     8.94e-05     0.000322         1.37         2.95       0.0722        0.104        0.159        0.198
     44   300       0.0545       0.0521     0.000146      0.00225         1.26         2.52       0.0804        0.134        0.501        0.524
     44   400      0.00202       0.0019     5.76e-05     5.85e-05        0.282        0.482       0.0558       0.0838       0.0671       0.0845
     44   500       0.0627       0.0623     5.93e-05     0.000362         1.62         2.76       0.0598       0.0851        0.195         0.21
     44   600      0.00822      0.00719      0.00011     0.000915        0.606        0.937       0.0771        0.116        0.269        0.334
     44   700       0.0798       0.0785     0.000176      0.00116         1.53          3.1       0.0934        0.147        0.339        0.376
     44   800       0.0214       0.0204     8.23e-05     0.000951        0.865         1.58       0.0738          0.1        0.301        0.341
     44   900       0.0216       0.0194     0.000119      0.00199        0.912         1.54       0.0848         0.12         0.44        0.493
     44  1000       0.0501       0.0415     0.000145      0.00839         1.49         2.25       0.0914        0.133        0.931         1.01
     44  1100      0.00362      0.00289     0.000101     0.000626        0.407        0.594       0.0778        0.111        0.227        0.277
     44  1200       0.0404       0.0377     0.000161      0.00255         1.26         2.15       0.0931         0.14         0.47        0.558
     44  1300      0.00707      0.00624     3.83e-05     0.000788        0.547        0.873       0.0505       0.0684        0.218         0.31
     44  1400      0.00326      0.00127     9.23e-05      0.00189        0.226        0.394        0.069        0.106        0.308         0.48
     44  1500       0.0576        0.057     0.000147     0.000411         1.24         2.64       0.0876        0.134        0.195        0.224
     44  1600        0.103        0.102     8.84e-05     0.000955         1.48         3.54       0.0708        0.104        0.277        0.342
     44  1700       0.0147       0.0142     0.000102     0.000427        0.781         1.32       0.0772        0.111        0.207        0.228
     44  1800       0.0182       0.0169     0.000192      0.00112        0.847         1.44       0.0953        0.153         0.34         0.37
     44  1900      0.00824      0.00621     8.36e-05      0.00195        0.425        0.871       0.0608        0.101        0.445        0.488
     44  2000      0.00829      0.00802     0.000201     6.95e-05        0.655        0.989        0.089        0.157        0.077       0.0921
     44  2039      0.00299     0.000582      2.4e-05      0.00239        0.206        0.267       0.0354       0.0542        0.533         0.54

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     44   100       0.0117      0.00368     7.04e-05      0.00798        0.473         0.67       0.0607       0.0927        0.603        0.987
     44   182        0.156        0.156     3.32e-05     0.000223         2.62         4.36       0.0471       0.0636        0.165        0.165


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              44 4372.439    0.001        0.028     0.000113      0.00108       0.0292        0.866         1.85       0.0766        0.117        0.282        0.364
! Validation         44 4372.439    0.001       0.0251     8.51e-05      0.00314       0.0283        0.789         1.73       0.0662        0.102        0.475         0.62
Wall time: 4372.439717546105
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     45   100       0.0261       0.0256     0.000111     0.000434        0.999         1.77       0.0745        0.116        0.211         0.23
     45   200       0.0172        0.017     0.000135     8.44e-05        0.882         1.44       0.0828        0.128       0.0932        0.102
     45   300       0.0503       0.0485     0.000135      0.00164          1.1         2.43       0.0861        0.129        0.353        0.447
     45   400       0.0039      0.00318     8.99e-05     0.000631        0.428        0.623       0.0714        0.105        0.227        0.277
     45   500       0.0424       0.0414     0.000139     0.000914         0.99         2.25       0.0837         0.13        0.283        0.334
     45   600       0.0194       0.0191     0.000126     0.000121        0.883         1.53       0.0848        0.124        0.113        0.122
     45   700       0.0171       0.0154     0.000148      0.00156        0.807         1.37        0.088        0.134        0.398        0.437
     45   800       0.0519       0.0492     9.52e-05      0.00261         1.24         2.45       0.0698        0.108        0.431        0.564
     45   900       0.0577       0.0572     0.000163     0.000385         1.51         2.64       0.0921        0.141        0.165        0.217
     45  1000       0.0008     0.000476     4.26e-05     0.000282        0.204        0.241       0.0528       0.0721        0.169        0.185
     45  1100        0.033       0.0296     8.75e-05      0.00337        0.999          1.9       0.0722        0.103        0.573        0.641
     45  1200       0.0367       0.0363     9.69e-05     0.000274            1         2.11       0.0724        0.109        0.157        0.183
     45  1300       0.0038       0.0029     9.85e-05     0.000797        0.413        0.595        0.076         0.11        0.295        0.312
     45  1400       0.0214       0.0212     9.19e-05       0.0001        0.898         1.61       0.0635        0.106       0.0993        0.111
     45  1500       0.0152       0.0138     0.000121      0.00133        0.748          1.3       0.0647        0.122        0.247        0.402
     45  1600       0.0115       0.0113     0.000115     0.000176        0.651         1.17       0.0724        0.118        0.126        0.146
     45  1700      0.00415      0.00267     0.000123      0.00136         0.45        0.571       0.0828        0.123        0.352        0.407
     45  1800      0.00327      0.00184     8.63e-05      0.00134        0.304        0.474       0.0678        0.103        0.395        0.404
     45  1900       0.0215       0.0207     7.62e-05     0.000783        0.852         1.59       0.0681       0.0964        0.247        0.309
     45  2000      0.00887      0.00839     0.000189     0.000296        0.603         1.01       0.0864        0.152        0.158         0.19
     45  2039      0.00483      0.00442     4.39e-05     0.000371        0.484        0.734       0.0523       0.0732        0.208        0.213

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     45   100      0.00621      0.00473     0.000118      0.00136        0.565         0.76       0.0778         0.12        0.342        0.408
     45   182        0.164        0.164     4.25e-05     1.19e-05         2.69         4.48       0.0559       0.0721       0.0381       0.0381


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              45 4471.325    0.001       0.0279     0.000109      0.00113       0.0291        0.859         1.84       0.0753        0.115        0.289        0.371
! Validation         45 4471.325    0.001       0.0257      0.00014     0.000896       0.0267        0.863         1.75       0.0834        0.131        0.262        0.331
Wall time: 4471.325722940266
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     46   100       0.0147       0.0119     0.000168      0.00263        0.785          1.2       0.0952        0.143        0.494        0.567
     46   200       0.0147       0.0143     8.63e-05     0.000315        0.691         1.32       0.0748        0.103        0.161        0.196
     46   300       0.0193       0.0177     6.35e-05      0.00148        0.757         1.47        0.062        0.088        0.302        0.425
     46   400      0.00697      0.00646     8.35e-05     0.000427         0.49        0.888       0.0672        0.101         0.21        0.228
     46   500      0.00852      0.00741     8.23e-05      0.00103        0.587        0.951       0.0627          0.1        0.283        0.355
     46   600        0.389        0.388     0.000118     0.000157         2.71         6.89       0.0793         0.12        0.135        0.138
     46   700       0.0721       0.0707     8.83e-05      0.00133          1.3         2.94       0.0629        0.104        0.351        0.404
     46   800      0.00447      0.00357     8.76e-05     0.000814         0.52         0.66       0.0709        0.103        0.305        0.315
     46   900       0.0797       0.0781      0.00014       0.0015         1.59         3.09       0.0921        0.131        0.327        0.428
     46  1000       0.0433       0.0427     0.000122     0.000452        0.958         2.28       0.0774        0.122        0.204        0.235
     46  1100       0.0111      0.00969     7.48e-05       0.0013        0.732         1.09       0.0687       0.0956        0.317        0.398
     46  1200      0.00423      0.00377     0.000114     0.000347        0.434        0.678       0.0773        0.118        0.133        0.206
     46  1300        0.206        0.205     0.000109     0.000334         2.42         5.01       0.0739        0.115        0.187        0.202
     46  1400       0.0564       0.0547     0.000174      0.00153         1.43         2.58       0.0966        0.146        0.398        0.432
     46  1500       0.0181       0.0177        7e-05     0.000329        0.642         1.47       0.0654       0.0924        0.161          0.2
     46  1600       0.0149       0.0141     0.000109     0.000641        0.632         1.31       0.0751        0.115        0.248         0.28
     46  1700       0.0437        0.042     0.000118      0.00159         1.28         2.26       0.0782         0.12         0.27        0.441
     46  1800       0.0836       0.0835     0.000132     2.44e-05         1.41         3.19       0.0874        0.127       0.0473       0.0546
     46  1900       0.0556       0.0545     8.65e-05     0.000997         1.22         2.58        0.074        0.103        0.302        0.349
     46  2000       0.0459       0.0448      7.7e-05      0.00108         1.18         2.34       0.0645       0.0969        0.319        0.362
     46  2039      0.00593      0.00295      0.00016      0.00282        0.468          0.6       0.0793         0.14         0.49        0.586

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     46   100      0.00729      0.00604     0.000138      0.00111        0.634        0.859       0.0809         0.13        0.307        0.369
     46   182        0.168        0.167     4.59e-05      0.00111         2.74         4.51       0.0568       0.0748        0.369        0.369


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              46 4570.173    0.001       0.0278     0.000112      0.00107        0.029        0.861         1.84       0.0762        0.117        0.279        0.362
! Validation         46 4570.173    0.001       0.0253     0.000135     0.000873       0.0263        0.855         1.74       0.0828        0.129        0.256        0.326
Wall time: 4570.174288317561
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     47   100      0.00775      0.00712     0.000124     0.000505        0.559        0.932       0.0822        0.123        0.207        0.248
     47   200      0.00663      0.00566     8.35e-05     0.000886        0.569        0.831       0.0675        0.101        0.271        0.329
     47   300       0.0655       0.0652      9.1e-05     0.000161         1.39         2.82       0.0689        0.105        0.121         0.14
     47   400      0.00383      0.00307     8.33e-05     0.000675        0.434        0.612       0.0709        0.101        0.226        0.287
     47   500       0.0166       0.0151     9.93e-05      0.00147        0.853         1.36       0.0695         0.11        0.383        0.424
     47   600       0.0531       0.0522     9.76e-05     0.000872         1.34         2.52        0.075        0.109        0.257        0.326
     47   700      0.00336      0.00301     8.08e-05     0.000276        0.455        0.606       0.0728       0.0993        0.169        0.183
     47   800      0.00667      0.00603     7.98e-05     0.000565        0.642        0.858       0.0662       0.0987        0.208        0.263
     47   900      0.00653      0.00471      7.7e-05      0.00175        0.422        0.758       0.0666       0.0969        0.402        0.462
     47  1000      0.00947      0.00906      0.00022     0.000187        0.671         1.05        0.112        0.164       0.0961        0.151
     47  1100       0.0585       0.0581     0.000133     0.000259         1.42         2.66       0.0852        0.128         0.14        0.178
     47  1200      0.00512      0.00333     9.13e-05       0.0017        0.461        0.637       0.0675        0.106         0.45        0.456
     47  1300       0.0583       0.0567     0.000249      0.00133         1.43         2.63        0.108        0.174        0.353        0.403
     47  1400      0.00693      0.00525      0.00016      0.00152        0.454        0.801       0.0833         0.14        0.306         0.43
     47  1500      0.00627      0.00562     0.000108     0.000545        0.491        0.828       0.0652        0.115         0.24        0.258
     47  1600       0.0896        0.089     9.03e-05     0.000483         1.69          3.3       0.0663        0.105         0.18        0.243
     47  1700      0.00363      0.00286     0.000142     0.000628        0.429        0.591        0.086        0.132        0.254        0.277
     47  1800       0.0281       0.0272     0.000101     0.000822        0.826         1.82       0.0735        0.111        0.294        0.317
     47  1900      0.00391      0.00271     9.67e-05      0.00111        0.343        0.575       0.0669        0.109        0.341        0.368
     47  2000      0.00268      0.00172     0.000115     0.000841        0.356        0.459       0.0771        0.118        0.251        0.321
     47  2039      0.00496      0.00401     0.000104     0.000842        0.492          0.7       0.0701        0.113        0.315        0.321

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     47   100      0.00631      0.00409     0.000119       0.0021         0.54        0.707       0.0734        0.121        0.436        0.506
     47   182        0.155        0.153      3.8e-05      0.00161         2.58         4.33       0.0529       0.0682        0.443        0.443


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              47 4669.113    0.001       0.0278      0.00011      0.00108        0.029        0.862         1.84       0.0759        0.116        0.279        0.362
! Validation         47 4669.113    0.001        0.025      0.00013      0.00175       0.0269        0.817         1.73       0.0783        0.126        0.355        0.462
Wall time: 4669.115683615208
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     48   100       0.0599       0.0578     0.000184      0.00188         1.43         2.66       0.0935         0.15        0.342        0.479
     48   200       0.0281       0.0273     0.000137     0.000653         1.06         1.83       0.0843        0.129        0.244        0.282
     48   300       0.0333        0.033     0.000169     0.000179        0.952         2.01       0.0851        0.143        0.115        0.148
     48   400      0.00177       0.0013     7.17e-05     0.000392        0.304        0.399       0.0635       0.0935        0.154        0.219
     48   500      0.00988      0.00751     7.83e-05      0.00229        0.599        0.957       0.0683       0.0978        0.504        0.529
     48   600       0.0344       0.0336     7.53e-05     0.000737        0.853         2.02       0.0651       0.0959        0.271          0.3
     48   700      0.00668      0.00625     6.74e-05      0.00037        0.534        0.873       0.0639       0.0907         0.15        0.212
     48   800        0.028        0.027     0.000145     0.000825        0.897         1.82       0.0826        0.133        0.258        0.317
     48   900       0.0697       0.0671     0.000105      0.00251         1.28         2.86       0.0776        0.113        0.394        0.554
     48  1000      0.00435      0.00296     8.45e-05       0.0013        0.322        0.602       0.0652        0.102        0.352        0.399
     48  1100      0.00452      0.00394     0.000115     0.000467        0.495        0.693       0.0732        0.118        0.207        0.239
     48  1200       0.0583       0.0557     0.000121      0.00253         1.32         2.61       0.0797        0.122         0.52        0.556
     48  1300       0.0283       0.0278     0.000149     0.000356         1.05         1.84       0.0851        0.135        0.184        0.208
     48  1400      0.00358      0.00327      9.8e-05     0.000215        0.401        0.632       0.0698        0.109        0.129        0.162
     48  1500        0.018       0.0178     7.73e-05     0.000102        0.728         1.47       0.0633       0.0971       0.0843        0.112
     48  1600       0.0177       0.0172     9.39e-05     0.000419        0.717         1.45       0.0668        0.107        0.194        0.226
     48  1700       0.0454       0.0452     7.76e-05     0.000125         1.11         2.35       0.0655       0.0973        0.104        0.124
     48  1800      0.00614      0.00574     0.000114     0.000284        0.584        0.837       0.0857        0.118        0.158        0.186
     48  1900       0.0128       0.0105     9.28e-05      0.00218        0.614         1.13       0.0692        0.106        0.391        0.516
     48  2000       0.0546        0.054     9.61e-05      0.00048         1.34         2.57        0.068        0.108        0.239        0.242
     48  2039      0.00341      0.00277     5.16e-05     0.000593        0.388        0.581       0.0582       0.0794        0.256        0.269

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     48   100      0.00554      0.00418     9.22e-05      0.00127        0.511        0.714       0.0688        0.106        0.253        0.393
     48   182        0.142        0.141     3.84e-05     0.000827         2.46         4.15        0.052       0.0685        0.318        0.318


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              48 4768.907    0.001       0.0278     0.000112      0.00105        0.029        0.862         1.84       0.0761        0.117        0.273        0.357
! Validation         48 4768.907    0.001       0.0249     0.000106      0.00106       0.0261        0.816         1.73        0.075        0.114         0.27         0.36
Wall time: 4768.90861081332
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     49   100       0.0762        0.074     0.000118      0.00202         1.62         3.01       0.0759         0.12         0.34        0.497
     49   200       0.0226       0.0214     8.01e-05      0.00117        0.852         1.62       0.0643       0.0989        0.288        0.378
     49   300       0.0189       0.0183     6.92e-05     0.000568        0.882         1.49       0.0598       0.0919        0.232        0.263
     49   400       0.0327       0.0315     0.000145      0.00111            1         1.96       0.0758        0.133        0.317        0.368
     49   500       0.0238       0.0235     4.04e-05     0.000172        0.885          1.7       0.0469       0.0702       0.0922        0.145
     49   600      0.00668      0.00618      6.5e-05     0.000437        0.552        0.869       0.0608       0.0891        0.182        0.231
     49   700       0.0709       0.0701     0.000132     0.000679         1.69         2.93       0.0927        0.127        0.225        0.288
     49   800       0.0255        0.024     0.000101      0.00142        0.895         1.71       0.0698        0.111         0.37        0.416
     49   900      0.00883       0.0078     0.000113     0.000924        0.624        0.976       0.0737        0.118        0.295        0.336
     49  1000       0.0363       0.0355     0.000138     0.000649          1.1         2.08       0.0858         0.13        0.235        0.281
     49  1100      0.00929      0.00796     0.000121      0.00121        0.603        0.986       0.0836        0.122        0.357        0.385
     49  1200        0.091       0.0906       0.0002      0.00025         1.86         3.33        0.109        0.156        0.149        0.175
     49  1300       0.0238       0.0232     0.000131     0.000452        0.872         1.68       0.0852        0.126        0.169        0.235
     49  1400      0.00872      0.00815     0.000116     0.000459        0.604        0.997       0.0789        0.119        0.219        0.237
     49  1500       0.0106      0.00993     6.96e-05     0.000567         0.61          1.1       0.0653       0.0922        0.209        0.263
     49  1600        0.108        0.106     0.000168      0.00127         1.52          3.6       0.0919        0.143        0.273        0.393
     49  1700        0.028        0.027     6.99e-05     0.000879        0.838         1.82       0.0661       0.0924         0.32        0.328
     49  1800       0.0116      0.00996      9.7e-05      0.00151        0.639          1.1       0.0713        0.109        0.375         0.43
     49  1900       0.0223       0.0219     9.84e-05     0.000346        0.932         1.63       0.0708         0.11        0.181        0.206
     49  2000       0.0393       0.0385     0.000109     0.000655         1.33         2.17       0.0816        0.115        0.251        0.283
     49  2039      0.00335      0.00315     7.51e-05     0.000131        0.429         0.62       0.0724       0.0957        0.123        0.127

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     49   100      0.00949       0.0085     0.000114     0.000873        0.675         1.02       0.0784        0.118        0.249        0.326
     49   182        0.115        0.115     4.27e-05     3.36e-05         2.25         3.74        0.055       0.0722        0.064        0.064


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              49 4868.162    0.001       0.0278     0.000111      0.00106       0.0289        0.858         1.84       0.0757        0.116        0.279         0.36
! Validation         49 4868.162    0.001       0.0279     0.000121     0.000663       0.0287        0.901         1.83       0.0819        0.122        0.216        0.285
Wall time: 4868.163453057408
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     50   100       0.0208       0.0184     9.05e-05      0.00237        0.854          1.5       0.0764        0.105        0.349        0.538
     50   200        0.028       0.0262     0.000117      0.00162        0.752         1.79       0.0796        0.119        0.405        0.445
     50   300       0.0611       0.0607     0.000125     0.000292         1.07         2.72       0.0811        0.124         0.15        0.189
     50   400       0.0317       0.0311     0.000108     0.000565          1.1         1.95       0.0752        0.115        0.222        0.263
     50   500        0.021       0.0207     5.77e-05     0.000195        0.883         1.59        0.059       0.0839        0.117        0.154
     50   600        0.378        0.378       0.0001     0.000693         2.35         6.79       0.0714        0.111        0.234        0.291
     50   700       0.0151       0.0145     0.000117     0.000417        0.643         1.33        0.077        0.119        0.198        0.226
     50   800      0.00697      0.00613     9.72e-05     0.000747        0.498        0.865       0.0715        0.109        0.267        0.302
     50   900       0.0204         0.02     0.000103     0.000271        0.864         1.56       0.0733        0.112        0.142        0.182
     50  1000        0.013       0.0129     9.79e-05     1.85e-05        0.668         1.26        0.078        0.109        0.044       0.0475
     50  1100      0.00271        0.002     9.05e-05     0.000626         0.33        0.494       0.0727        0.105        0.263        0.276
     50  1200       0.0492       0.0488     0.000152     0.000241         1.24         2.44       0.0952        0.136        0.116        0.171
     50  1300      0.00241      0.00137     7.99e-05     0.000961        0.327        0.409       0.0715       0.0988        0.284        0.343
     50  1400       0.0543       0.0536     0.000117     0.000557         1.09         2.56       0.0753        0.119        0.221        0.261
     50  1500       0.0125       0.0105     0.000146      0.00186        0.779         1.13       0.0936        0.133        0.399        0.476
     50  1600       0.0398       0.0392     0.000103     0.000492         1.08         2.19       0.0779        0.112        0.223        0.245
     50  1700       0.0715       0.0708     0.000118     0.000568         1.63         2.94        0.084         0.12        0.205        0.263
     50  1800       0.0231        0.022     0.000161     0.000929        0.844         1.64       0.0858         0.14        0.304        0.337
     50  1900       0.0158       0.0147     0.000121     0.000999        0.707         1.34       0.0788        0.122        0.284        0.349
     50  2000       0.0432       0.0426     0.000126     0.000529        0.965         2.28       0.0853        0.124        0.201        0.254
     50  2039       0.0105      0.00983     0.000115     0.000552        0.819          1.1       0.0708        0.119        0.259         0.26

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     50   100      0.00612      0.00557     9.61e-05     0.000453        0.558        0.825       0.0694        0.108        0.194        0.235
     50   182        0.116        0.115     4.43e-05     0.000655         2.29         3.75       0.0571       0.0735        0.283        0.283


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              50 4967.036    0.001       0.0277     0.000116     0.000969       0.0288        0.862         1.84       0.0777        0.119        0.267        0.344
! Validation         50 4967.036    0.001       0.0255     9.84e-05     0.000599       0.0262        0.819         1.75       0.0736         0.11        0.212         0.27
Wall time: 4967.036893643439
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     51   100        0.011       0.0106     6.73e-05     0.000302        0.528         1.14        0.062       0.0906        0.139        0.192
     51   200       0.0245       0.0228        9e-05      0.00164        0.918         1.67       0.0672        0.105          0.4        0.448
     51   300       0.0201       0.0165     0.000289      0.00327        0.963         1.42        0.121        0.188        0.462        0.631
     51   400        0.019       0.0172      8.7e-05       0.0017        0.914         1.45       0.0693        0.103        0.455        0.456
     51   500      0.00464       0.0044     6.92e-05      0.00017        0.416        0.733       0.0537       0.0919        0.136        0.144
     51   600       0.0117       0.0103     6.49e-05      0.00125        0.633         1.12         0.06        0.089        0.359        0.391
     51   700      0.00755      0.00686     8.13e-05     0.000616        0.664        0.915       0.0671       0.0996        0.191        0.274
     51   800       0.0354        0.034      0.00011      0.00135         1.12         2.04       0.0756        0.116        0.374        0.406
     51   900      0.00456       0.0044     0.000114     4.24e-05        0.502        0.733       0.0771        0.118       0.0615        0.072
     51  1000       0.0377       0.0375     0.000121     8.73e-05         1.11         2.14       0.0759        0.122       0.0937        0.103
     51  1100       0.0135        0.013     0.000117      0.00046        0.736         1.26       0.0744         0.12        0.174        0.237
     51  1200       0.0461       0.0458     0.000131     0.000176         1.25         2.36       0.0869        0.127        0.119        0.147
     51  1300       0.0812       0.0802     0.000124     0.000882         1.34         3.13       0.0752        0.123        0.241        0.328
     51  1400       0.0432        0.042     0.000104      0.00108        0.892         2.26       0.0714        0.113        0.276        0.363
     51  1500       0.0695       0.0692     9.18e-05     0.000165          1.6         2.91        0.072        0.106        0.122        0.142
     51  1600      0.00655      0.00606     5.33e-05     0.000437        0.458         0.86       0.0564       0.0807        0.219        0.231
     51  1700        0.012      0.00929      0.00012       0.0026        0.657         1.06       0.0771        0.121        0.455        0.563
     51  1800      0.00389      0.00353     0.000213     0.000143        0.453        0.657       0.0961        0.161        0.121        0.132
     51  1900       0.0507       0.0498     0.000137     0.000795         1.18         2.47        0.091        0.129        0.276        0.311
     51  2000      0.00554      0.00426     8.14e-05      0.00119        0.496        0.721       0.0694       0.0997        0.343        0.381
     51  2039      0.00735      0.00675     0.000135     0.000461        0.608        0.908       0.0843        0.128        0.236        0.237

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     51   100      0.00653      0.00546     0.000142     0.000926        0.605        0.816       0.0838        0.132        0.317        0.336
     51   182        0.147        0.145     4.54e-05      0.00176         2.48         4.21        0.056       0.0744        0.463        0.463


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              51 5065.895    0.001       0.0277     0.000111      0.00095       0.0287        0.857         1.84        0.076        0.116        0.266        0.341
! Validation         51 5065.895    0.001       0.0248      0.00014      0.00142       0.0264        0.851         1.72       0.0854        0.131        0.317        0.416
Wall time: 5065.896401837468
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     52   100       0.0308       0.0302     0.000189     0.000486         1.08         1.92          0.1        0.152        0.163        0.244
     52   200       0.0115       0.0104     0.000107     0.000983        0.683         1.13       0.0806        0.114        0.277        0.346
     52   300      0.00933      0.00806     0.000114      0.00116        0.602        0.992        0.078        0.118        0.329        0.376
     52   400       0.0041      0.00346     6.53e-05     0.000579        0.402         0.65       0.0627       0.0893        0.227        0.266
     52   500      0.00121     0.000713     3.67e-05     0.000457        0.222        0.295       0.0452       0.0669        0.214        0.236
     52   600      0.00502      0.00446     0.000128     0.000426        0.524        0.738       0.0819        0.125        0.197        0.228
     52   700       0.0229       0.0225     0.000103     0.000262         0.72         1.66       0.0731        0.112        0.141        0.179
     52   800        0.184         0.18     0.000143      0.00384         2.35         4.68       0.0912        0.132        0.612        0.684
     52   900       0.0182       0.0175     7.92e-05     0.000665        0.763         1.46       0.0648       0.0983         0.28        0.285
     52  1000       0.0129        0.012     0.000136     0.000728        0.783         1.21       0.0883        0.129        0.235        0.298
     52  1100       0.0152       0.0143     6.83e-05     0.000862         0.75         1.32       0.0583       0.0913        0.306        0.324
     52  1200      0.00193      0.00147     8.38e-05     0.000377        0.284        0.424        0.067        0.101        0.206        0.214
     52  1300       0.0456       0.0449     0.000117     0.000558         1.22         2.34       0.0816         0.12        0.234        0.261
     52  1400       0.0397       0.0385     0.000118      0.00108         1.18         2.17        0.074         0.12        0.324        0.363
     52  1500       0.0225        0.022     9.15e-05     0.000449        0.906         1.64       0.0635        0.106        0.221        0.234
     52  1600        0.158        0.156     0.000142      0.00182         2.17         4.36       0.0906        0.132        0.396        0.471
     52  1700       0.0259        0.025      0.00019     0.000773        0.984         1.75       0.0994        0.152        0.268        0.307
     52  1800       0.0584       0.0568     0.000129      0.00145         1.32         2.63       0.0716        0.126        0.356         0.42
     52  1900       0.0329       0.0303     0.000142      0.00254        0.954         1.92       0.0851        0.132        0.535        0.557
     52  2000       0.0587       0.0578     0.000119     0.000816         1.33         2.66       0.0856        0.121        0.253        0.316
     52  2039       0.0688       0.0683     7.02e-05     0.000413         1.44         2.89         0.06       0.0926        0.193        0.225

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     52   100      0.00644      0.00506     9.65e-05      0.00128        0.556        0.786       0.0707        0.109        0.293        0.396
     52   182        0.144        0.144     3.52e-05     8.08e-06         2.55          4.2       0.0513       0.0656       0.0314       0.0314


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              52 5164.702    0.001       0.0276     0.000114     0.000954       0.0287        0.861         1.83       0.0769        0.118        0.265        0.341
! Validation         52 5164.702    0.001       0.0245     0.000105      0.00065       0.0253        0.794         1.71       0.0745        0.113        0.215        0.282
Wall time: 5164.70275824517
! Best model       52    0.025
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     53   100       0.0793       0.0788     0.000169     0.000331         1.59          3.1        0.088        0.144        0.191        0.201
     53   200      0.00449      0.00409      9.4e-05     0.000308        0.425        0.707       0.0694        0.107        0.188        0.194
     53   300       0.0374       0.0366     0.000127     0.000692         1.16         2.11         0.08        0.125        0.242        0.291
     53   400       0.0246       0.0239      0.00016     0.000585         1.12         1.71       0.0893         0.14        0.247        0.267
     53   500      0.00761      0.00595     0.000109      0.00154        0.588        0.853       0.0756        0.116        0.322        0.434
     53   600        0.046       0.0451     0.000134      0.00075         1.08         2.35       0.0891        0.128        0.197        0.303
     53   700        0.233        0.231      0.00014      0.00112         2.17         5.31       0.0855        0.131        0.291         0.37
     53   800       0.0036      0.00245     0.000163     0.000986        0.392        0.547       0.0923        0.141         0.27        0.347
     53   900       0.0269       0.0266     0.000109     0.000156        0.984          1.8        0.076        0.116        0.106        0.138
     53  1000      0.00241      0.00168     8.56e-05     0.000648        0.352        0.452       0.0632        0.102        0.244        0.281
     53  1100      0.00482      0.00436       0.0001     0.000362        0.532         0.73        0.075        0.111        0.161         0.21
     53  1200      0.00774       0.0071     0.000101     0.000536        0.718        0.931       0.0802        0.111        0.222        0.256
     53  1300       0.0663        0.066     0.000101     0.000228         1.21         2.84       0.0726        0.111        0.133        0.167
     53  1400      0.00764      0.00699     0.000136     0.000522        0.699        0.924        0.091        0.129        0.229        0.252
     53  1500      0.00146      0.00105     8.64e-05     0.000324        0.262        0.358       0.0718        0.103        0.159        0.199
     53  1600       0.0474       0.0462     0.000182     0.000976         1.46         2.38       0.0946        0.149        0.294        0.345
     53  1700      0.00587      0.00537     0.000123     0.000381        0.494        0.809       0.0768        0.123        0.197        0.216
     53  1800       0.0127       0.0119     0.000103     0.000677          0.6         1.21       0.0623        0.112        0.235        0.287
     53  1900      0.00243      0.00174     9.17e-05     0.000598        0.308         0.46       0.0644        0.106        0.221         0.27
     53  2000      0.00507      0.00475     0.000128     0.000191        0.517        0.761       0.0782        0.125        0.133        0.153
     53  2039       0.0536       0.0526     0.000176     0.000849         1.15         2.53       0.0941        0.147        0.309        0.322

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     53   100      0.00738      0.00624     0.000134      0.00101         0.61        0.873       0.0809        0.128        0.311         0.35
     53   182        0.148        0.146     3.46e-05      0.00192         2.52         4.23        0.049        0.065        0.484        0.484


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              53 5263.720    0.001       0.0277     0.000112     0.000908       0.0288        0.859         1.84       0.0762        0.117        0.257        0.333
! Validation         53 5263.720    0.001       0.0246      0.00013     0.000584       0.0253        0.822         1.71       0.0806        0.126        0.209        0.266
Wall time: 5263.720711611211
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     54   100        0.104        0.103     0.000142     0.000551         1.81         3.55       0.0848        0.131        0.256        0.259
     54   200      0.00858      0.00804     7.23e-05     0.000466        0.541        0.991       0.0682        0.094        0.194        0.239
     54   300      0.00183      0.00104     0.000103     0.000684        0.282        0.356       0.0684        0.112        0.278        0.289
     54   400       0.0227       0.0221     7.34e-05     0.000533        0.845         1.64       0.0635       0.0946        0.243        0.255
     54   500      0.00425      0.00405     8.91e-05     0.000116        0.549        0.703       0.0709        0.104        0.109        0.119
     54   600       0.0295        0.029     9.49e-05     0.000406         1.01         1.88       0.0606        0.108        0.192        0.223
     54   700       0.0072      0.00316     0.000154      0.00388        0.344        0.621       0.0871        0.137        0.596        0.688
     54   800      0.00649      0.00585     7.98e-05     0.000557        0.551        0.845       0.0629       0.0987         0.25        0.261
     54   900       0.0268       0.0261     0.000115     0.000614         1.16         1.78       0.0781        0.118        0.239        0.274
     54  1000       0.0205         0.02     8.52e-05     0.000436        0.833         1.56       0.0675        0.102        0.177        0.231
     54  1100       0.0103       0.0074     0.000136      0.00274         0.58        0.951       0.0842        0.129        0.523        0.578
     54  1200       0.0047      0.00371     0.000148     0.000844         0.49        0.673       0.0852        0.135        0.301        0.321
     54  1300       0.0398       0.0396     0.000102     0.000125        0.981          2.2       0.0762        0.112        0.117        0.124
     54  1400       0.0448       0.0445     0.000133     0.000118          1.1         2.33       0.0808        0.128       0.0837         0.12
     54  1500       0.0812       0.0802     0.000165     0.000832         1.48         3.13       0.0823        0.142        0.307        0.319
     54  1600      0.00741      0.00718     0.000101     0.000129        0.554        0.936       0.0733        0.111        0.125        0.125
     54  1700       0.0654       0.0646     0.000129     0.000645         1.41         2.81       0.0789        0.125        0.228        0.281
     54  1800      0.00804      0.00718     7.37e-05     0.000782        0.496        0.936       0.0578       0.0948         0.24        0.309
     54  1900       0.0309       0.0304     0.000111     0.000344         0.92         1.93       0.0761        0.116        0.162        0.205
     54  2000       0.0644       0.0627     0.000102      0.00161         1.48         2.77        0.081        0.112        0.385        0.443
     54  2039      0.00262      0.00194     6.93e-05     0.000612        0.388        0.486        0.062        0.092        0.251        0.273

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     54   100      0.00508      0.00427     9.93e-05     0.000711        0.472        0.722        0.073         0.11        0.241        0.295
     54   182        0.146        0.145     4.42e-05     0.000804         2.59          4.2       0.0564       0.0734        0.313        0.313


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              54 5363.021    0.001       0.0276     0.000115     0.000963       0.0287        0.857         1.84       0.0764        0.119        0.264        0.343
! Validation         54 5363.021    0.001        0.025     0.000109     0.000703       0.0259         0.82         1.73       0.0782        0.116         0.23        0.293
Wall time: 5363.021693482995
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     55   100       0.0168       0.0165     0.000108     0.000232        0.876         1.42       0.0732        0.115        0.162        0.168
     55   200      0.00677      0.00613     0.000109      0.00053        0.576        0.865       0.0772        0.116        0.195        0.254
     55   300       0.0158       0.0154       0.0001     0.000227        0.717         1.37       0.0671        0.111        0.154        0.166
     55   400       0.0124       0.0112     0.000135       0.0011        0.652         1.17       0.0811        0.128        0.341        0.366
     55   500      0.00484      0.00376     7.84e-05      0.00101        0.423        0.677       0.0692       0.0979        0.281         0.35
     55   600      0.00661      0.00639     5.53e-05      0.00017        0.405        0.883       0.0529       0.0822        0.108        0.144
     55   700       0.0445        0.044     0.000131     0.000289         1.04         2.32        0.079        0.127        0.181        0.188
     55   800      0.00254      0.00196     5.73e-05     0.000524        0.327         0.49       0.0539       0.0837        0.248        0.253
     55   900       0.0651       0.0645     5.79e-05     0.000542         1.35         2.81       0.0579       0.0841         0.24        0.257
     55  1000       0.0527       0.0502     0.000188      0.00225          1.2         2.48       0.0917        0.152        0.371        0.524
     55  1100        0.141        0.133     0.000186      0.00777         2.02         4.03        0.101        0.151        0.564        0.974
     55  1200       0.0212         0.02     7.57e-05      0.00115        0.908         1.56       0.0651       0.0961        0.242        0.374
     55  1300        0.024       0.0237     9.49e-05     0.000266        0.816          1.7       0.0694        0.108        0.158         0.18
     55  1400      0.00297       0.0021       0.0001     0.000773        0.413        0.506       0.0719        0.111        0.294        0.307
     55  1500       0.0514        0.051     7.73e-05     0.000386         1.27         2.49       0.0675       0.0971        0.165        0.217
     55  1600       0.0226        0.019     9.21e-05       0.0035        0.948         1.52       0.0788        0.106        0.456        0.654
     55  1700      0.00909      0.00839     0.000108      0.00059        0.613         1.01       0.0807        0.115        0.235        0.268
     55  1800       0.0393       0.0386     0.000194     0.000507         1.17         2.17        0.103        0.154        0.226        0.249
     55  1900      0.00391      0.00316     0.000128      0.00062        0.422        0.621       0.0797        0.125        0.266        0.275
     55  2000       0.0423       0.0413     7.87e-05     0.000893         1.29         2.24        0.066        0.098        0.226         0.33
     55  2039      0.00312       0.0022     0.000222       0.0007        0.388        0.518        0.109        0.165        0.289        0.292

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     55   100      0.00557      0.00436     9.77e-05      0.00111        0.512         0.73       0.0718        0.109        0.297        0.368
     55   182        0.127        0.126     4.47e-05      0.00126         2.39         3.92       0.0588       0.0739        0.392        0.392


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              55 5462.004    0.001       0.0276     0.000111     0.000942       0.0286         0.86         1.84       0.0756        0.116         0.26        0.339
! Validation         55 5462.004    0.001       0.0254     0.000116     0.000695       0.0262        0.833         1.75       0.0789        0.119        0.234        0.291
Wall time: 5462.005594089627
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     56   100        0.031       0.0304     0.000124      0.00052        0.971         1.92        0.087        0.123        0.178        0.252
     56   200        0.011       0.0103     7.79e-05     0.000664        0.501         1.12       0.0659       0.0975        0.212        0.285
     56   300      0.00971      0.00827     0.000108      0.00133        0.679         1.01       0.0724        0.115         0.37        0.403
     56   400       0.0447        0.044     0.000102     0.000529         1.23         2.32       0.0743        0.112        0.244        0.254
     56   500       0.0637       0.0613     0.000132      0.00225         1.45         2.74       0.0842        0.127        0.419        0.524
     56   600       0.0182       0.0168      6.1e-05       0.0013        0.684         1.43        0.062       0.0863        0.284        0.398
     56   700        0.028       0.0267     0.000104      0.00119        0.767         1.81       0.0756        0.113        0.374        0.382
     56   800       0.0153       0.0147     8.55e-05     0.000516        0.729         1.34       0.0727        0.102        0.231        0.251
     56   900      0.00773      0.00739     8.66e-05      0.00026        0.553         0.95       0.0707        0.103        0.167        0.178
     56  1000       0.0046      0.00333     0.000126      0.00114        0.472        0.638       0.0798        0.124         0.32        0.373
     56  1100        0.052         0.05      6.8e-05      0.00195          1.2         2.47       0.0629       0.0911        0.399        0.487
     56  1200      0.00403      0.00299     0.000103     0.000941        0.368        0.604       0.0656        0.112        0.265        0.339
     56  1300        0.107        0.106     0.000147     0.000632         1.88          3.6       0.0918        0.134        0.198        0.278
     56  1400       0.0014      0.00113     0.000103     0.000165        0.283        0.372       0.0673        0.112        0.107        0.142
     56  1500        0.055       0.0548     0.000159     8.44e-05          1.5         2.59       0.0873        0.139       0.0783        0.102
     56  1600       0.0936       0.0916     0.000106      0.00184         1.94         3.34       0.0804        0.114        0.433        0.474
     56  1700      0.00385      0.00199     8.82e-05      0.00178        0.382        0.493       0.0747        0.104        0.353        0.466
     56  1800       0.0172       0.0155     8.24e-05      0.00155        0.769         1.38       0.0718          0.1        0.325        0.435
     56  1900        0.043       0.0418     9.93e-05      0.00109        0.997         2.26       0.0773         0.11        0.355        0.365
     56  2000         0.01      0.00965      7.7e-05     0.000309        0.611         1.09       0.0645        0.097        0.172        0.194
     56  2039        0.106        0.106     7.89e-05     0.000163         1.69          3.6       0.0587       0.0981        0.133        0.141

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     56   100      0.00602      0.00559        8e-05     0.000348        0.494        0.826       0.0605       0.0988        0.193        0.206
     56   182        0.114        0.112     3.99e-05      0.00238         2.26         3.69       0.0544       0.0698        0.539        0.539


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              56 5560.867    0.001       0.0275     0.000116     0.000873       0.0285        0.861         1.83       0.0775        0.119        0.252        0.326
! Validation         56 5560.867    0.001       0.0265     8.64e-05      0.00096       0.0275        0.833         1.78       0.0665        0.103        0.265        0.341
Wall time: 5560.868007540703
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     57   100       0.0572       0.0548     0.000177      0.00218         1.39         2.59       0.0963        0.147        0.439        0.516
     57   200        0.146        0.145     9.98e-05      0.00127         1.59          4.2       0.0733         0.11        0.254        0.394
     57   300       0.0639       0.0626     0.000146      0.00123         1.11         2.76       0.0902        0.133        0.342        0.387
     57   400       0.0416       0.0398     7.97e-05      0.00168         1.18          2.2       0.0702       0.0987        0.366        0.453
     57   500      0.00373      0.00161     8.75e-05      0.00202        0.348        0.444       0.0647        0.103        0.446        0.497
     57   600       0.0648       0.0639     6.67e-05     0.000788         1.38         2.79       0.0628       0.0902        0.254         0.31
     57   700       0.0179       0.0174     0.000167     0.000324            1         1.46       0.0909        0.143        0.149        0.199
     57   800        0.032       0.0312     6.69e-05     0.000746        0.954         1.95       0.0563       0.0904        0.287        0.302
     57   900       0.0495       0.0485     0.000144       0.0009         1.03         2.43       0.0805        0.132        0.256        0.331
     57  1000       0.0259        0.025     0.000175     0.000694        0.874         1.75       0.0797        0.146        0.262        0.291
     57  1100       0.0977       0.0968     0.000154     0.000801          1.4         3.44       0.0903        0.137        0.255        0.313
     57  1200      0.00369      0.00279     7.92e-05     0.000825        0.398        0.583       0.0708       0.0983        0.299        0.317
     57  1300       0.0732       0.0726     8.51e-05     0.000507         1.31         2.98       0.0651        0.102        0.167        0.249
     57  1400       0.0615        0.061     0.000194     0.000245         1.84         2.73        0.107        0.154        0.141        0.173
     57  1500       0.0301       0.0293     0.000152     0.000661         1.14         1.89        0.084        0.136        0.189        0.284
     57  1600       0.0328       0.0326     0.000136     3.86e-05         1.23            2        0.081        0.129        0.067       0.0687
     57  1700      0.00577      0.00496     0.000121      0.00069        0.532        0.778       0.0823        0.121        0.226         0.29
     57  1800      0.00465      0.00301     9.09e-05      0.00154        0.395        0.606       0.0663        0.105         0.36        0.434
     57  1900       0.0774       0.0757      0.00011      0.00164         1.21         3.04       0.0686        0.116        0.373        0.447
     57  2000       0.0149       0.0142      0.00015     0.000552        0.818         1.32       0.0917        0.135        0.175         0.26
     57  2039       0.0132       0.0128     9.81e-05     0.000345        0.898         1.25       0.0799        0.109        0.191        0.205

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     57   100      0.00729      0.00684     0.000109     0.000345        0.626        0.914       0.0773        0.116        0.174        0.205
     57   182         0.16        0.159     4.83e-05     0.000808         2.66          4.4       0.0601       0.0768        0.314        0.314


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              57 5659.714    0.001       0.0274     0.000113     0.000879       0.0284        0.854         1.83       0.0765        0.118        0.253        0.328
! Validation         57 5659.714    0.001       0.0249     0.000116     0.000581       0.0256        0.826         1.72       0.0807        0.119        0.208        0.266
Wall time: 5659.71469886601
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     58   100         0.04       0.0391     0.000118     0.000755        0.961         2.18       0.0793         0.12        0.284        0.304
     58   200      0.00843      0.00801      8.6e-05     0.000338        0.573        0.989       0.0712        0.102        0.179        0.203
     58   300      0.00165     0.000905     6.23e-05      0.00068        0.255        0.332       0.0624       0.0872        0.282        0.288
     58   400       0.0527       0.0513     0.000203      0.00124         1.43          2.5        0.113        0.158        0.359         0.39
     58   500       0.0407       0.0392     0.000115      0.00141         1.11         2.19       0.0781        0.118        0.265        0.415
     58   600      0.00895      0.00864     0.000104     0.000207        0.565         1.03       0.0666        0.113        0.126        0.159
     58   700      0.00369      0.00312      8.7e-05     0.000484        0.392        0.617       0.0739        0.103        0.181        0.243
     58   800       0.0138       0.0135     0.000148     0.000151         0.75         1.28       0.0813        0.134        0.108        0.136
     58   900      0.00215       0.0018     8.75e-05     0.000269        0.384        0.468       0.0722        0.103        0.144        0.181
     58  1000       0.0208       0.0168     0.000173      0.00378         0.92         1.43       0.0935        0.145        0.566        0.679
     58  1100       0.0109       0.0104     0.000136     0.000371         0.64         1.13       0.0771        0.129        0.199        0.213
     58  1200       0.0219       0.0212     8.93e-05     0.000657        0.772         1.61        0.065        0.104        0.237        0.283
     58  1300       0.0295       0.0291     6.57e-05     0.000316        0.918         1.89       0.0609       0.0895        0.182        0.196
     58  1400      0.00448      0.00392     0.000165     0.000397        0.487        0.691       0.0988        0.142        0.165         0.22
     58  1500       0.0133       0.0109     0.000112      0.00232        0.733         1.15       0.0732        0.117        0.386        0.532
     58  1600      0.00403      0.00277     0.000161       0.0011        0.424        0.582       0.0891         0.14        0.329        0.366
     58  1700       0.0112      0.00897     0.000134      0.00211        0.602         1.05       0.0858        0.128        0.443        0.508
     58  1800      0.00922      0.00864     0.000185     0.000394        0.513         1.03       0.0925         0.15        0.173        0.219
     58  1900       0.0343       0.0336     0.000102     0.000675         1.02         2.02       0.0657        0.111        0.274        0.287
     58  2000       0.0129       0.0123     0.000126     0.000404        0.717         1.23       0.0803        0.124        0.173        0.222
     58  2039       0.0249       0.0244     8.74e-05     0.000435        0.819         1.72       0.0617        0.103        0.203         0.23

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     58   100      0.00506      0.00343     0.000139      0.00148        0.498        0.647       0.0792         0.13        0.357        0.426
     58   182        0.155        0.155     3.85e-05     0.000174         2.65         4.35       0.0531       0.0685        0.146        0.146


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              58 5758.597    0.001       0.0274     0.000117     0.000896       0.0285        0.859         1.83       0.0773        0.119        0.254        0.331
! Validation         58 5758.597    0.001       0.0256     0.000139     0.000734       0.0265        0.841         1.75       0.0813         0.13        0.229          0.3
Wall time: 5758.597808815539
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     59   100       0.0444       0.0422     0.000153      0.00201         1.01         2.27       0.0815        0.137        0.415        0.495
     59   200       0.0162       0.0155     0.000158      0.00048        0.855         1.38       0.0939        0.139        0.203        0.242
     59   300       0.0131       0.0114     0.000211      0.00149        0.638         1.18        0.104        0.161        0.355        0.426
     59   400       0.0125       0.0117     0.000166     0.000685        0.758         1.19       0.0918        0.142        0.273        0.289
     59   500       0.0316       0.0302     0.000127      0.00132        0.983         1.92       0.0778        0.124        0.284        0.401
     59   600        0.029       0.0275     0.000118      0.00147        0.939         1.83       0.0773         0.12         0.35        0.424
     59   700       0.0325       0.0322     0.000108     0.000174        0.961         1.98       0.0706        0.115        0.145        0.146
     59   800       0.0044       0.0029     5.68e-05      0.00145        0.387        0.595       0.0591       0.0833         0.32         0.42
     59   900       0.0113      0.00975     5.83e-05      0.00153        0.606         1.09       0.0552       0.0843        0.378        0.432
     59  1000       0.0627       0.0619      9.5e-05     0.000684         1.53         2.75       0.0753        0.108        0.231        0.289
     59  1100        0.122         0.12     0.000146      0.00134         2.19         3.83       0.0938        0.133        0.308        0.404
     59  1200      0.00694      0.00659     0.000109     0.000242        0.657        0.897       0.0755        0.116        0.153        0.172
     59  1300      0.00862      0.00816     0.000204     0.000252        0.638        0.998          0.1        0.158        0.135        0.176
     59  1400       0.0424       0.0414     0.000286      0.00073         1.23         2.25        0.106        0.187         0.24        0.298
     59  1500       0.0328       0.0325     0.000124     0.000151        0.899         1.99       0.0822        0.123        0.135        0.136
     59  1600      0.00999      0.00851     0.000122      0.00135        0.718         1.02        0.086        0.122        0.321        0.406
     59  1700       0.0379       0.0368     0.000123     0.000901         1.25         2.12       0.0807        0.123        0.222        0.332
     59  1800      0.00285      0.00127     8.55e-05      0.00149        0.305        0.395       0.0661        0.102        0.322        0.426
     59  1900       0.0238       0.0228     0.000106     0.000844        0.644         1.67       0.0676        0.114          0.3        0.321
     59  2000       0.0297       0.0293     7.37e-05     0.000259        0.822         1.89       0.0616       0.0948        0.144        0.178
     59  2039      0.00985      0.00812     3.58e-05      0.00169         0.62        0.996       0.0496       0.0661        0.357        0.455

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     59   100      0.00503      0.00359     8.22e-05      0.00136        0.452        0.662        0.062          0.1        0.242        0.407
     59   182        0.138        0.138     3.38e-05      6.3e-05         2.49          4.1       0.0499       0.0642       0.0877       0.0877


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              59 5857.583    0.001       0.0274     0.000117     0.000837       0.0283        0.861         1.83       0.0771         0.12        0.248         0.32
! Validation         59 5857.583    0.001       0.0247     8.45e-05      0.00117        0.026        0.771         1.72       0.0656        0.102         0.28        0.379
Wall time: 5857.584515355527
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     60   100      0.00406      0.00371     0.000138     0.000214        0.416        0.673       0.0734         0.13        0.134        0.162
     60   200        0.018       0.0174     8.86e-05     0.000516        0.839         1.46        0.072        0.104        0.218        0.251
     60   300       0.0558       0.0554     8.66e-05     0.000322         1.18          2.6       0.0671        0.103        0.186        0.198
     60   400      0.00841      0.00751     0.000166     0.000734        0.527        0.957       0.0784        0.142        0.263        0.299
     60   500       0.0364       0.0359     0.000121     0.000321        0.999         2.09       0.0858        0.121         0.18        0.198
     60   600       0.0302       0.0296     0.000107     0.000473        0.936          1.9       0.0776        0.114        0.213         0.24
     60   700       0.0173       0.0161     7.59e-05      0.00113        0.716          1.4       0.0651       0.0963        0.258        0.371
     60   800       0.0462       0.0451     9.96e-05      0.00101         1.12         2.35        0.071         0.11        0.332        0.351
     60   900      0.00541      0.00435     0.000129     0.000937        0.525        0.728       0.0848        0.125          0.3        0.338
     60  1000       0.0245       0.0231     8.94e-05      0.00137         1.02         1.68       0.0763        0.104        0.369        0.409
     60  1100        0.186        0.182     0.000169      0.00394         2.07         4.71       0.0838        0.144        0.591        0.693
     60  1200       0.0793       0.0777     0.000149      0.00145         1.38         3.08       0.0897        0.135        0.324        0.421
     60  1300       0.0484       0.0478      7.4e-05     0.000551         1.19         2.42       0.0606       0.0951        0.225        0.259
     60  1400       0.0552       0.0547     0.000105     0.000343         1.46         2.58       0.0689        0.113        0.154        0.205
     60  1500       0.0229       0.0225     0.000133     0.000321        0.939         1.66       0.0771        0.127        0.142        0.198
     60  1600        0.104        0.104     0.000127     0.000239         1.63         3.56       0.0813        0.124        0.105        0.171
     60  1700       0.0949       0.0937     0.000117      0.00113         1.88         3.38       0.0763        0.119        0.334        0.371
     60  1800       0.0511       0.0498     0.000131      0.00125        0.965         2.46       0.0812        0.126         0.33         0.39
     60  1900       0.0356       0.0352     0.000118     0.000325         1.17         2.07       0.0757         0.12        0.169        0.199
     60  2000       0.0233       0.0221     0.000157      0.00113        0.972         1.64       0.0966        0.139        0.269        0.371
     60  2039       0.0683       0.0674     0.000183     0.000692         1.79         2.87        0.102        0.149        0.288        0.291

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     60   100      0.00789      0.00659     0.000132      0.00117        0.619        0.897       0.0773        0.127        0.278        0.378
     60   182        0.122        0.122     4.05e-05     3.25e-05         2.24         3.86       0.0534       0.0703        0.063        0.063


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              60 5956.461    0.001       0.0275     0.000116     0.000861       0.0285        0.853         1.83       0.0765        0.119         0.25        0.324
! Validation         60 5956.461    0.001       0.0252     0.000123     0.000983       0.0263        0.851         1.74       0.0799        0.123        0.267        0.347
Wall time: 5956.462194137275
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     61   100        0.049       0.0484     0.000129     0.000482          1.1         2.43       0.0727        0.126         0.21        0.243
     61   200      0.00417      0.00365     0.000117     0.000398        0.438        0.668       0.0772        0.119        0.143         0.22
     61   300      0.00621      0.00577     9.77e-05     0.000337        0.585         0.84       0.0727        0.109        0.169        0.203
     61   400        0.013       0.0122     0.000123     0.000618         0.73         1.22       0.0814        0.123        0.227        0.275
     61   500       0.0947       0.0939     0.000108     0.000674          1.6         3.39       0.0764        0.115        0.212        0.287
     61   600       0.0102      0.00969     9.18e-05      0.00042        0.606         1.09       0.0721        0.106        0.214        0.226
     61   700       0.0345       0.0326     9.14e-05      0.00184         1.03            2       0.0774        0.106        0.381        0.473
     61   800       0.0285       0.0283     0.000106     9.35e-05         1.11         1.86       0.0761        0.114       0.0868        0.107
     61   900       0.0804       0.0782      0.00012      0.00205         1.32         3.09       0.0794        0.121        0.446        0.501
     61  1000       0.0233       0.0225     7.41e-05     0.000675        0.826         1.66       0.0679       0.0951         0.23        0.287
     61  1100       0.0035      0.00307     9.69e-05     0.000338        0.375        0.612       0.0726        0.109        0.185        0.203
     61  1200      0.00957      0.00885     0.000129     0.000595        0.563         1.04        0.077        0.125        0.238        0.269
     61  1300       0.0142       0.0136     0.000104     0.000512        0.707         1.29       0.0743        0.113        0.235         0.25
     61  1400       0.0655       0.0651     8.58e-05     0.000331          1.2         2.82       0.0714        0.102        0.167        0.201
     61  1500        0.065       0.0639     0.000171     0.000887         1.15         2.79       0.0847        0.145        0.292        0.329
     61  1600       0.0349       0.0348     0.000153      3.3e-05         1.14         2.06       0.0883        0.137       0.0578       0.0635
     61  1700       0.0764       0.0758     8.65e-05     0.000513         1.16         3.04       0.0691        0.103        0.229         0.25
     61  1800       0.0596       0.0588     0.000108     0.000701         1.26         2.68         0.08        0.115        0.274        0.292
     61  1900        0.033       0.0325     0.000135     0.000346         1.01         1.99       0.0836        0.128        0.159        0.205
     61  2000       0.0735       0.0727     0.000179     0.000681         1.42         2.98        0.102        0.148        0.205        0.288
     61  2039       0.0814         0.08     0.000168      0.00122         1.69         3.13       0.0958        0.143        0.383        0.386

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     61   100      0.00794      0.00692     8.64e-05     0.000933        0.573        0.919       0.0687        0.103         0.24        0.337
     61   182        0.134        0.134     3.79e-05     2.54e-05         2.44         4.04       0.0527        0.068       0.0557       0.0557


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              61 6055.365    0.001       0.0273     0.000121     0.000804       0.0282        0.857         1.83       0.0784        0.122        0.244        0.313
! Validation         61 6055.365    0.001       0.0253     0.000104     0.000576        0.026         0.82         1.74       0.0743        0.113        0.207        0.266
Wall time: 6055.3661010712385
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     62   100      0.00685      0.00565     0.000107      0.00109        0.577        0.831       0.0759        0.114        0.315        0.365
     62   200      0.00798      0.00729     0.000177      0.00051        0.502        0.943       0.0777        0.147         0.24        0.249
     62   300       0.0275       0.0267     0.000121     0.000637        0.968         1.81       0.0794        0.122        0.234        0.279
     62   400       0.0109       0.0106     0.000131     0.000191         0.69         1.13        0.081        0.126        0.122        0.153
     62   500      0.00538      0.00459     9.59e-05       0.0007        0.436        0.748       0.0767        0.108        0.259        0.292
     62   600       0.0231       0.0227     6.69e-05     0.000274        0.743         1.67       0.0574       0.0904         0.14        0.183
     62   700      0.00509      0.00394     0.000109      0.00104        0.481        0.693       0.0801        0.116        0.248        0.356
     62   800       0.0982       0.0967     0.000129      0.00132         1.67         3.44       0.0794        0.126        0.338        0.401
     62   900        0.014       0.0137     9.68e-05     0.000184        0.847         1.29       0.0747        0.109         0.13         0.15
     62  1000       0.0217       0.0213     0.000134     0.000261        0.961         1.61       0.0842        0.128        0.149        0.178
     62  1100       0.0073      0.00706     7.57e-05     0.000173        0.575        0.928        0.059       0.0962        0.144        0.145
     62  1200      0.00567      0.00465     8.27e-05     0.000939        0.539        0.753        0.067          0.1         0.31        0.339
     62  1300        0.067       0.0666     0.000125     0.000227         1.17         2.85       0.0776        0.124        0.134        0.166
     62  1400      0.00505      0.00359     9.72e-05      0.00137        0.453        0.662       0.0717        0.109        0.374        0.408
     62  1500       0.0124       0.0118     5.59e-05     0.000497        0.765          1.2       0.0605       0.0826        0.229        0.246
     62  1600       0.0339       0.0327     0.000357     0.000775         1.06            2        0.119        0.209         0.26        0.308
     62  1700      0.00373        0.003     9.93e-05     0.000624        0.474        0.606       0.0769         0.11        0.208        0.276
     62  1800       0.0274       0.0258     7.27e-05       0.0015        0.973         1.78       0.0673       0.0942        0.373        0.428
     62  1900        0.158        0.156      0.00016      0.00165         2.02         4.36       0.0954         0.14        0.394        0.449
     62  2000       0.0595       0.0587     0.000153     0.000703         1.53         2.68       0.0931        0.137        0.251        0.293
     62  2039      0.00473      0.00429     8.48e-05     0.000347        0.532        0.724       0.0773        0.102        0.188        0.206

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     62   100      0.00904      0.00715      0.00013      0.00176        0.645        0.934       0.0826        0.126        0.369        0.463
     62   182        0.125        0.124     6.06e-05     0.000237         2.36          3.9       0.0687        0.086         0.17         0.17


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              62 6154.233    0.001       0.0273     0.000115     0.000782       0.0282        0.857         1.82       0.0767        0.119         0.24        0.309
! Validation         62 6154.233    0.001       0.0242     0.000145     0.000546       0.0249        0.831          1.7        0.088        0.133        0.193        0.259
Wall time: 6154.233726345003
! Best model       62    0.025
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     63   100      0.00468        0.004     9.77e-05     0.000581        0.516        0.699       0.0741        0.109        0.233        0.266
     63   200       0.0833       0.0807     0.000137      0.00242         1.39         3.14       0.0871        0.129         0.46        0.543
     63   300       0.0249       0.0242     0.000174     0.000505        0.797         1.72       0.0919        0.146        0.237        0.248
     63   400       0.0796       0.0787     0.000198     0.000658         1.85          3.1        0.105        0.155        0.238        0.283
     63   500       0.0048      0.00409     0.000106     0.000613        0.512        0.706       0.0794        0.114        0.227        0.274
     63   600        0.113        0.112     0.000166     0.000839         1.47         3.69       0.0828        0.142         0.25         0.32
     63   700       0.0139       0.0132     0.000102     0.000607        0.791         1.27       0.0755        0.112        0.195        0.272
     63   800       0.0162       0.0151     0.000124     0.000986        0.742         1.36       0.0843        0.123        0.307        0.347
     63   900       0.0343       0.0336     0.000151     0.000524          1.3         2.03       0.0978        0.136        0.185        0.253
     63  1000       0.0421       0.0417     7.87e-05     0.000273         1.05         2.26       0.0719        0.098        0.168        0.183
     63  1100      0.00523      0.00491     6.67e-05     0.000259        0.401        0.774       0.0644       0.0902        0.136        0.178
     63  1200       0.0246        0.024     9.27e-05     0.000452        0.952         1.71       0.0631        0.106        0.213        0.235
     63  1300       0.0014      0.00114     9.48e-05     0.000163        0.263        0.374       0.0623        0.108        0.117        0.141
     63  1400      0.00271      0.00165      5.1e-05        0.001        0.317        0.449       0.0543       0.0789        0.309         0.35
     63  1500      0.00635      0.00591     0.000115     0.000328          0.6        0.849       0.0735        0.118        0.182          0.2
     63  1600       0.0689        0.068     0.000128     0.000801         1.39         2.88       0.0828        0.125        0.306        0.313
     63  1700      0.00725      0.00662     9.25e-05     0.000539        0.627        0.899       0.0731        0.106        0.233        0.256
     63  1800       0.0029      0.00173     4.37e-05      0.00113        0.235         0.46       0.0515        0.073        0.291        0.371
     63  1900       0.0139       0.0132     0.000104     0.000596        0.879         1.27       0.0769        0.113        0.242         0.27
     63  2000       0.0513        0.051     0.000188     0.000138          1.5          2.5       0.0928        0.152        0.108         0.13
     63  2039      0.00461       0.0044     4.74e-05     0.000158        0.392        0.733       0.0548       0.0761        0.107        0.139

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     63   100       0.0101      0.00879     0.000111      0.00121        0.602         1.04       0.0738        0.117        0.367        0.384
     63   182        0.117        0.116     4.58e-05      8.6e-05         2.29         3.77       0.0596       0.0748        0.102        0.102


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              63 6253.151    0.001        0.027      0.00012     0.000801        0.028        0.854         1.82        0.078        0.121        0.243        0.313
! Validation         63 6253.151    0.001       0.0251     0.000115      0.00114       0.0263        0.831         1.73       0.0779        0.119         0.31        0.373
Wall time: 6253.152083739638
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     64   100       0.0297       0.0265     0.000263      0.00295         1.11          1.8        0.111        0.179        0.492          0.6
     64   200      0.00171      0.00125     0.000141     0.000323        0.331         0.39       0.0983        0.131         0.17        0.199
     64   300       0.0545       0.0538     0.000144     0.000535         1.18         2.56        0.091        0.133        0.254        0.256
     64   400      0.00684      0.00603     0.000118     0.000694        0.647        0.858       0.0866         0.12         0.23        0.291
     64   500       0.0381       0.0376     0.000132     0.000307         1.18         2.14       0.0847        0.127         0.17        0.194
     64   600       0.0107       0.0101     0.000103     0.000502        0.754         1.11       0.0778        0.112        0.176        0.247
     64   700       0.0198       0.0197     9.65e-05     6.04e-05        0.776         1.55       0.0672        0.109       0.0833       0.0859
     64   800      0.00251      0.00178     8.74e-05     0.000644        0.327        0.466       0.0627        0.103        0.243         0.28
     64   900      0.00408      0.00352     0.000107     0.000461        0.503        0.655       0.0823        0.114        0.207        0.237
     64  1000       0.0277       0.0271     0.000161      0.00041         1.06         1.82       0.0952         0.14        0.205        0.224
     64  1100      0.00508      0.00446      9.7e-05     0.000525        0.503        0.738       0.0763        0.109        0.229        0.253
     64  1200       0.0476       0.0472     0.000149     0.000214         1.17          2.4       0.0879        0.135        0.114        0.162
     64  1300       0.0445       0.0437     0.000147     0.000666         1.33         2.31       0.0889        0.134        0.215        0.285
     64  1400        0.105        0.104     0.000182     0.000407          1.4         3.56       0.0994        0.149         0.18        0.223
     64  1500       0.0463       0.0457     0.000184     0.000507         1.22         2.36       0.0856         0.15        0.177        0.249
     64  1600       0.0701       0.0679     0.000102      0.00217         1.48         2.88       0.0748        0.112        0.464        0.515
     64  1700        0.051        0.044     0.000205      0.00673         1.22         2.32        0.102        0.158        0.718        0.906
     64  1800      0.00832      0.00807     8.53e-05     0.000163        0.494        0.993       0.0619        0.102        0.128        0.141
     64  1900       0.0217       0.0209     0.000119     0.000682        0.804          1.6       0.0803        0.121        0.263        0.289
     64  2000      0.00674      0.00588     6.74e-05       0.0008        0.598        0.847       0.0644       0.0907        0.272        0.312
     64  2039       0.0121       0.0113     0.000107     0.000696        0.643         1.17       0.0708        0.115        0.272        0.291

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     64   100      0.00608      0.00508      0.00012     0.000877        0.553        0.788       0.0744        0.121         0.27        0.327
     64   182        0.144        0.143     4.43e-05     0.000689         2.51         4.18       0.0591       0.0736         0.29         0.29


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              64 6351.933    0.001       0.0272     0.000121     0.000832       0.0282        0.855         1.82       0.0783        0.122        0.242        0.319
! Validation         64 6351.933    0.001       0.0241      0.00012     0.000656       0.0249        0.799          1.7       0.0784        0.121        0.221        0.283
Wall time: 6351.933679513633
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     65   100       0.0273       0.0266     0.000161     0.000557         0.94          1.8       0.0935         0.14        0.251        0.261
     65   200       0.0176       0.0173     7.32e-05     0.000199        0.891         1.45       0.0697       0.0945         0.13        0.156
     65   300       0.0115       0.0104     9.71e-05     0.000994         0.75         1.13       0.0756        0.109        0.314        0.348
     65   400       0.0166       0.0158     0.000122     0.000743        0.711         1.39       0.0794        0.122        0.239        0.301
     65   500        0.016       0.0155     0.000139     0.000282        0.693         1.38       0.0894         0.13        0.159        0.185
     65   600       0.0125      0.00914     0.000109      0.00329        0.755         1.06       0.0783        0.116        0.576        0.634
     65   700        0.176        0.175     0.000147     0.000156         2.07         4.62       0.0892        0.134        0.127        0.138
     65   800      0.00827      0.00751     0.000243     0.000519        0.639        0.957       0.0942        0.172        0.179        0.252
     65   900       0.0105      0.00837     0.000177      0.00195        0.615         1.01       0.0995        0.147        0.399        0.488
     65  1000      0.00846      0.00749     9.94e-05     0.000864        0.543        0.957       0.0688         0.11        0.273        0.325
     65  1100       0.0215       0.0205     0.000114      0.00091         0.72         1.58       0.0853        0.118        0.281        0.333
     65  1200      0.00852      0.00801     0.000116     0.000402        0.641        0.989       0.0817        0.119        0.178        0.222
     65  1300       0.0591       0.0587     0.000127     0.000317         1.08         2.68        0.084        0.125        0.148        0.197
     65  1400         0.01      0.00957     0.000128     0.000356        0.721         1.08       0.0835        0.125        0.148        0.208
     65  1500       0.0169       0.0158     0.000104      0.00103        0.827         1.39       0.0771        0.113        0.342        0.354
     65  1600      0.00556      0.00532     0.000169      7.3e-05        0.563        0.806       0.0933        0.144       0.0865       0.0944
     65  1700      0.00651      0.00542     8.54e-05      0.00101        0.564        0.813       0.0674        0.102        0.332        0.351
     65  1800      0.00366      0.00243     0.000101      0.00113        0.449        0.545       0.0723        0.111        0.318        0.371
     65  1900       0.0582       0.0574      0.00014     0.000669         1.53         2.65       0.0811        0.131        0.238        0.286
     65  2000       0.0121      0.00999     7.55e-05      0.00199        0.648          1.1       0.0669        0.096        0.416        0.493
     65  2039       0.0105       0.0101     0.000253     0.000218        0.816         1.11       0.0982        0.176        0.148        0.163

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     65   100      0.00509      0.00453     0.000121     0.000438        0.512        0.744       0.0737        0.122        0.206        0.231
     65   182        0.144        0.142     3.89e-05      0.00146         2.54         4.16       0.0549        0.069        0.423        0.423


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              65 6450.822    0.001       0.0271     0.000121     0.000764       0.0279        0.853         1.82       0.0786        0.121        0.233        0.305
! Validation         65 6450.822    0.001       0.0242     0.000119     0.000738        0.025        0.798          1.7       0.0757        0.121        0.243        0.299
Wall time: 6450.8227637037635
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     66   100       0.0133       0.0129     0.000135     0.000273        0.655         1.26       0.0871        0.128        0.157        0.183
     66   200       0.0698       0.0692     0.000123     0.000461          1.4         2.91         0.08        0.122        0.204        0.237
     66   300       0.0185        0.017     8.95e-05       0.0014         0.79         1.44       0.0715        0.105        0.371        0.414
     66   400       0.0312       0.0309     0.000205     0.000101         1.18         1.94        0.104        0.158        0.104        0.111
     66   500       0.0451       0.0427     0.000125       0.0023         1.28         2.28        0.087        0.124        0.369         0.53
     66   600        0.053        0.052     0.000134     0.000803         1.45         2.52       0.0859        0.128        0.309        0.313
     66   700        0.058       0.0574     0.000152     0.000454         1.31         2.65       0.0891        0.136        0.184        0.235
     66   800      0.00761      0.00719     0.000158     0.000265        0.714        0.937       0.0927        0.139        0.151         0.18
     66   900        0.032       0.0307     0.000111      0.00119        0.889         1.93       0.0798        0.116        0.345        0.381
     66  1000       0.0388       0.0369     0.000103      0.00182         1.39         2.12       0.0714        0.112        0.364        0.471
     66  1100      0.00516      0.00382      8.4e-05      0.00126        0.508        0.682       0.0691        0.101        0.327        0.392
     66  1200      0.00656      0.00584     7.35e-05     0.000652        0.515        0.844       0.0662       0.0947        0.251        0.282
     66  1300      0.00404      0.00329     9.02e-05     0.000657         0.48        0.634       0.0679        0.105        0.235        0.283
     66  1400       0.0588       0.0581      5.6e-05       0.0006         1.35         2.66       0.0607       0.0827        0.224        0.271
     66  1500       0.0699       0.0685     0.000182      0.00119         1.75         2.89       0.0992        0.149        0.357        0.381
     66  1600       0.0145        0.014     0.000147     0.000323        0.738         1.31       0.0766        0.134         0.19        0.199
     66  1700        0.045       0.0448      4.4e-05     0.000169         1.08         2.34       0.0515       0.0733        0.141        0.144
     66  1800      0.00883      0.00797     0.000151     0.000706        0.628        0.987       0.0949        0.136        0.213        0.294
     66  1900       0.0136       0.0121       0.0001      0.00136        0.737         1.22       0.0744        0.111        0.346        0.408
     66  2000      0.00979      0.00821     0.000105      0.00148        0.585            1       0.0694        0.113         0.38        0.425
     66  2039      0.00749      0.00653     0.000166     0.000789        0.648        0.893         0.09        0.142        0.277         0.31

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     66   100      0.00422      0.00378     9.74e-05     0.000335        0.441         0.68       0.0668        0.109         0.14        0.202
     66   182        0.154        0.154     3.47e-05     0.000401          2.6         4.33       0.0515       0.0651        0.221        0.221


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              66 6549.658    0.001       0.0271      0.00012     0.000816        0.028        0.852         1.82       0.0781        0.121        0.244        0.316
! Validation         66 6549.658    0.001       0.0245     9.92e-05     0.000524       0.0252        0.791         1.71       0.0699         0.11        0.197        0.253
Wall time: 6549.658863060176
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     67   100      0.00586       0.0052     7.42e-05     0.000589        0.525        0.797       0.0635       0.0951        0.201        0.268
     67   200      0.00304      0.00257     5.11e-05     0.000427        0.311         0.56       0.0531        0.079          0.2        0.228
     67   300       0.0471       0.0466     0.000154     0.000329         1.25         2.38       0.0976        0.137        0.171          0.2
     67   400       0.0113      0.00988      0.00017      0.00127        0.718          1.1       0.0842        0.144        0.299        0.394
     67   500      0.00257      0.00206     0.000104     0.000408        0.338        0.502       0.0749        0.112        0.197        0.223
     67   600       0.0787       0.0779     0.000162     0.000614         1.48         3.08       0.0934        0.141        0.214        0.274
     67   700       0.0201       0.0193     0.000107     0.000672        0.823         1.54       0.0811        0.115        0.252        0.287
     67   800      0.00333      0.00241     0.000184     0.000743        0.424        0.542        0.101         0.15        0.246        0.301
     67   900       0.0122       0.0115     8.36e-05     0.000585         0.68         1.19       0.0633        0.101        0.236        0.267
     67  1000       0.0105      0.00907     0.000106      0.00128        0.638         1.05        0.076        0.114        0.344        0.395
     67  1100        0.012       0.0106     7.22e-05      0.00127        0.724         1.14       0.0645       0.0939        0.321        0.393
     67  1200       0.0574       0.0569     0.000161     0.000334         1.46         2.64       0.0964         0.14        0.175        0.202
     67  1300       0.0168       0.0166      9.8e-05     3.99e-05        0.768         1.42       0.0757        0.109        0.055       0.0698
     67  1400       0.0059      0.00534     0.000126     0.000436         0.54        0.807       0.0772        0.124        0.228        0.231
     67  1500      0.00289       0.0022     5.21e-05     0.000636        0.368        0.519       0.0604       0.0798        0.196        0.279
     67  1600      0.00651      0.00626     7.54e-05     0.000174        0.573        0.874       0.0673        0.096        0.126        0.146
     67  1700      0.00352      0.00307      0.00012     0.000331        0.384        0.613       0.0805        0.121        0.171        0.201
     67  1800       0.0498       0.0489     0.000103     0.000784         1.24         2.44       0.0791        0.112        0.262        0.309
     67  1900       0.0516        0.051     0.000115     0.000467         1.31         2.49       0.0743        0.118        0.208        0.239
     67  2000       0.0337       0.0334     0.000112     0.000206        0.972         2.02       0.0771        0.117        0.105        0.159
     67  2039       0.0466       0.0457     6.63e-05     0.000829         1.53         2.36       0.0663         0.09        0.229        0.318

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     67   100      0.00446      0.00366     9.76e-05     0.000705        0.447        0.668       0.0699        0.109        0.259        0.293
     67   182        0.153        0.153      4.2e-05      0.00034         2.57         4.32       0.0559       0.0716        0.204        0.204


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              67 6648.483    0.001       0.0271     0.000118     0.000761       0.0279        0.853         1.82       0.0782         0.12        0.235        0.305
! Validation         67 6648.483    0.001       0.0252     0.000112     0.000466       0.0257        0.821         1.73       0.0766        0.117        0.186        0.239
Wall time: 6648.483596257865
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     68   100      0.00444      0.00327     0.000127      0.00104        0.363        0.632       0.0786        0.124        0.334        0.357
     68   200       0.0118      0.00799     7.93e-05      0.00375        0.687        0.988       0.0667       0.0984        0.556        0.677
     68   300       0.0522       0.0514     0.000154     0.000616         1.45         2.51        0.097        0.137         0.24        0.274
     68   400      0.00206      0.00175     0.000105     0.000202        0.352        0.462       0.0786        0.113        0.135        0.157
     68   500       0.0186       0.0182     7.71e-05     0.000269        0.834         1.49       0.0691        0.097        0.146        0.181
     68   600      0.00331      0.00289     9.38e-05     0.000328        0.453        0.594       0.0681        0.107        0.172          0.2
     68   700      0.00661      0.00585     0.000122     0.000634         0.61        0.845       0.0795        0.122        0.239        0.278
     68   800       0.0594       0.0579     0.000272      0.00131         1.53         2.66        0.113        0.182        0.364          0.4
     68   900        0.045       0.0445     0.000101     0.000335            1         2.33        0.073        0.111        0.165        0.202
     68  1000      0.00284      0.00192     0.000117     0.000798        0.349        0.485        0.078         0.12        0.248        0.312
     68  1100       0.0111       0.0108     0.000113     0.000169        0.601         1.15       0.0804        0.117         0.14        0.144
     68  1200       0.0723       0.0722     9.42e-05      3.2e-05         1.32         2.97       0.0733        0.107       0.0582       0.0625
     68  1300       0.0834        0.083     0.000169     0.000302         1.96         3.18        0.098        0.144        0.183        0.192
     68  1400         0.06        0.058     0.000124      0.00189         1.38         2.66       0.0848        0.123        0.452         0.48
     68  1500       0.0309       0.0298     0.000135      0.00104        0.802         1.91       0.0781        0.128        0.298        0.356
     68  1600       0.0642       0.0635     0.000115     0.000591         1.32         2.78       0.0777        0.119         0.25        0.269
     68  1700      0.00939      0.00909     0.000116     0.000184        0.652         1.05       0.0798        0.119        0.114         0.15
     68  1800       0.0177       0.0165     8.39e-05      0.00116        0.655         1.42       0.0678        0.101        0.355        0.377
     68  1900       0.0278        0.027     0.000122     0.000587        0.885         1.82       0.0877        0.122         0.23        0.268
     68  2000       0.0356       0.0349     0.000119     0.000532         1.17         2.06       0.0862        0.121         0.21        0.255
     68  2039      0.00427      0.00418     8.25e-05     6.39e-06        0.544        0.715       0.0721          0.1       0.0206       0.0279

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     68   100      0.00607      0.00558     0.000109     0.000377        0.563        0.826       0.0719        0.115        0.209        0.215
     68   182        0.139        0.139      3.8e-05     0.000662         2.49         4.11       0.0538       0.0681        0.284        0.284


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              68 6747.315    0.001        0.027     0.000119     0.000772       0.0279        0.852         1.82       0.0778         0.12        0.237        0.307
! Validation         68 6747.315    0.001       0.0243     0.000114     0.000523       0.0249        0.795          1.7       0.0764        0.118          0.2        0.252
Wall time: 6747.315680667758
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     69   100      0.00754      0.00634      0.00021     0.000996        0.618         0.88        0.109         0.16        0.251        0.349
     69   200      0.00786      0.00715     0.000152     0.000561        0.611        0.934       0.0885        0.136        0.225        0.262
     69   300      0.00428      0.00415     7.68e-05     4.46e-05        0.509        0.712       0.0699       0.0968       0.0614       0.0738
     69   400       0.0326       0.0323     8.05e-05     0.000206        0.871         1.98       0.0683       0.0992        0.141        0.159
     69   500       0.0348       0.0337     0.000122      0.00101        0.911         2.03       0.0769        0.122        0.246        0.351
     69   600      0.00591      0.00449     0.000121       0.0013        0.451         0.74       0.0794        0.122        0.394        0.398
     69   700      0.00662      0.00622     0.000115     0.000286        0.523        0.872       0.0837        0.119        0.144        0.187
     69   800       0.0165       0.0156     0.000131     0.000784        0.652         1.38       0.0835        0.126        0.259        0.309
     69   900       0.0276        0.027     0.000154     0.000456        0.818         1.81       0.0864        0.137        0.189        0.236
     69  1000      0.00794      0.00739     9.35e-05     0.000461        0.645         0.95       0.0773        0.107        0.188        0.237
     69  1100       0.0726       0.0709     0.000265      0.00151         1.38         2.94        0.125         0.18        0.356         0.43
     69  1200        0.013       0.0118     9.55e-05      0.00115        0.724          1.2       0.0704        0.108        0.304        0.375
     69  1300       0.0298       0.0281     0.000119      0.00156         1.04         1.85        0.083         0.12        0.415        0.436
     69  1400         0.02       0.0196     0.000148     0.000265        0.712         1.55       0.0804        0.134        0.152         0.18
     69  1500        0.051       0.0494     0.000101      0.00154        0.951         2.46        0.066        0.111        0.371        0.434
     69  1600       0.0204       0.0197     7.52e-05      0.00069        0.692         1.55       0.0643       0.0958        0.254         0.29
     69  1700        0.103        0.102     0.000126     0.000783         1.56         3.52       0.0847        0.124        0.271        0.309
     69  1800       0.0493       0.0461     0.000132      0.00301         1.02         2.37       0.0786        0.127         0.53        0.606
     69  1900       0.0152        0.013     7.11e-05      0.00213        0.718         1.26       0.0643       0.0931        0.443         0.51
     69  2000       0.0164       0.0156     0.000112     0.000623        0.841         1.38       0.0833        0.117        0.232        0.276
     69  2039      0.00437      0.00415     7.52e-05     0.000149        0.507        0.712       0.0646       0.0958        0.128        0.135

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     69   100      0.00596       0.0054      0.00012     0.000437        0.518        0.812       0.0762        0.121        0.187        0.231
     69   182        0.151        0.151     4.84e-05     0.000292         2.59         4.29       0.0614       0.0768        0.189        0.189


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              69 6846.173    0.001        0.027      0.00012     0.000733       0.0279        0.852         1.82       0.0781        0.121        0.231        0.299
! Validation         69 6846.173    0.001       0.0243     0.000128     0.000433       0.0249         0.81          1.7       0.0813        0.125        0.179         0.23
Wall time: 6846.174056082964
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     70   100       0.0039      0.00231     7.21e-05      0.00152        0.329        0.531       0.0657       0.0938        0.365        0.431
     70   200       0.0415       0.0411     0.000159     0.000231         1.16         2.24       0.0868        0.139        0.157        0.168
     70   300       0.0243       0.0232     0.000146      0.00093        0.917         1.68       0.0915        0.133        0.286        0.337
     70   400       0.0335       0.0311      0.00011      0.00227         1.01         1.95       0.0755        0.116        0.482        0.526
     70   500       0.0048      0.00398      0.00016     0.000651        0.458        0.697       0.0861         0.14        0.257        0.282
     70   600       0.0216       0.0206     0.000132     0.000829        0.891         1.59       0.0864        0.127        0.295        0.318
     70   700       0.0176       0.0172     7.34e-05     0.000356        0.774         1.45       0.0653       0.0947        0.132        0.208
     70   800       0.0414        0.041     0.000103     0.000217         1.07         2.24       0.0796        0.112        0.139        0.163
     70   900      0.00525      0.00449      9.1e-05      0.00067        0.532         0.74       0.0694        0.105        0.251        0.286
     70  1000        0.052       0.0511     7.99e-05     0.000876         1.16          2.5       0.0678       0.0988        0.258        0.327
     70  1100       0.0379       0.0372     8.13e-05     0.000588         1.16         2.13       0.0675       0.0996        0.238        0.268
     70  1200      0.00841      0.00745     8.95e-05     0.000867         0.56        0.954       0.0712        0.105        0.295        0.325
     70  1300       0.0102      0.00972     0.000148     0.000294        0.663         1.09       0.0829        0.134        0.183        0.189
     70  1400      0.00812      0.00792     0.000114     8.17e-05        0.629        0.983       0.0769        0.118       0.0949       0.0999
     70  1500       0.0101      0.00918     0.000105     0.000795        0.657         1.06       0.0808        0.113        0.306        0.312
     70  1600       0.0523       0.0521     7.97e-05      0.00014         1.14         2.52       0.0645       0.0987       0.0987        0.131
     70  1700       0.0932        0.093      9.5e-05     0.000142         1.42         3.37       0.0735        0.108        0.117        0.132
     70  1800       0.0353       0.0343     9.22e-05      0.00086         1.05         2.05        0.073        0.106        0.251        0.324
     70  1900       0.0759       0.0745     0.000204      0.00112         1.69         3.02        0.101        0.158        0.294        0.369
     70  2000      0.00679      0.00634     0.000142     0.000314        0.542         0.88       0.0817        0.132        0.156        0.196
     70  2039      0.00654      0.00577      0.00012     0.000644        0.652         0.84       0.0787        0.121        0.212         0.28

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     70   100      0.00419      0.00378     0.000102     0.000309        0.499        0.679       0.0653        0.112         0.16        0.194
     70   182        0.159        0.158     3.82e-05      0.00087         2.66          4.4       0.0541       0.0682        0.326        0.326


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              70 6945.130    0.001       0.0269     0.000122     0.000754       0.0278        0.853         1.81       0.0786        0.122        0.235        0.303
! Validation         70 6945.130    0.001       0.0245     0.000102     0.000637       0.0253        0.795         1.71       0.0711        0.112        0.209        0.279
Wall time: 6945.13096576184
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     71   100       0.0286       0.0283        6e-05     0.000221        0.708         1.86       0.0551       0.0856        0.121        0.164
     71   200        0.032       0.0314     7.84e-05     0.000589        0.955         1.96       0.0636       0.0978        0.216        0.268
     71   300       0.0138       0.0129      0.00011     0.000812        0.653         1.25       0.0739        0.116        0.275        0.315
     71   400       0.0124       0.0122     0.000177     7.64e-05        0.634         1.22       0.0924        0.147       0.0827       0.0966
     71   500       0.0486        0.048     8.38e-05     0.000457        0.946         2.42       0.0667        0.101        0.216        0.236
     71   600       0.0876       0.0872     8.36e-05     0.000285         1.25         3.26       0.0638        0.101        0.145        0.187
     71   700       0.0119       0.0112     0.000121     0.000586        0.566         1.17       0.0812        0.122        0.224        0.267
     71   800       0.0108       0.0104     8.29e-05     0.000312        0.637         1.13       0.0663        0.101        0.145        0.195
     71   900       0.0411        0.041     6.91e-05     6.06e-05         1.31         2.24       0.0586       0.0918       0.0704        0.086
     71  1000      0.00415      0.00314     0.000103     0.000905         0.44         0.62       0.0708        0.112        0.317        0.332
     71  1100      0.00665      0.00657     7.66e-05     2.72e-06        0.575        0.895       0.0604       0.0967       0.0126       0.0182
     71  1200       0.0565       0.0534     0.000253      0.00287         1.53         2.55        0.107        0.176        0.469        0.592
     71  1300      0.00514      0.00481     0.000164     0.000166         0.48        0.766       0.0895        0.142        0.112        0.142
     71  1400      0.00756      0.00718     0.000143     0.000241        0.605        0.936       0.0872        0.132        0.136        0.172
     71  1500      0.00422      0.00216     8.06e-05      0.00199        0.383        0.513       0.0694       0.0992        0.379        0.493
     71  1600       0.0558       0.0546     0.000115      0.00108         1.26         2.58       0.0777        0.119        0.313        0.363
     71  1700       0.0369       0.0361     0.000147      0.00067            1          2.1       0.0875        0.134        0.244        0.286
     71  1800       0.0398       0.0372     0.000133      0.00243         1.13         2.13       0.0842        0.127        0.504        0.544
     71  1900        0.022       0.0215     9.52e-05     0.000464        0.924         1.62       0.0689        0.108        0.209        0.238
     71  2000       0.0145       0.0115     0.000149      0.00283        0.726         1.18       0.0894        0.135         0.51        0.588
     71  2039        0.136        0.135     0.000139     0.000998          2.6         4.06       0.0925         0.13        0.317        0.349

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     71   100      0.00878      0.00723     0.000115      0.00144        0.648        0.939       0.0755        0.118        0.306        0.419
     71   182        0.103        0.103     4.96e-05        2e-05         2.12         3.55       0.0594       0.0778       0.0495       0.0495


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              71 7043.986    0.001        0.027     0.000118     0.000717       0.0278        0.848         1.81       0.0769         0.12        0.229        0.296
! Validation         71 7043.986    0.001       0.0247     0.000136     0.000554       0.0254        0.848         1.72       0.0819        0.129        0.202        0.261
Wall time: 7043.987371660769
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     72   100       0.0054      0.00444     0.000138     0.000817        0.548        0.736       0.0883         0.13        0.285        0.316
     72   200      0.00388      0.00359     7.94e-05     0.000211        0.443        0.662       0.0686       0.0984        0.149        0.161
     72   300      0.00615       0.0053       0.0001     0.000751        0.497        0.804       0.0732         0.11        0.249        0.303
     72   400      0.00684      0.00607      0.00014     0.000631        0.533        0.861       0.0796        0.131         0.23        0.278
     72   500      0.00335      0.00158     0.000162      0.00161        0.282        0.439       0.0827         0.14        0.366        0.443
     72   600      0.00918      0.00676     0.000172      0.00225        0.591        0.909       0.0937        0.145        0.443        0.524
     72   700       0.0304       0.0296      8.8e-05       0.0007        0.851          1.9       0.0739        0.104         0.28        0.292
     72   800       0.0168       0.0152     0.000105      0.00149        0.638         1.36       0.0756        0.113        0.354        0.426
     72   900       0.0366       0.0361     9.82e-05     0.000382        0.987          2.1       0.0739        0.109        0.127        0.216
     72  1000      0.00753      0.00733     0.000102     9.33e-05        0.615        0.946        0.077        0.112       0.0705        0.107
     72  1100        0.114        0.114     0.000107     8.24e-05         1.73         3.72       0.0737        0.114       0.0862          0.1
     72  1200       0.0482       0.0479     0.000139     0.000198         1.18         2.42       0.0938         0.13        0.135        0.155
     72  1300         0.03       0.0287     0.000138      0.00108        0.945         1.87       0.0812         0.13        0.312        0.363
     72  1400      0.00228      0.00118     0.000137     0.000961        0.303         0.38       0.0843        0.129        0.296        0.343
     72  1500       0.0146        0.013     9.83e-05      0.00153        0.656         1.26       0.0671         0.11         0.36        0.432
     72  1600      0.00973      0.00944     0.000104     0.000193        0.553         1.07       0.0792        0.113        0.142        0.154
     72  1700      0.00275      0.00252     7.49e-05     0.000159        0.421        0.555       0.0706       0.0956        0.106        0.139
     72  1800      0.00432      0.00375     7.11e-05     0.000503         0.49        0.677        0.057       0.0932        0.168        0.248
     72  1900       0.0292       0.0287     8.72e-05     0.000407         0.93         1.87       0.0707        0.103        0.215        0.223
     72  2000       0.0179       0.0173     0.000108     0.000565        0.846         1.45       0.0725        0.115        0.216        0.263
     72  2039      0.00251      0.00222     0.000209     8.02e-05        0.361        0.521        0.106         0.16       0.0741        0.099

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     72   100      0.00704      0.00651     0.000103     0.000424        0.532        0.891       0.0697        0.112        0.184        0.227
     72   182        0.166        0.165     3.87e-05     0.000598         2.71         4.49       0.0545       0.0688         0.27         0.27


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              72 7142.855    0.001       0.0268     0.000121     0.000718       0.0277        0.854         1.81       0.0784        0.122         0.23        0.296
! Validation         72 7142.855    0.001       0.0252     0.000107     0.000457       0.0257        0.819         1.73       0.0736        0.114        0.183        0.236
Wall time: 7142.856808416545
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     73   100       0.0141       0.0137     0.000127     0.000246        0.778         1.29       0.0801        0.125        0.152        0.173
     73   200       0.0462       0.0451     0.000128     0.000978         1.03         2.35       0.0728        0.125        0.312        0.346
     73   300       0.0167       0.0164     0.000141      0.00023        0.825         1.41        0.078        0.131        0.127        0.168
     73   400      0.00557      0.00509     9.43e-05     0.000385        0.525        0.788       0.0744        0.107        0.178        0.217
     73   500      0.00398      0.00242     8.77e-05      0.00146        0.394        0.544       0.0695        0.103        0.392        0.423
     73   600      0.00397      0.00313     0.000167      0.00067        0.464        0.618       0.0837        0.143        0.276        0.286
     73   700       0.0183       0.0169     0.000127      0.00125        0.787         1.44       0.0824        0.125        0.356        0.391
     73   800       0.0105       0.0101     0.000147     0.000219        0.741         1.11       0.0813        0.134        0.155        0.164
     73   900        0.041       0.0403     0.000119     0.000524         1.16         2.22       0.0719         0.12        0.157        0.253
     73  1000        0.058       0.0578     9.09e-05     8.18e-05         1.01         2.66       0.0734        0.105       0.0969          0.1
     73  1100      0.00965      0.00909     6.55e-05     0.000497        0.612         1.05       0.0645       0.0894        0.177        0.246
     73  1200      0.00338       0.0029     0.000118      0.00036        0.492        0.595       0.0848         0.12         0.18         0.21
     73  1300       0.0119       0.0113     0.000126     0.000506        0.737         1.17       0.0794        0.124        0.172        0.249
     73  1400      0.00196     0.000838     8.94e-05      0.00103         0.23         0.32        0.075        0.104        0.313        0.355
     73  1500        0.109        0.108     0.000118     0.000433          2.1         3.63       0.0821         0.12        0.189         0.23
     73  1600      0.00969      0.00883     0.000143     0.000715        0.727         1.04        0.094        0.132        0.259        0.295
     73  1700      0.00697      0.00677     0.000124      7.1e-05        0.591        0.909       0.0863        0.123       0.0821       0.0931
     73  1800      0.00458      0.00367     6.79e-05     0.000848        0.438        0.669       0.0578       0.0911        0.228        0.322
     73  1900       0.0384       0.0376     0.000136     0.000678         1.04         2.14       0.0851        0.129        0.273        0.288
     73  2000       0.0401       0.0399     0.000178     5.76e-05         1.05         2.21        0.092        0.147         0.07       0.0839
     73  2039      0.00347      0.00339     3.79e-05     4.37e-05        0.509        0.643       0.0475        0.068       0.0609        0.073

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     73   100      0.00795      0.00743     0.000108     0.000413        0.561        0.952       0.0708        0.115        0.168        0.225
     73   182        0.133        0.132     4.31e-05     0.000889         2.48         4.01       0.0568       0.0726        0.329        0.329


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              73 7241.629    0.001       0.0268     0.000122     0.000678       0.0276        0.852         1.81       0.0786        0.122        0.223        0.288
! Validation         73 7241.629    0.001       0.0248     0.000112     0.000625       0.0255        0.817         1.72       0.0757        0.117         0.21        0.276
Wall time: 7241.630165360868
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     74   100       0.0755       0.0743      0.00015      0.00106          1.5         3.01         0.09        0.135        0.315         0.36
     74   200       0.0487       0.0484      0.00016      0.00016         1.29         2.43       0.0896         0.14         0.12         0.14
     74   300       0.0134       0.0127     0.000133     0.000534        0.873         1.25       0.0838        0.127        0.217        0.255
     74   400      0.00272      0.00244     6.49e-05      0.00022        0.361        0.546       0.0575        0.089         0.16        0.164
     74   500       0.0189       0.0179     0.000144      0.00084         0.78         1.48       0.0908        0.133        0.305         0.32
     74   600       0.0622       0.0619     0.000101     0.000167         1.05         2.75       0.0758        0.111       0.0836        0.143
     74   700       0.0145       0.0132     6.32e-05      0.00116        0.542         1.27       0.0554       0.0878        0.328        0.376
     74   800       0.0104      0.00996     0.000117     0.000306        0.696          1.1        0.075         0.12        0.177        0.193
     74   900       0.0522       0.0514     0.000105     0.000709         1.21          2.5       0.0702        0.113        0.217        0.294
     74  1000       0.0192       0.0187     0.000129     0.000369        0.771         1.51       0.0741        0.125        0.141        0.212
     74  1100       0.0236       0.0233     0.000143     0.000201         1.06         1.69       0.0875        0.132        0.134        0.157
     74  1200       0.0172       0.0159     8.07e-05      0.00127        0.712         1.39       0.0671       0.0992        0.278        0.394
     74  1300        0.016       0.0156     0.000131     0.000268        0.682         1.38       0.0894        0.126        0.151        0.181
     74  1400       0.0306       0.0299     0.000207     0.000554         1.09         1.91       0.0988        0.159        0.252         0.26
     74  1500       0.0157       0.0152      9.6e-05     0.000391        0.742         1.36        0.068        0.108        0.173        0.218
     74  1600        0.112        0.111     0.000208     0.000784         1.69         3.67        0.105        0.159        0.262        0.309
     74  1700       0.0274       0.0266     0.000241     0.000497         1.11          1.8        0.114        0.171        0.222        0.246
     74  1800       0.0361        0.036     0.000105     3.38e-05         1.09          2.1       0.0683        0.113       0.0618       0.0643
     74  1900       0.0032      0.00272      0.00015     0.000329        0.407        0.576       0.0852        0.135        0.177          0.2
     74  2000       0.0262       0.0257     0.000111     0.000393        0.964         1.77        0.071        0.116        0.207        0.219
     74  2039      0.00153      0.00111      4.5e-05     0.000378        0.283        0.368       0.0506       0.0741        0.201        0.215

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     74   100      0.00544      0.00443     0.000101     0.000909        0.492        0.735       0.0685        0.111        0.323        0.333
     74   182        0.142        0.142     4.27e-05     1.27e-05         2.48         4.16       0.0563       0.0722       0.0394       0.0394


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              74 7340.514    0.001       0.0268      0.00012     0.000686       0.0276         0.85         1.81       0.0777        0.121        0.225        0.289
! Validation         74 7340.514    0.001       0.0242     0.000116     0.000792       0.0251        0.804          1.7       0.0765        0.119        0.251        0.312
Wall time: 7340.515311308205
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     75   100       0.0294       0.0291      0.00016     7.86e-05         1.03         1.89       0.0848         0.14       0.0889       0.0979
     75   200      0.00991      0.00874     0.000118      0.00104        0.574         1.03       0.0826         0.12        0.333        0.357
     75   300       0.0366       0.0362     0.000151     0.000205        0.997          2.1       0.0923        0.136        0.145        0.158
     75   400       0.0166       0.0158     0.000119     0.000722         0.85         1.39       0.0849         0.12        0.256        0.297
     75   500      0.00625       0.0052     0.000196     0.000851        0.494        0.797        0.108        0.155         0.26        0.322
     75   600      0.00838      0.00819     6.33e-05     0.000127        0.554            1       0.0632       0.0879        0.108        0.124
     75   700      0.00535      0.00432     0.000154     0.000869        0.535        0.727       0.0905        0.137        0.306        0.326
     75   800      0.00636      0.00615     8.71e-05     0.000128        0.531        0.866       0.0674        0.103        0.106        0.125
     75   900       0.0282       0.0276     0.000114     0.000391        0.973         1.84       0.0748        0.118        0.203        0.219
     75  1000       0.0402       0.0394     0.000139     0.000604         1.05         2.19        0.087         0.13        0.231        0.272
     75  1100       0.0257       0.0252      0.00016     0.000408         1.19         1.75       0.0888         0.14        0.196        0.223
     75  1200      0.00848      0.00754     0.000101     0.000836        0.506        0.959       0.0719        0.111         0.29         0.32
     75  1300       0.0348       0.0345     0.000135     0.000173        0.818         2.05       0.0834        0.128        0.129        0.145
     75  1400      0.00874       0.0085     0.000137     0.000105        0.653         1.02       0.0869        0.129       0.0742        0.113
     75  1500      0.00673      0.00617     0.000115     0.000443         0.58        0.868       0.0776        0.119        0.202        0.233
     75  1600       0.0137       0.0129     7.18e-05     0.000708        0.713         1.26       0.0625       0.0937        0.284        0.294
     75  1700       0.0385       0.0382     0.000121     0.000185          1.2         2.16       0.0808        0.121        0.108         0.15
     75  1800      0.00759      0.00689     4.82e-05     0.000652        0.499        0.917       0.0544       0.0767        0.241        0.282
     75  1900      0.00499      0.00403     7.34e-05     0.000894        0.437        0.701        0.061       0.0947        0.273         0.33
     75  2000       0.0269       0.0248     0.000157      0.00199        0.761         1.74       0.0848        0.139        0.332        0.493
     75  2039      0.00233      0.00188     0.000131     0.000314        0.368        0.479         0.09        0.126        0.194        0.196

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     75   100      0.00549      0.00524     9.92e-05     0.000147        0.567          0.8       0.0667         0.11        0.115        0.134
     75   182        0.132        0.131     4.23e-05      0.00043         2.43            4       0.0561       0.0718        0.229        0.229


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              75 7439.376    0.001       0.0268     0.000121     0.000689       0.0276        0.848         1.81       0.0783        0.121        0.224         0.29
! Validation         75 7439.376    0.001       0.0247     0.000108     0.000459       0.0253        0.828         1.72       0.0737        0.115        0.183        0.237
Wall time: 7439.376866407692
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     76   100       0.0104       0.0101     0.000118     0.000202        0.598         1.11       0.0785         0.12        0.125        0.157
     76   200        0.042        0.041     7.08e-05     0.000942         1.06         2.24       0.0649        0.093          0.3        0.339
     76   300       0.0066      0.00565      8.4e-05     0.000865        0.519        0.831       0.0724        0.101        0.283        0.325
     76   400        0.109        0.108     9.07e-05     0.000406         1.79         3.63       0.0695        0.105        0.176        0.223
     76   500       0.0261       0.0257     8.79e-05     0.000249        0.771         1.77       0.0672        0.104        0.151        0.174
     76   600       0.0416       0.0412     0.000164     0.000234         1.13         2.24       0.0882        0.141        0.152        0.169
     76   700       0.0509       0.0502     0.000107     0.000577         1.38         2.48       0.0793        0.114        0.216        0.265
     76   800      0.00267      0.00224      0.00013     0.000297        0.276        0.523       0.0709        0.126        0.183         0.19
     76   900        0.046       0.0451     6.76e-05     0.000794         1.01         2.35       0.0615       0.0908         0.21        0.311
     76  1000       0.0144        0.011     9.27e-05       0.0033        0.555         1.16       0.0661        0.106        0.463        0.635
     76  1100       0.0199       0.0193     0.000202     0.000392         0.72         1.53       0.0869        0.157        0.199        0.219
     76  1200      0.00273      0.00206     0.000141     0.000527        0.334        0.501       0.0738        0.131        0.231        0.254
     76  1300       0.0138       0.0112     0.000111      0.00257         0.78         1.17         0.08        0.117        0.531         0.56
     76  1400       0.0142       0.0136      9.1e-05      0.00045         0.68         1.29       0.0625        0.105        0.193        0.234
     76  1500       0.0049      0.00346     0.000157      0.00129        0.503         0.65       0.0959        0.139        0.357        0.397
     76  1600      0.00139      0.00126       0.0001     3.03e-05        0.312        0.392       0.0637        0.111       0.0544       0.0608
     76  1700      0.00357      0.00278     7.99e-05     0.000715        0.393        0.582       0.0637       0.0988        0.288        0.295
     76  1800       0.0132        0.012     0.000106      0.00104        0.615         1.21       0.0735        0.114        0.328        0.356
     76  1900      0.00449      0.00353     0.000142     0.000819        0.441        0.656       0.0864        0.132        0.305        0.316
     76  2000       0.0135       0.0112     0.000196      0.00212        0.703         1.17       0.0961        0.155        0.351        0.509
     76  2039      0.00332      0.00306     8.99e-05     0.000172         0.39        0.611        0.071        0.105        0.113        0.145

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     76   100      0.00915      0.00861     0.000106     0.000435        0.655         1.03       0.0712        0.114        0.161         0.23
     76   182        0.101        0.101     4.47e-05     0.000611         2.14         3.51        0.059       0.0739        0.273        0.273


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              76 7538.369    0.001       0.0267     0.000118     0.000668       0.0275         0.85         1.81       0.0774         0.12        0.221        0.286
! Validation         76 7538.369    0.001        0.026     0.000114     0.000738       0.0268         0.89         1.77       0.0769        0.118        0.228          0.3
Wall time: 7538.369780704379
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     77   100      0.00366      0.00318     0.000206      0.00028        0.399        0.623        0.089        0.158        0.147        0.185
     77   200      0.00698      0.00643     0.000102     0.000441        0.417        0.886        0.065        0.112        0.211        0.232
     77   300       0.0196       0.0194     8.93e-05     0.000118        0.717         1.54       0.0652        0.104          0.1         0.12
     77   400       0.0422       0.0412     0.000126     0.000829         1.01         2.24       0.0773        0.124        0.298        0.318
     77   500      0.00227      0.00187     7.58e-05     0.000315        0.354        0.478       0.0571       0.0962        0.166        0.196
     77   600      0.00248      0.00148     0.000138     0.000862        0.309        0.425       0.0797         0.13        0.246        0.324
     77   700       0.0337       0.0329      8.2e-05     0.000742        0.825            2       0.0662          0.1        0.272        0.301
     77   800       0.0318       0.0308     0.000119     0.000934        0.991         1.94       0.0812         0.12        0.299        0.338
     77   900       0.0658       0.0653     0.000172     0.000312          1.3         2.82       0.0817        0.145        0.165        0.195
     77  1000       0.0392       0.0376     0.000199      0.00144         1.14         2.14       0.0986        0.156        0.328        0.419
     77  1100       0.0173        0.017     7.68e-05     0.000213        0.609         1.44       0.0631       0.0968        0.152        0.161
     77  1200       0.0222       0.0212     0.000101     0.000915        0.896         1.61       0.0726        0.111         0.24        0.334
     77  1300      0.00282      0.00251     8.36e-05     0.000224        0.405        0.553       0.0722        0.101         0.14        0.165
     77  1400       0.0453        0.045     0.000106     0.000251         1.03         2.34       0.0736        0.114         0.13        0.175
     77  1500       0.0397       0.0375     0.000201      0.00203         1.06         2.14       0.0976        0.157        0.424        0.498
     77  1600       0.0177       0.0171     7.68e-05     0.000526        0.697         1.44       0.0673       0.0968        0.176        0.253
     77  1700       0.0316       0.0309     0.000106     0.000553        0.901         1.94       0.0729        0.114        0.216         0.26
     77  1800       0.0202       0.0198     7.35e-05     0.000294        0.826         1.56       0.0615       0.0947        0.158        0.189
     77  1900      0.00526      0.00423     0.000163     0.000864        0.505        0.719       0.0871        0.141        0.322        0.325
     77  2000      0.00514      0.00444     6.04e-05     0.000637        0.472        0.736       0.0527       0.0859        0.245        0.279
     77  2039      0.00767       0.0074     8.68e-05     0.000183        0.675         0.95       0.0708        0.103        0.111         0.15

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     77   100      0.00557      0.00489     0.000105     0.000577        0.518        0.773       0.0668        0.113        0.203        0.265
     77   182        0.158        0.158     3.11e-05     9.24e-05         2.64         4.39        0.049       0.0617        0.106        0.106


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              77 7637.213    0.001       0.0266     0.000124     0.000675       0.0274        0.851          1.8       0.0789        0.123         0.22        0.287
! Validation         77 7637.213    0.001       0.0244     0.000108     0.000668       0.0252        0.793         1.71       0.0723        0.115        0.223        0.286
Wall time: 7637.216686218977
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     78   100       0.0231        0.022     0.000189     0.000933        0.938         1.64        0.103        0.152         0.32        0.337
     78   200      0.00342      0.00271     6.57e-05     0.000648        0.367        0.575       0.0575       0.0896        0.203        0.281
     78   300       0.0224       0.0219      7.5e-05     0.000442        0.787         1.64        0.065       0.0957        0.174        0.232
     78   400       0.0192        0.018     7.95e-05      0.00112        0.759         1.48       0.0715       0.0985        0.323         0.37
     78   500      0.00335      0.00314     0.000103     0.000101        0.405        0.619       0.0806        0.112       0.0831        0.111
     78   600      0.00981      0.00851     9.39e-05       0.0012        0.589         1.02        0.075        0.107        0.348        0.383
     78   700       0.0486       0.0471     9.02e-05      0.00142        0.987          2.4       0.0688        0.105        0.383        0.417
     78   800      0.00631      0.00585     9.59e-05     0.000369        0.542        0.845       0.0752        0.108        0.191        0.212
     78   900      0.00144      0.00113     9.85e-05     0.000204        0.279        0.372       0.0739         0.11        0.153        0.158
     78  1000      0.00242      0.00222     0.000158     4.15e-05        0.397        0.521       0.0842        0.139       0.0568       0.0711
     78  1100      0.00418      0.00397     6.62e-05     0.000143        0.463        0.696       0.0609       0.0899        0.113        0.132
     78  1200      0.00433      0.00407      9.4e-05     0.000162        0.416        0.705       0.0687        0.107         0.12        0.141
     78  1300       0.0162       0.0142     8.38e-05      0.00198        0.792         1.31       0.0714        0.101        0.327        0.491
     78  1400       0.0254        0.025     0.000122     0.000285        0.971         1.75       0.0767        0.122        0.162        0.187
     78  1500       0.0473       0.0466     0.000127     0.000488         1.23         2.39       0.0804        0.124        0.195        0.244
     78  1600       0.0367       0.0361     0.000129      0.00046         1.03          2.1       0.0787        0.125        0.202        0.237
     78  1700       0.0325       0.0321     0.000111     0.000252        0.966         1.98       0.0688        0.116        0.113        0.175
     78  1800       0.0382       0.0376     0.000114     0.000439        0.879         2.14       0.0742        0.118        0.208        0.232
     78  1900       0.0433       0.0424     0.000125     0.000703         1.24         2.28       0.0806        0.123        0.245        0.293
     78  2000        0.023       0.0227     0.000184     0.000173        0.887         1.66        0.102         0.15        0.133        0.146
     78  2039       0.0211       0.0207     0.000177     0.000207        0.786         1.59       0.0804        0.147         0.13        0.159

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     78   100      0.00787      0.00713      0.00011     0.000629        0.609        0.933       0.0725        0.116         0.24        0.277
     78   182        0.129        0.129     4.79e-05     0.000612         2.37         3.96        0.058       0.0765        0.273        0.273


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              78 7736.058    0.001       0.0266     0.000121     0.000682       0.0274        0.848          1.8       0.0773        0.121        0.222        0.289
! Validation         78 7736.058    0.001       0.0238     0.000121      0.00047       0.0244        0.812         1.69       0.0784        0.122        0.186        0.239
Wall time: 7736.058793403208
! Best model       78    0.024
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     79   100       0.0478       0.0472      0.00028     0.000308         1.17          2.4       0.0969        0.185        0.164        0.194
     79   200       0.0318       0.0305     0.000154      0.00116         1.08         1.93       0.0872        0.137        0.338        0.377
     79   300       0.0914       0.0906     9.68e-05     0.000639         1.58         3.33       0.0747        0.109        0.248        0.279
     79   400       0.0545       0.0541     0.000124     0.000364         1.05         2.57       0.0856        0.123        0.168        0.211
     79   500        0.003      0.00281     0.000106     7.97e-05        0.411        0.586       0.0772        0.114       0.0794       0.0986
     79   600      0.00332      0.00264     9.18e-05      0.00059        0.352        0.568       0.0656        0.106        0.218        0.268
     79   700      0.00237      0.00218     0.000106     9.11e-05         0.36        0.516       0.0711        0.113       0.0941        0.105
     79   800       0.0818       0.0814     0.000184     0.000255         1.52         3.15       0.0917         0.15        0.146        0.176
     79   900      0.00743      0.00586     0.000151      0.00142         0.52        0.846       0.0832        0.136        0.386        0.416
     79  1000      0.00354       0.0027     9.61e-05     0.000747        0.452        0.574       0.0688        0.108        0.272        0.302
     79  1100      0.00635      0.00582       0.0001     0.000429        0.582        0.843       0.0761        0.111          0.2        0.229
     79  1200       0.0185        0.018     8.38e-05     0.000457          0.9         1.48       0.0584        0.101        0.224        0.236
     79  1300       0.0606       0.0597     7.91e-05      0.00079         1.42          2.7       0.0619       0.0983        0.254         0.31
     79  1400       0.0321       0.0317     0.000137     0.000281         1.08         1.97       0.0821        0.129        0.166        0.185
     79  1500      0.00334      0.00275     0.000133     0.000466        0.389        0.579        0.086        0.128        0.229        0.238
     79  1600      0.00492      0.00455     5.17e-05      0.00031        0.405        0.746       0.0512       0.0794        0.173        0.195
     79  1700      0.00164     0.000614     0.000122     0.000907        0.225        0.274       0.0694        0.122        0.249        0.333
     79  1800       0.0109       0.0103     8.66e-05     0.000453        0.645         1.12       0.0724        0.103        0.216        0.235
     79  1900       0.0313       0.0306     0.000173     0.000489         1.23         1.93        0.092        0.145         0.22        0.244
     79  2000       0.0475       0.0473     9.23e-05     0.000117         1.06          2.4       0.0667        0.106        0.101        0.119
     79  2039      0.00558      0.00552     4.01e-05     2.12e-05        0.624        0.821       0.0519         0.07       0.0504       0.0509

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     79   100      0.00675      0.00628     0.000218     0.000253        0.491        0.875       0.0871        0.163        0.173        0.176
     79   182       0.0994       0.0992     6.04e-05     9.27e-05         2.15         3.48       0.0656       0.0859        0.106        0.106


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              79 7834.893    0.001       0.0266     0.000121     0.000648       0.0273        0.846          1.8       0.0773        0.121        0.217        0.281
! Validation         79 7834.893    0.001       0.0254     0.000198     0.000465       0.0261        0.888         1.75        0.093        0.156        0.178        0.239
Wall time: 7834.894414655864
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     80   100       0.0357       0.0353     0.000286     0.000101         1.21         2.08        0.118        0.187       0.0868        0.111
     80   200      0.00249      0.00209     0.000118     0.000276        0.373        0.505       0.0677         0.12        0.179        0.183
     80   300      0.00103     0.000722     4.22e-05     0.000268        0.221        0.297       0.0503       0.0718        0.143        0.181
     80   400      0.00895      0.00837     0.000152     0.000434        0.606         1.01       0.0731        0.136         0.17         0.23
     80   500      0.00806      0.00757     0.000231     0.000261        0.658        0.961       0.0889        0.168        0.164        0.178
     80   600        0.029       0.0287     0.000154     0.000211        0.901         1.87       0.0885        0.137        0.139        0.161
     80   700      0.00618      0.00494     0.000114      0.00113        0.547        0.777       0.0784        0.118        0.291        0.371
     80   800       0.0491       0.0478     9.85e-05       0.0012         1.09         2.42       0.0696         0.11        0.348        0.382
     80   900      0.00258      0.00226      0.00014     0.000185        0.374        0.525       0.0831        0.131         0.13         0.15
     80  1000      0.00863       0.0081     0.000237     0.000292        0.713        0.994       0.0986         0.17        0.142        0.189
     80  1100       0.0378        0.035     9.73e-05      0.00273         1.25         2.07       0.0707        0.109        0.516        0.577
     80  1200       0.0131       0.0128     0.000157     9.93e-05        0.797         1.25       0.0904        0.138       0.0946         0.11
     80  1300       0.0364       0.0358     6.84e-05      0.00046          1.2         2.09       0.0639       0.0913        0.146        0.237
     80  1400       0.0448       0.0445     0.000112     0.000171         1.14         2.33       0.0767        0.117        0.131        0.144
     80  1500       0.0326       0.0319     0.000196     0.000515        0.937         1.97       0.0941        0.155        0.222        0.251
     80  1600       0.0656       0.0649     0.000131     0.000539         1.56         2.81       0.0858        0.126        0.209        0.257
     80  1700        0.016       0.0156     0.000149      0.00025        0.723         1.38       0.0843        0.135        0.158        0.175
     80  1800       0.0378       0.0365     0.000107      0.00115         1.27         2.11       0.0723        0.114        0.315        0.374
     80  1900       0.0234       0.0226     8.67e-05     0.000719        0.755         1.66       0.0643        0.103        0.269        0.296
     80  2000       0.0291       0.0287     0.000139     0.000328        0.985         1.87        0.085         0.13        0.155          0.2
     80  2039        0.015       0.0138      0.00019      0.00104        0.797          1.3       0.0989        0.152         0.29        0.357

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     80   100      0.00607      0.00569      0.00015      0.00023        0.574        0.833       0.0794        0.135        0.138        0.168
     80   182        0.118        0.117     5.83e-05     0.000392         2.27         3.78       0.0653       0.0844        0.219        0.219


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              80 7933.739    0.001       0.0264     0.000124       0.0007       0.0272        0.846         1.79       0.0779        0.123        0.225        0.292
! Validation         80 7933.739    0.001       0.0243     0.000136     0.000527        0.025        0.837         1.71       0.0835        0.129        0.204        0.254
Wall time: 7933.73975007236
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     81   100       0.0376       0.0372     7.61e-05     0.000338         1.24         2.13       0.0668       0.0964        0.173        0.203
     81   200       0.0326       0.0322     0.000153     0.000212        0.985         1.98        0.085        0.137        0.133        0.161
     81   300       0.0169       0.0152     0.000176      0.00157        0.877         1.36        0.104        0.147        0.405        0.438
     81   400      0.00207      0.00174     8.58e-05     0.000251        0.308         0.46       0.0688        0.102        0.152        0.175
     81   500       0.0744       0.0733     0.000217     0.000902         1.72         2.99        0.111        0.163        0.328        0.332
     81   600       0.0124       0.0123     6.76e-05     6.19e-05        0.718         1.22       0.0587       0.0909       0.0836       0.0869
     81   700       0.0139       0.0137     0.000138      5.4e-05        0.791         1.29       0.0835         0.13       0.0715       0.0812
     81   800       0.0677       0.0669     0.000154      0.00068         1.15         2.86       0.0979        0.137        0.267        0.288
     81   900       0.0292       0.0286     8.73e-05     0.000509        0.922         1.87       0.0642        0.103        0.178        0.249
     81  1000       0.0106       0.0096     0.000212     0.000758        0.682         1.08       0.0941        0.161        0.239        0.304
     81  1100      0.00286      0.00154     7.53e-05      0.00125        0.266        0.434       0.0607       0.0959        0.362         0.39
     81  1200      0.00514      0.00486     5.93e-05     0.000225        0.462         0.77       0.0591       0.0851        0.142        0.166
     81  1300      0.00428      0.00369     0.000134     0.000463        0.461        0.671       0.0894        0.128        0.191        0.238
     81  1400       0.0419       0.0413     9.74e-05     0.000522         1.17         2.25       0.0734        0.109        0.247        0.252
     81  1500       0.0686       0.0676     0.000167     0.000843         1.56         2.87       0.0936        0.143        0.315        0.321
     81  1600       0.0518       0.0514     0.000264     0.000116         1.25          2.5        0.105        0.179       0.0792        0.119
     81  1700       0.0166       0.0158     0.000125     0.000723        0.702         1.39       0.0777        0.123        0.273        0.297
     81  1800       0.0759       0.0748     0.000213     0.000944          1.7         3.02       0.0979        0.161        0.291         0.34
     81  1900       0.0387       0.0382      0.00013     0.000428          1.2         2.16       0.0844        0.126        0.196        0.229
     81  2000       0.0203       0.0198     0.000259     0.000202        0.912         1.56        0.111        0.178        0.138        0.157
     81  2039       0.0103      0.00965     0.000116     0.000578        0.592         1.09       0.0804        0.119        0.265        0.266

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     81   100      0.00762      0.00716     0.000113     0.000344        0.632        0.935        0.077        0.117        0.181        0.205
     81   182         0.14        0.139     6.06e-05       0.0016         2.53         4.11       0.0647        0.086        0.442        0.442


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              81 8032.519    0.001       0.0265     0.000125     0.000635       0.0272        0.849          1.8        0.079        0.124        0.215        0.279
! Validation         81 8032.519    0.001       0.0242     0.000155     0.000536       0.0249        0.848          1.7        0.088        0.138        0.206        0.255
Wall time: 8032.520133249462
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     82   100      0.00236      0.00191     6.59e-05     0.000381        0.373        0.483       0.0592       0.0897        0.212        0.216
     82   200       0.0135       0.0126       0.0002     0.000715        0.721         1.24       0.0844        0.156        0.247        0.295
     82   300       0.0163       0.0161     0.000168     8.09e-05        0.676          1.4       0.0855        0.143       0.0841       0.0994
     82   400      0.00801      0.00725     0.000111      0.00065         0.58        0.941       0.0721        0.117        0.278        0.282
     82   500      0.00957      0.00933     0.000185     5.67e-05        0.598         1.07       0.0923         0.15       0.0603       0.0832
     82   600      0.00322      0.00259     5.98e-05     0.000576        0.341        0.562        0.058       0.0854        0.217        0.265
     82   700      0.00782      0.00744     5.15e-05     0.000332        0.637        0.953       0.0543       0.0793        0.181        0.201
     82   800       0.0184       0.0182     8.42e-05     0.000139        0.817         1.49       0.0696        0.101        0.122         0.13
     82   900       0.0331       0.0324     0.000126     0.000607         1.18         1.99       0.0851        0.124        0.231        0.272
     82  1000       0.0318       0.0314     0.000145     0.000246        0.998         1.96        0.081        0.133        0.165        0.173
     82  1100       0.0132       0.0128       0.0003     0.000118        0.724         1.25        0.108        0.192        0.104         0.12
     82  1200      0.00992      0.00836     0.000135      0.00143        0.605         1.01       0.0916        0.128        0.379        0.417
     82  1300       0.0273       0.0271     0.000139     7.81e-05         1.03         1.82       0.0753         0.13       0.0742       0.0976
     82  1400       0.0281       0.0278     0.000121     0.000127        0.807         1.84       0.0793        0.121        0.103        0.124
     82  1500      0.00674       0.0058     0.000122     0.000813        0.544        0.842       0.0846        0.122        0.306        0.315
     82  1600        0.156        0.155      0.00016     0.000661         2.19         4.35       0.0894         0.14        0.208        0.284
     82  1700       0.0574       0.0569      8.1e-05     0.000471         1.11         2.64       0.0657       0.0994        0.194         0.24
     82  1800      0.00257       0.0023     4.92e-05     0.000224        0.335        0.529       0.0544       0.0775        0.141        0.165
     82  1900      0.00523      0.00453     0.000219     0.000474        0.543        0.744        0.104        0.163         0.18        0.241
     82  2000      0.00296       0.0027     6.58e-05     0.000194        0.365        0.574       0.0628       0.0897       0.0987        0.154
     82  2039      0.00416      0.00341     8.51e-05      0.00066        0.421        0.645        0.067        0.102        0.257        0.284

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     82   100      0.00538      0.00489     0.000184     0.000306        0.463        0.773       0.0804         0.15        0.172        0.193
     82   182        0.135        0.135     4.75e-05     0.000226         2.43         4.06       0.0602       0.0761        0.166        0.166


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              82 8131.428    0.001       0.0265      0.00012     0.000612       0.0273        0.849          1.8       0.0772        0.121         0.21        0.273
! Validation         82 8131.428    0.001       0.0241     0.000145     0.000361       0.0246         0.83          1.7       0.0828        0.133        0.164         0.21
Wall time: 8131.428794361651
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     83   100       0.0406       0.0387     0.000138      0.00175         1.25         2.17       0.0869         0.13        0.397        0.462
     83   200       0.0335       0.0327     9.94e-05     0.000685         1.11            2       0.0723         0.11        0.275        0.289
     83   300      0.00576       0.0049     0.000216     0.000642        0.573        0.774       0.0985        0.162         0.25         0.28
     83   400       0.0255       0.0253      8.6e-05      6.7e-05        0.743         1.76       0.0672        0.102       0.0784       0.0905
     83   500       0.0148       0.0134     9.75e-05      0.00137        0.642         1.28       0.0676        0.109        0.351        0.408
     83   600       0.0284       0.0281     0.000107     0.000187        0.853         1.85       0.0799        0.114        0.131        0.151
     83   700      0.00844      0.00764     6.25e-05     0.000739         0.64        0.966       0.0593       0.0874        0.243          0.3
     83   800         0.13        0.129     0.000156     0.000868         1.47         3.96       0.0915        0.138         0.28        0.326
     83   900       0.0238       0.0228     0.000394     0.000678         1.02         1.67        0.147        0.219        0.244        0.288
     83  1000      0.00758      0.00606     0.000113      0.00141        0.534         0.86       0.0809        0.117        0.402        0.415
     83  1100      0.00514      0.00467     9.31e-05     0.000377        0.493        0.755        0.065        0.107        0.141        0.214
     83  1200      0.00938      0.00926      9.7e-05     1.54e-05        0.727         1.06       0.0676        0.109       0.0288       0.0434
     83  1300       0.0847       0.0842     0.000153      0.00038         1.84         3.21       0.0863        0.136        0.145        0.215
     83  1400      0.00643      0.00582     7.89e-05     0.000532         0.52        0.843       0.0699       0.0982        0.186        0.255
     83  1500       0.0123        0.012     0.000132     0.000178        0.766         1.21       0.0845        0.127        0.116        0.147
     83  1600       0.0197       0.0195     0.000148     0.000102        0.819         1.54       0.0757        0.134        0.087        0.112
     83  1700      0.00582      0.00468     0.000158     0.000975        0.542        0.756       0.0811        0.139        0.291        0.345
     83  1800       0.0442       0.0437     0.000165     0.000359         1.42         2.31       0.0941        0.142        0.159        0.209
     83  1900      0.00685      0.00556     0.000117      0.00117        0.495        0.824       0.0739         0.12        0.332        0.378
     83  2000       0.0105      0.00734     0.000252      0.00288        0.565        0.947        0.105        0.175        0.451        0.593
     83  2039      0.00392      0.00339     5.56e-05     0.000476        0.389        0.644       0.0572       0.0824         0.21        0.241

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     83   100      0.00446      0.00393     0.000103     0.000421        0.439        0.693       0.0668        0.112        0.217        0.227
     83   182         0.13         0.13      4.9e-05     3.42e-05         2.41         3.98       0.0588       0.0773       0.0646       0.0646


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              83 8230.249    0.001       0.0262     0.000124     0.000612        0.027        0.846         1.79       0.0777        0.123         0.21        0.273
! Validation         83 8230.249    0.001       0.0238     0.000111     0.000598       0.0245        0.788         1.69       0.0738        0.116        0.211        0.271
Wall time: 8230.249963708222
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     84   100       0.0382        0.037     0.000196     0.000941         1.24         2.13       0.0914        0.155        0.337        0.339
     84   200       0.0316       0.0308     0.000135     0.000724        0.999         1.94       0.0845        0.128        0.253        0.297
     84   300        0.048       0.0466      0.00011      0.00122         1.18         2.39       0.0696        0.116        0.268        0.387
     84   400      0.00823      0.00768     9.98e-05     0.000443        0.549        0.968       0.0679         0.11        0.198        0.233
     84   500      0.00532      0.00439     9.53e-05     0.000832        0.518        0.732       0.0742        0.108        0.276        0.319
     84   600      0.00415      0.00107     0.000169       0.0029        0.284        0.362       0.0924        0.144        0.471        0.595
     84   700       0.0425       0.0417      0.00015     0.000697         1.21         2.26       0.0865        0.135        0.213        0.292
     84   800       0.0215       0.0195     7.95e-05      0.00195        0.728         1.54       0.0636       0.0985        0.382        0.488
     84   900      0.00357      0.00328     0.000179     0.000119        0.444        0.632       0.0969        0.148       0.0839         0.12
     84  1000       0.0131        0.012     0.000105     0.000985        0.599         1.21       0.0754        0.113         0.31        0.347
     84  1100       0.0169       0.0162     0.000136     0.000523        0.724         1.41       0.0769        0.129         0.23        0.253
     84  1200       0.0301       0.0294     0.000153     0.000487         1.22          1.9       0.0913        0.137        0.236        0.244
     84  1300      0.00427      0.00384     0.000149     0.000275        0.458        0.685       0.0735        0.135        0.148        0.183
     84  1400       0.0418       0.0406     8.54e-05      0.00113         1.06         2.23       0.0672        0.102        0.289        0.372
     84  1500       0.0503       0.0491     0.000266     0.000952         1.39         2.45       0.0965         0.18        0.267        0.341
     84  1600       0.0379       0.0375     7.71e-05     0.000372        0.884         2.14       0.0691        0.097         0.17        0.213
     84  1700       0.0144       0.0141     0.000126     0.000192        0.699         1.31        0.078        0.124        0.124        0.153
     84  1800       0.0323       0.0318     0.000159     0.000367        0.988         1.97       0.0937        0.139        0.151        0.212
     84  1900      0.00933      0.00877     7.13e-05     0.000489        0.532         1.03       0.0546       0.0933        0.222        0.244
     84  2000         0.12         0.12     7.07e-05     0.000727         1.55         3.82       0.0602       0.0929        0.224        0.298
     84  2039        0.118        0.117     0.000127      0.00147         2.31         3.77       0.0807        0.125        0.375        0.423

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     84   100       0.0056      0.00498     0.000101     0.000516        0.507         0.78       0.0697        0.111        0.201        0.251
     84   182        0.133        0.132     4.69e-05      0.00102         2.41         4.02       0.0585       0.0757        0.353        0.353


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              84 8329.154    0.001       0.0263     0.000122     0.000662       0.0271        0.842         1.79       0.0773        0.122        0.219        0.284
! Validation         84 8329.154    0.001       0.0238     0.000109     0.000567       0.0245        0.791         1.69       0.0742        0.115          0.2        0.263
Wall time: 8329.154440000653
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     85   100       0.0203       0.0197     9.68e-05      0.00047        0.808         1.55       0.0698        0.109        0.221         0.24
     85   200       0.0619       0.0611     0.000193     0.000616         1.47         2.73       0.0987        0.153        0.202        0.274
     85   300       0.0101      0.00886     8.32e-05       0.0012        0.537         1.04       0.0713        0.101        0.359        0.383
     85   400       0.0565       0.0561      0.00018     0.000153         1.61         2.62          0.1        0.148        0.126        0.137
     85   500      0.00663      0.00598     0.000226     0.000422         0.61        0.854       0.0903        0.166        0.162        0.227
     85   600       0.0262       0.0256     7.99e-05     0.000528        0.787         1.77       0.0689       0.0987        0.232        0.254
     85   700       0.0257       0.0253     0.000168     0.000289        0.913         1.76       0.0911        0.143        0.168        0.188
     85   800       0.0123       0.0114     5.07e-05     0.000882        0.735         1.18       0.0539       0.0787         0.28        0.328
     85   900      0.00244      0.00209     0.000115     0.000237        0.385        0.505       0.0789        0.119        0.116         0.17
     85  1000      0.00712      0.00692     8.31e-05     0.000109        0.464        0.919       0.0639        0.101       0.0895        0.116
     85  1100       0.0323        0.032      9.3e-05     0.000238        0.999         1.98       0.0723        0.107        0.161        0.171
     85  1200      0.00327      0.00263     7.03e-05     0.000569        0.374        0.567       0.0622       0.0926        0.237        0.264
     85  1300       0.0068       0.0058     0.000173     0.000825        0.452        0.841       0.0819        0.146        0.245        0.317
     85  1400        0.103        0.103      0.00016     0.000558          1.9         3.54       0.0953         0.14        0.231        0.261
     85  1500      0.00224      0.00197     5.11e-05     0.000221        0.334         0.49       0.0566        0.079         0.15        0.164
     85  1600       0.0356       0.0338     7.67e-05      0.00169         1.15         2.03       0.0626       0.0968        0.449        0.454
     85  1700       0.0145       0.0111     6.95e-05      0.00331        0.714         1.17       0.0633       0.0921         0.58        0.635
     85  1800      0.00227      0.00194     6.99e-05     0.000258        0.344        0.487       0.0649       0.0924        0.176        0.178
     85  1900      0.00477      0.00432     0.000125     0.000321        0.459        0.726       0.0794        0.123        0.174        0.198
     85  2000       0.0136       0.0131     8.01e-05     0.000497        0.759         1.26       0.0715       0.0989        0.205        0.246
     85  2039       0.0547       0.0546     9.39e-05     5.19e-05         1.18         2.58       0.0699        0.107       0.0754       0.0796

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     85   100      0.00429       0.0036     8.72e-05     0.000603         0.45        0.663       0.0644        0.103        0.239        0.271
     85   182        0.159        0.159     5.46e-05     6.01e-10         2.71          4.4        0.061       0.0816     0.000271     0.000271


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              85 8428.000    0.001       0.0262     0.000123      0.00069       0.0271        0.844         1.79       0.0774        0.122        0.222         0.29
! Validation         85 8428.000    0.001       0.0239     0.000102     0.000572       0.0246        0.793         1.69       0.0731        0.112         0.21        0.265
Wall time: 8428.000962547958
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     86   100       0.0116       0.0114     7.83e-05     0.000177        0.799         1.18       0.0691       0.0978        0.111        0.147
     86   200       0.0297       0.0292     0.000118     0.000367        0.969         1.89       0.0754         0.12        0.172        0.212
     86   300       0.0784       0.0774     0.000227     0.000713         1.55         3.07       0.0989        0.166        0.287        0.295
     86   400       0.0152       0.0141     7.48e-05     0.000998        0.756         1.31       0.0653       0.0955        0.325        0.349
     86   500        0.015       0.0146      0.00012     0.000325        0.601         1.33       0.0821        0.121        0.188        0.199
     86   600        0.045       0.0448     0.000238     4.68e-05         1.34         2.34        0.105         0.17       0.0541       0.0756
     86   700       0.0244       0.0239     9.47e-05     0.000407        0.816         1.71       0.0705        0.108        0.173        0.223
     86   800       0.0349       0.0345     0.000153     0.000199        0.902         2.05       0.0827        0.137        0.143        0.156
     86   900       0.0258       0.0254     0.000159     0.000205        0.925         1.76       0.0875        0.139        0.134        0.158
     86  1000       0.0364        0.036     0.000134     0.000291          1.3          2.1       0.0847        0.128        0.166        0.188
     86  1100       0.0112       0.0105     0.000104     0.000522        0.568         1.13        0.068        0.113        0.223        0.252
     86  1200      0.00497      0.00406     9.45e-05     0.000815        0.531        0.704       0.0688        0.107        0.254        0.315
     86  1300      0.00904      0.00892     0.000107     1.16e-05        0.707         1.04       0.0713        0.114       0.0358       0.0377
     86  1400       0.0278       0.0262     0.000126      0.00146        0.885         1.79       0.0795        0.124        0.352        0.422
     86  1500       0.0101      0.00931     8.55e-05     0.000682        0.705         1.07       0.0706        0.102        0.251        0.288
     86  1600       0.0882       0.0873     0.000103     0.000844         1.29         3.26       0.0797        0.112        0.305        0.321
     86  1700      0.00568      0.00515     0.000211     0.000327        0.607        0.793        0.101        0.161         0.15          0.2
     86  1800      0.00747      0.00659     8.19e-05       0.0008        0.528        0.897       0.0642          0.1        0.278        0.312
     86  1900      0.00921      0.00858     0.000117      0.00052        0.582         1.02       0.0782        0.119        0.186        0.252
     86  2000       0.0102      0.00868     7.65e-05      0.00142        0.629         1.03       0.0711       0.0967        0.331        0.416
     86  2039       0.0187       0.0183     0.000117     0.000301        0.812          1.5       0.0834         0.12        0.171        0.192

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     86   100      0.00426      0.00402     0.000107     0.000134        0.467        0.701       0.0659        0.114        0.115        0.128
     86   182        0.137        0.137     4.96e-05     0.000462         2.51         4.09         0.06       0.0778        0.237        0.237


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              86 8526.987    0.001       0.0261     0.000122     0.000644       0.0269        0.843         1.79        0.077        0.122        0.216         0.28
! Validation         86 8526.987    0.001        0.024      0.00011     0.000401       0.0245        0.793         1.69       0.0732        0.116        0.174        0.221
Wall time: 8526.987726643682
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     87   100       0.0312       0.0304     0.000109     0.000777        0.979         1.92       0.0769        0.115        0.278        0.308
     87   200        0.015       0.0146     7.41e-05     0.000298        0.567         1.34       0.0615       0.0951        0.155        0.191
     87   300      0.00959      0.00937     0.000112     0.000115        0.713         1.07       0.0775        0.117        0.111        0.119
     87   400      0.00754      0.00722     0.000145     0.000179        0.555        0.939       0.0905        0.133        0.122        0.148
     87   500       0.0138        0.013     0.000152     0.000706        0.853         1.26       0.0899        0.136        0.233        0.294
     87   600       0.0538       0.0523     0.000109      0.00146         1.28         2.53       0.0718        0.115        0.385        0.423
     87   700       0.0615        0.061     0.000217     0.000277         1.48         2.73       0.0994        0.163        0.178        0.184
     87   800       0.0145        0.014     0.000136     0.000305        0.935         1.31       0.0857        0.129        0.179        0.193
     87   900       0.0254       0.0249      0.00012     0.000377            1         1.74       0.0752        0.121        0.191        0.214
     87  1000      0.00737      0.00355     0.000108      0.00371        0.429        0.658       0.0781        0.115          0.6        0.673
     87  1100       0.0793       0.0786     6.85e-05     0.000598         1.14          3.1        0.061       0.0915        0.248         0.27
     87  1200       0.0277       0.0269     0.000103     0.000678        0.824         1.81       0.0733        0.112         0.26        0.288
     87  1300      0.00384      0.00324     6.84e-05     0.000529        0.393        0.629       0.0521       0.0914        0.235        0.254
     87  1400       0.0145       0.0135     0.000122     0.000875        0.692         1.28       0.0824        0.122        0.233        0.327
     87  1500      0.00696      0.00561     0.000104      0.00125        0.606        0.827       0.0748        0.113        0.349        0.391
     87  1600      0.00523      0.00278     0.000262      0.00219        0.404        0.582        0.092        0.179          0.5        0.517
     87  1700       0.0402       0.0395     0.000116     0.000612         1.05          2.2       0.0716        0.119        0.245        0.273
     87  1800       0.0053      0.00474     7.79e-05     0.000476        0.487        0.761       0.0643       0.0975        0.192        0.241
     87  1900       0.0229       0.0223     0.000116      0.00051        0.783         1.65       0.0833        0.119        0.212        0.249
     87  2000      0.00571      0.00504     0.000253     0.000415        0.578        0.785        0.122        0.176        0.175        0.225
     87  2039      0.00195      0.00158     5.74e-05     0.000315        0.373        0.439       0.0623       0.0837        0.192        0.196

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     87   100      0.00685      0.00638     0.000113     0.000354        0.593        0.883       0.0746        0.118        0.168        0.208
     87   182        0.131        0.131        8e-05     3.31e-05          2.4         3.99       0.0674       0.0988       0.0636       0.0636


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              87 8625.866    0.001        0.026     0.000125     0.000643       0.0268        0.845         1.78       0.0778        0.124        0.216         0.28
! Validation         87 8625.866    0.001       0.0238      0.00013     0.000474       0.0244        0.808         1.69       0.0819        0.126        0.183        0.241
Wall time: 8625.86705839634
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     88   100      0.00949      0.00831     9.22e-05      0.00108        0.645         1.01       0.0774        0.106        0.308        0.363
     88   200       0.0137       0.0132     8.48e-05     0.000432        0.704         1.27       0.0694        0.102          0.2         0.23
     88   300       0.0547       0.0533     0.000123      0.00124         1.33         2.55       0.0786        0.123        0.348         0.39
     88   400      0.00191      0.00132     8.05e-05     0.000508        0.309        0.401       0.0694       0.0991        0.237        0.249
     88   500     0.000982     0.000609     6.03e-05     0.000313        0.214        0.273       0.0582       0.0858        0.189        0.195
     88   600       0.0145       0.0143     0.000118     3.59e-05        0.845         1.32       0.0811         0.12        0.054       0.0662
     88   700       0.0209       0.0203     0.000149     0.000528        0.948         1.57       0.0884        0.135        0.218        0.254
     88   800      0.00297      0.00138     0.000132      0.00146        0.294         0.41        0.073        0.127        0.315        0.422
     88   900       0.0143       0.0139     7.04e-05     0.000394        0.759          1.3       0.0638       0.0927        0.185        0.219
     88  1000       0.0323       0.0319     8.76e-05     0.000362         1.01         1.97       0.0695        0.103        0.184         0.21
     88  1100       0.0556       0.0549     0.000139     0.000568          1.3         2.59       0.0908         0.13        0.246        0.263
     88  1200       0.0237       0.0232     0.000147     0.000366         1.02         1.68       0.0888        0.134        0.182        0.211
     88  1300       0.0287       0.0265     0.000252       0.0019        0.943          1.8        0.108        0.175        0.403        0.481
     88  1400       0.0107      0.00976     0.000115     0.000848        0.631         1.09       0.0686        0.119        0.308        0.322
     88  1500       0.0796       0.0791     0.000103     0.000447         1.41         3.11       0.0732        0.112        0.178        0.234
     88  1600        0.028       0.0264     9.73e-05      0.00148         1.01          1.8       0.0688        0.109         0.36        0.424
     88  1700      0.00638      0.00585     9.26e-05     0.000428        0.506        0.845       0.0651        0.106        0.195        0.229
     88  1800       0.0182       0.0171     0.000126      0.00101        0.995         1.44       0.0856        0.124        0.272         0.35
     88  1900       0.0125       0.0105     9.56e-05      0.00195        0.658         1.13       0.0714        0.108        0.455        0.487
     88  2000      0.00273      0.00214     0.000119     0.000464        0.392        0.511       0.0626         0.12        0.208        0.238
     88  2039       0.0152        0.015     5.91e-05     0.000154        0.815         1.35        0.058       0.0849        0.122        0.137

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     88   100      0.00467      0.00366     8.64e-05     0.000923         0.43        0.668       0.0593        0.103        0.261        0.336
     88   182        0.147        0.147     3.62e-05     0.000191         2.56         4.23        0.052       0.0665        0.153        0.153


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              88 8724.761    0.001        0.026      0.00012     0.000673       0.0267        0.844         1.78        0.077        0.121        0.221        0.287
! Validation         88 8724.761    0.001       0.0237      8.5e-05     0.000855       0.0247        0.787         1.68       0.0658        0.102        0.252        0.324
Wall time: 8724.762331962585
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     89   100          0.1       0.0998     0.000126     0.000245         1.56         3.49       0.0802        0.124        0.135        0.173
     89   200      0.00246      0.00222     0.000174     6.56e-05        0.419         0.52       0.0901        0.146       0.0865       0.0895
     89   300       0.0105      0.00764     9.05e-05      0.00275        0.536        0.966       0.0653        0.105         0.54         0.58
     89   400      0.00924      0.00855     0.000144     0.000543        0.668         1.02       0.0745        0.133        0.243        0.257
     89   500      0.00165       0.0014     7.44e-05     0.000174        0.326        0.413        0.062       0.0953        0.132        0.146
     89   600        0.121         0.12     0.000111     0.000529         1.59         3.83         0.07        0.117        0.203        0.254
     89   700       0.0744       0.0737     0.000127     0.000555         1.38            3       0.0747        0.124        0.203         0.26
     89   800      0.00732      0.00691     0.000137     0.000269         0.54        0.919       0.0746        0.129        0.149        0.181
     89   900       0.0282       0.0273     0.000115      0.00079         1.03         1.83       0.0789        0.118        0.251        0.311
     89  1000       0.0524        0.051      7.7e-05      0.00132         1.26          2.5       0.0655        0.097         0.32        0.402
     89  1100       0.0169       0.0164     7.02e-05     0.000426         0.81         1.42       0.0549       0.0926        0.199        0.228
     89  1200       0.0024      0.00187     0.000106     0.000428        0.358        0.478       0.0745        0.114        0.221        0.228
     89  1300       0.0047      0.00424     0.000103     0.000354        0.479        0.719       0.0747        0.112        0.184        0.208
     89  1400       0.0312       0.0296     0.000104      0.00142        0.902          1.9       0.0752        0.113        0.368        0.417
     89  1500       0.0049      0.00427     0.000174      0.00046        0.505        0.722       0.0959        0.146        0.168        0.237
     89  1600      0.00699       0.0068     0.000142     5.11e-05        0.612        0.911        0.083        0.132       0.0701        0.079
     89  1700       0.0653       0.0644     0.000143     0.000737          1.6          2.8       0.0877        0.132        0.283          0.3
     89  1800       0.0144       0.0143     8.68e-05     6.07e-05        0.642         1.32       0.0736        0.103       0.0624       0.0861
     89  1900       0.0121       0.0117     0.000164     0.000243        0.776         1.19       0.0988        0.141        0.145        0.172
     89  2000        0.011      0.00937     0.000132      0.00145        0.651         1.07       0.0833        0.127          0.3        0.421
     89  2039      0.00268      0.00191     0.000127     0.000639        0.305        0.483       0.0699        0.125        0.264        0.279

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     89   100      0.00564      0.00522     0.000116     0.000306        0.504        0.798       0.0709        0.119        0.164        0.193
     89   182        0.113        0.113     6.07e-05     2.36e-06         2.25         3.71       0.0612       0.0861        0.017        0.017


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              89 8823.597    0.001       0.0258     0.000122     0.000589       0.0265         0.84         1.77        0.077        0.122        0.208        0.268
! Validation         89 8823.597    0.001       0.0237     0.000122     0.000604       0.0244        0.801         1.69       0.0774        0.122        0.215        0.272
Wall time: 8823.598468996584
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     90   100        0.153        0.152     0.000124      0.00128         1.91         4.31       0.0862        0.123        0.311        0.395
     90   200       0.0304       0.0301     0.000101     0.000178        0.864         1.92       0.0713        0.111        0.125        0.147
     90   300       0.0446       0.0436     0.000216     0.000721         1.23         2.31       0.0899        0.162        0.285        0.297
     90   400       0.0427       0.0418     0.000102     0.000754         1.04         2.26       0.0712        0.112        0.267        0.303
     90   500       0.0207       0.0206     9.46e-05     4.81e-05        0.865         1.59       0.0773        0.107       0.0617       0.0766
     90   600       0.0103      0.00539     7.33e-05       0.0048        0.494        0.811       0.0642       0.0946        0.459        0.766
     90   700       0.0842        0.082     0.000302      0.00191         1.58         3.16        0.109        0.192        0.426        0.483
     90   800       0.0517        0.051     0.000109     0.000559         1.24          2.5       0.0754        0.115        0.224        0.261
     90   900       0.0104      0.00956     0.000134     0.000699         0.59         1.08       0.0753        0.128         0.25        0.292
     90  1000       0.0132       0.0129     0.000269     8.35e-05         0.76         1.25       0.0998        0.181       0.0762        0.101
     90  1100       0.0942       0.0937      0.00015     0.000348         1.35         3.38       0.0817        0.135        0.151        0.206
     90  1200       0.0374       0.0365     0.000163     0.000647         1.07         2.11       0.0864        0.141         0.26        0.281
     90  1300      0.00408      0.00384     0.000116     0.000122         0.38        0.685       0.0811        0.119        0.111        0.122
     90  1400        0.075       0.0743     0.000125      0.00061         1.36         3.01       0.0745        0.123        0.244        0.273
     90  1500       0.0137       0.0135     9.61e-05     0.000127         0.73         1.28       0.0691        0.108        0.114        0.124
     90  1600      0.00509      0.00466     6.13e-05     0.000366        0.482        0.754        0.053       0.0865        0.165        0.211
     90  1700       0.0119       0.0115      0.00016     0.000156        0.598         1.19       0.0768         0.14        0.117        0.138
     90  1800       0.0449       0.0443      7.5e-05      0.00053         1.14         2.33       0.0664       0.0957        0.225        0.254
     90  1900       0.0203       0.0192     6.95e-05      0.00102        0.922         1.53       0.0643       0.0921        0.261        0.353
     90  2000      0.00115     0.000766     6.13e-05     0.000321        0.248        0.306        0.064       0.0865        0.174        0.198
     90  2039       0.0535       0.0532     0.000231     3.61e-05         1.32         2.55       0.0943        0.168       0.0659       0.0664

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     90   100      0.00486      0.00463     0.000104     0.000126        0.497        0.752       0.0661        0.113       0.0969        0.124
     90   182        0.163        0.162     5.29e-05     0.000371         2.71         4.45       0.0582       0.0804        0.213        0.213


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              90 8922.454    0.001       0.0257     0.000124     0.000565       0.0263        0.839         1.77       0.0778        0.123        0.203        0.263
! Validation         90 8922.454    0.001       0.0234     0.000113     0.000461        0.024        0.775         1.67       0.0729        0.117         0.18        0.237
Wall time: 8922.454659320414
! Best model       90    0.024
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     91   100      0.00272      0.00175     5.15e-05     0.000917        0.322        0.462       0.0559       0.0793         0.26        0.335
     91   200       0.0225       0.0221     6.31e-05     0.000285        0.814         1.64       0.0594       0.0878        0.166        0.187
     91   300       0.0246       0.0239     0.000114     0.000617        0.849         1.71       0.0691        0.118        0.223        0.274
     91   400       0.0716       0.0705     9.78e-05      0.00101         1.12         2.93       0.0708        0.109        0.311        0.352
     91   500       0.0354        0.035     0.000218     0.000236         1.09         2.07       0.0955        0.163        0.116         0.17
     91   600        0.006      0.00513     0.000138     0.000728        0.555        0.792       0.0865         0.13        0.253        0.298
     91   700       0.0239       0.0234     9.03e-05       0.0004        0.862         1.69       0.0683        0.105        0.207        0.221
     91   800      0.00166       0.0014     8.91e-05     0.000169        0.271        0.413       0.0641        0.104        0.115        0.144
     91   900      0.00836      0.00809     9.52e-05      0.00017        0.659        0.994       0.0715        0.108        0.116        0.144
     91  1000       0.0443       0.0429     0.000121      0.00122         1.04         2.29       0.0828        0.121         0.36        0.386
     91  1100      0.00604      0.00574     9.74e-05     0.000197        0.541        0.837       0.0717        0.109        0.146        0.155
     91  1200      0.00858      0.00813     0.000229     0.000224         0.59        0.996       0.0851        0.167        0.154        0.165
     91  1300      0.00656      0.00535     9.66e-05      0.00111         0.49        0.808       0.0767        0.109        0.323        0.367
     91  1400       0.0387       0.0364      0.00018      0.00215         1.07         2.11        0.101        0.148        0.408        0.512
     91  1500       0.0717       0.0708     0.000222     0.000701         1.96         2.94        0.115        0.165        0.269        0.293
     91  1600       0.0112       0.0105     0.000155     0.000598        0.704         1.13       0.0871        0.138        0.266         0.27
     91  1700       0.0125       0.0112     9.36e-05      0.00128        0.754         1.17       0.0785        0.107        0.334        0.395
     91  1800       0.0189       0.0185     0.000123     0.000246         1.05          1.5       0.0842        0.122        0.158        0.173
     91  1900      0.00377      0.00356     0.000111     9.72e-05        0.468        0.659       0.0808        0.116       0.0974        0.109
     91  2000       0.0323       0.0321     8.64e-05     8.09e-05        0.724         1.98       0.0677        0.103       0.0852       0.0994
     91  2039       0.0115       0.0112     0.000179     0.000138        0.836         1.17       0.0934        0.148        0.103         0.13

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     91   100      0.00995      0.00966      0.00015     0.000148        0.704         1.09       0.0855        0.135        0.105        0.134
     91   182         0.12        0.119     6.69e-05      2.9e-05          2.3         3.82       0.0669       0.0904       0.0595       0.0595


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              91 9021.354    0.001       0.0255     0.000122     0.000658       0.0263        0.838         1.77       0.0765        0.122        0.218        0.283
! Validation         91 9021.354    0.001       0.0235     0.000151     0.000442       0.0241        0.836         1.68        0.088        0.136        0.181        0.233
Wall time: 9021.355081297457
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     92   100       0.0446       0.0444      8.8e-05     0.000102         1.26         2.33       0.0743        0.104        0.101        0.112
     92   200       0.0236       0.0232     0.000121     0.000229        0.942         1.68       0.0803        0.121        0.152        0.167
     92   300      0.00567      0.00521     7.02e-05     0.000385        0.531        0.798       0.0564       0.0926        0.172        0.217
     92   400       0.0298       0.0293     9.08e-05     0.000487         1.01         1.89       0.0716        0.105        0.205        0.244
     92   500      0.00316      0.00106     3.98e-05      0.00207        0.256        0.359        0.049       0.0697        0.418        0.502
     92   600      0.00204      0.00175     0.000105     0.000186        0.357        0.463       0.0767        0.113        0.144        0.151
     92   700       0.0151       0.0148     0.000106     0.000207        0.741         1.34       0.0708        0.114        0.131        0.159
     92   800      0.00197      0.00169     7.01e-05     0.000212        0.319        0.454        0.062       0.0925        0.153        0.161
     92   900        0.016       0.0153     0.000101     0.000619         0.77         1.37       0.0816        0.111        0.221        0.275
     92  1000       0.0473        0.047      0.00013     0.000211         1.34         2.39       0.0812        0.126        0.114         0.16
     92  1100       0.0371       0.0366     9.96e-05     0.000391         1.07         2.11       0.0677         0.11        0.202        0.218
     92  1200       0.0114       0.0107     5.09e-05     0.000626          0.6         1.15       0.0521       0.0788        0.229        0.276
     92  1300      0.00623      0.00568     0.000177      0.00038        0.584        0.832       0.0837        0.147        0.197        0.215
     92  1400       0.0307       0.0302     0.000157     0.000358         1.09         1.92       0.0931        0.139        0.178        0.209
     92  1500      0.00328      0.00297     0.000104     0.000213        0.347        0.602       0.0769        0.113         0.14        0.161
     92  1600       0.0518       0.0513     0.000142     0.000349         1.18          2.5       0.0875        0.132        0.149        0.206
     92  1700       0.0262       0.0256     0.000124     0.000425         0.92         1.77       0.0848        0.123        0.214        0.228
     92  1800       0.0112       0.0111     0.000112     6.47e-05        0.766         1.16       0.0714        0.117       0.0878       0.0889
     92  1900       0.0309       0.0306     8.01e-05     0.000254         1.01         1.93       0.0655       0.0989        0.168        0.176
     92  2000        0.126        0.123     0.000188      0.00191         2.11         3.88       0.0972        0.151        0.375        0.482
     92  2039      0.00375      0.00295     0.000107     0.000691        0.463          0.6       0.0824        0.114        0.263         0.29

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     92   100      0.00555      0.00375     0.000107       0.0017        0.457        0.676       0.0675        0.114        0.339        0.455
     92   182        0.162        0.161     4.92e-05     0.000676         2.65         4.43       0.0547       0.0775        0.287        0.287


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              92 9120.189    0.001       0.0255     0.000118     0.000597       0.0263        0.836         1.77       0.0754         0.12        0.209         0.27
! Validation         92 9120.189    0.001       0.0234     0.000109      0.00111       0.0246        0.779         1.67       0.0733        0.116        0.288        0.368
Wall time: 9120.189514547586
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     93   100      0.00868      0.00838     0.000113     0.000182        0.729         1.01        0.086        0.118        0.136        0.149
     93   200      0.00374      0.00313      9.9e-05     0.000516        0.445        0.618       0.0746         0.11        0.197        0.251
     93   300       0.0106         0.01      8.1e-05     0.000511         0.62         1.11       0.0659       0.0995        0.232         0.25
     93   400       0.0093      0.00842     7.57e-05     0.000805        0.553         1.01       0.0674       0.0961        0.265        0.314
     93   500      0.00331      0.00248     7.52e-05     0.000754         0.38         0.55       0.0639       0.0958        0.294        0.303
     93   600       0.0356        0.034     0.000188      0.00141         1.29         2.04        0.104        0.152        0.391        0.416
     93   700         0.11        0.101     0.000138      0.00955         1.51         3.51       0.0827         0.13         0.64         1.08
     93   800       0.0173       0.0171     0.000116     4.84e-05        0.737         1.44        0.078        0.119       0.0763       0.0769
     93   900      0.00288       0.0026     5.06e-05     0.000223        0.394        0.564       0.0526       0.0786        0.148        0.165
     93  1000        0.173        0.173      0.00017     0.000231         2.77         4.59       0.0925        0.144        0.152        0.168
     93  1100       0.0707       0.0704     0.000179     0.000111         1.76         2.93       0.0992        0.148       0.0897        0.116
     93  1200       0.0413       0.0411     8.56e-05     9.19e-05        0.869         2.24       0.0645        0.102       0.0896        0.106
     93  1300      0.00429      0.00409     5.57e-05     0.000143        0.373        0.706       0.0571       0.0824        0.125        0.132
     93  1400      0.00329      0.00256     9.43e-05     0.000641        0.425        0.558       0.0696        0.107        0.223         0.28
     93  1500       0.0286       0.0273      7.4e-05      0.00129        0.847         1.83       0.0596        0.095        0.333        0.397
     93  1600       0.0307       0.0296     0.000168     0.000942         1.12          1.9       0.0881        0.143        0.273        0.339
     93  1700      0.00954      0.00894     0.000136     0.000465        0.595         1.04        0.081        0.129        0.204        0.238
     93  1800      0.00781      0.00729     0.000162     0.000361         0.61        0.943       0.0901        0.141        0.207         0.21
     93  1900      0.00126      0.00103     7.21e-05     0.000161        0.284        0.354       0.0619       0.0938        0.114         0.14
     93  2000       0.0192       0.0187     9.23e-05     0.000349        0.715         1.51       0.0625        0.106        0.189        0.206
     93  2039      0.00344      0.00329     7.25e-05     7.69e-05        0.381        0.634       0.0687       0.0941       0.0968       0.0969

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     93   100      0.00621      0.00599     0.000127     9.73e-05        0.573        0.855       0.0726        0.125       0.0935        0.109
     93   182        0.193        0.192     7.44e-05     0.000581         2.89         4.84       0.0614       0.0953        0.266        0.266


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              93 9219.153    0.001       0.0255     0.000121     0.000626       0.0263        0.836         1.76       0.0761        0.121        0.212        0.277
! Validation         93 9219.153    0.001       0.0253     0.000128     0.000396       0.0258        0.849         1.73        0.078        0.125        0.172         0.22
Wall time: 9219.153838463128
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     94   100       0.0107      0.00984     0.000193     0.000663         0.74          1.1        0.092        0.154         0.21        0.284
     94   200       0.0242       0.0239     0.000227     7.04e-05        0.945         1.71        0.108        0.167       0.0873       0.0927
     94   300       0.0215       0.0206     0.000146     0.000733        0.879         1.59       0.0877        0.134        0.259        0.299
     94   400        0.112         0.11     0.000102      0.00194         2.01         3.67       0.0739        0.112        0.414        0.486
     94   500       0.0417       0.0408     0.000397     0.000529         1.34         2.23        0.127         0.22         0.17        0.254
     94   600      0.00886      0.00837     0.000147     0.000345        0.457         1.01       0.0746        0.134         0.18        0.205
     94   700      0.00494      0.00436     0.000132     0.000448        0.399         0.73        0.078        0.127        0.191        0.234
     94   800      0.00247      0.00184     0.000116     0.000516        0.313        0.474       0.0764        0.119        0.218        0.251
     94   900      0.00393      0.00337     8.94e-05     0.000465        0.437        0.641       0.0758        0.104        0.157        0.238
     94  1000       0.0134       0.0128     7.38e-05     0.000509        0.633         1.25       0.0614       0.0949        0.217        0.249
     94  1100      0.00494      0.00408     0.000103     0.000765        0.428        0.705       0.0733        0.112        0.251        0.306
     94  1200       0.0277       0.0269     0.000157     0.000597        0.821         1.81       0.0828        0.139        0.231         0.27
     94  1300       0.0215       0.0209     0.000193     0.000391         1.01          1.6       0.0997        0.153        0.212        0.218
     94  1400       0.0453       0.0437     0.000104      0.00149         1.24         2.31       0.0742        0.113         0.38        0.427
     94  1500       0.0392       0.0374     9.18e-05      0.00166         1.04         2.14       0.0712        0.106        0.383         0.45
     94  1600       0.0376       0.0372     0.000146     0.000304         1.18         2.13        0.095        0.134        0.153        0.193
     94  1700       0.0136       0.0133     0.000117     0.000181         0.77         1.27       0.0726        0.119        0.129        0.149
     94  1800       0.0198       0.0195      0.00016     0.000159        0.649         1.54        0.082         0.14        0.117        0.139
     94  1900        0.027       0.0268     0.000104     7.99e-05        0.844         1.81       0.0721        0.113       0.0689       0.0988
     94  2000       0.0871       0.0863     0.000104     0.000766         1.24         3.25       0.0743        0.113        0.259        0.306
     94  2039       0.0247       0.0242     7.97e-05     0.000376        0.949         1.72       0.0628       0.0986        0.214        0.214

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     94   100      0.00881      0.00853     0.000124     0.000158        0.666         1.02       0.0724        0.123        0.114        0.139
     94   182        0.175        0.174     5.08e-05     0.000449         2.87         4.61       0.0589       0.0788        0.234        0.234


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              94 9318.025    0.001       0.0255     0.000123     0.000574       0.0262        0.838         1.77       0.0769        0.122        0.203        0.265
! Validation         94 9318.025    0.001       0.0248     0.000112     0.000424       0.0253        0.823         1.72       0.0739        0.117        0.176        0.227
Wall time: 9318.026052251458
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     95   100       0.0207       0.0203     0.000163     0.000282        0.939         1.57       0.0782        0.141        0.169        0.186
     95   200       0.0235       0.0232     4.94e-05     0.000285        0.836         1.68       0.0571       0.0777        0.166        0.187
     95   300       0.0652       0.0642     0.000115     0.000942         1.56          2.8       0.0738        0.118          0.3        0.339
     95   400       0.0288       0.0285     0.000171     0.000135        0.862         1.87       0.0872        0.144        0.122        0.129
     95   500       0.0167       0.0156     0.000153     0.000872        0.562         1.38       0.0816        0.137        0.299        0.326
     95   600       0.0128       0.0125       0.0001     0.000168        0.674         1.24       0.0694        0.111        0.124        0.143
     95   700      0.00167      0.00138      9.4e-05     0.000197        0.314        0.411       0.0705        0.107        0.124        0.155
     95   800      0.00575      0.00541     6.94e-05     0.000268        0.507        0.812       0.0587        0.092        0.141        0.181
     95   900       0.0136       0.0126     0.000122     0.000825        0.736         1.24       0.0811        0.122        0.259        0.317
     95  1000        0.033       0.0326     8.83e-05     0.000358         1.19         1.99       0.0695        0.104        0.196        0.209
     95  1100       0.0689       0.0684      0.00011      0.00037          1.4         2.89       0.0818        0.116        0.175        0.212
     95  1200       0.0447       0.0442     0.000197     0.000294         1.05         2.32        0.071        0.155        0.179        0.189
     95  1300        0.015       0.0147     0.000108     0.000223        0.737         1.34       0.0724        0.115        0.159        0.165
     95  1400       0.0203       0.0191     0.000121      0.00106        0.833         1.53       0.0843        0.122        0.314         0.36
     95  1500       0.0198       0.0188        6e-05     0.000866        0.848         1.52       0.0591       0.0856        0.267        0.325
     95  1600      0.00858      0.00827     0.000121     0.000189        0.553            1       0.0778        0.121        0.131        0.152
     95  1700      0.00231      0.00118     0.000109      0.00102        0.272         0.38       0.0664        0.116         0.34        0.353
     95  1800       0.0312       0.0307      0.00011     0.000306         0.96         1.94       0.0748        0.116        0.188        0.193
     95  1900      0.00213      0.00162     0.000128     0.000375        0.359        0.445       0.0799        0.125        0.182        0.214
     95  2000      0.00299      0.00278     0.000139     7.12e-05        0.441        0.582       0.0794         0.13       0.0821       0.0932
     95  2039      0.00897      0.00861     0.000224     0.000143        0.672         1.03        0.102        0.165        0.132        0.132

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     95   100      0.00545       0.0044     0.000134     0.000919        0.473        0.732       0.0748        0.128         0.28        0.335
     95   182        0.149        0.147     0.000126      0.00192          2.6         4.23       0.0669        0.124        0.485        0.485


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              95 9416.794    0.001       0.0253      0.00012     0.000622        0.026        0.835         1.76       0.0756        0.121        0.213        0.276
! Validation         95 9416.794    0.001        0.023     0.000127      0.00118       0.0243        0.795         1.66       0.0773        0.125        0.287        0.379
Wall time: 9416.794938571751
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     96   100       0.0684       0.0673     7.83e-05     0.000975         1.44         2.87       0.0632       0.0978        0.267        0.345
     96   200       0.0787       0.0781     0.000105     0.000508         1.41         3.09       0.0713        0.113        0.219        0.249
     96   300       0.0537        0.053     0.000132     0.000542         1.35         2.54        0.086        0.127        0.193        0.257
     96   400      0.00352      0.00243      7.6e-05      0.00102        0.407        0.545       0.0662       0.0963        0.321        0.352
     96   500       0.0536       0.0526     0.000196     0.000802         1.35         2.53        0.101        0.155        0.264        0.313
     96   600       0.0231       0.0226     0.000143      0.00032        0.847         1.66       0.0842        0.132        0.187        0.198
     96   700       0.0144       0.0138     0.000118     0.000544        0.772          1.3       0.0717         0.12        0.222        0.258
     96   800      0.00915      0.00879     0.000116     0.000249        0.699         1.04       0.0727        0.119        0.152        0.174
     96   900       0.0527       0.0518     0.000101     0.000756         1.34         2.52        0.077        0.111        0.251        0.304
     96  1000      0.00664      0.00493     0.000147      0.00156        0.527        0.776       0.0849        0.134        0.377        0.436
     96  1100       0.0388       0.0383     9.85e-05     0.000379        0.955         2.16        0.069         0.11        0.199        0.215
     96  1200       0.0473       0.0456     0.000144      0.00156         1.06         2.36       0.0839        0.133        0.428        0.436
     96  1300        0.033       0.0325     9.66e-05     0.000417         1.02         1.99       0.0682        0.109        0.196        0.226
     96  1400       0.0319       0.0315     0.000141     0.000258        0.867         1.96       0.0864        0.131        0.146        0.178
     96  1500       0.0116       0.0112     6.83e-05     0.000371        0.526         1.17       0.0622       0.0913         0.14        0.213
     96  1600       0.0455       0.0451     0.000187     0.000247          1.3         2.35       0.0978        0.151         0.14        0.174
     96  1700       0.0115       0.0113     0.000103     0.000125        0.612         1.18       0.0743        0.112       0.0919        0.124
     96  1800      0.00665      0.00641     7.91e-05     0.000156        0.543        0.885        0.065       0.0983       0.0946        0.138
     96  1900        0.048       0.0475     0.000193     0.000263         1.16         2.41       0.0927        0.153        0.164        0.179
     96  2000       0.0227       0.0224     6.85e-05     0.000286        0.817         1.65       0.0613       0.0914        0.161        0.187
     96  2039       0.0399       0.0394     0.000133      0.00036         1.15         2.19       0.0842        0.127        0.209         0.21

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     96   100      0.00466       0.0044     8.31e-05     0.000183         0.46        0.733       0.0612        0.101        0.128        0.149
     96   182        0.138        0.138     5.58e-05     2.16e-08         2.53          4.1       0.0596       0.0826      0.00163      0.00163


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              96 9515.619    0.001       0.0254      0.00012     0.000632       0.0261        0.832         1.76       0.0754        0.121        0.212        0.278
! Validation         96 9515.619    0.001       0.0238     9.33e-05     0.000373       0.0243        0.781         1.69       0.0686        0.107        0.169        0.214
Wall time: 9515.620123103261
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     97   100      0.00692      0.00632     0.000107     0.000496        0.631        0.878       0.0711        0.114        0.169        0.246
     97   200       0.0464       0.0448     0.000156      0.00143         1.36         2.34       0.0901        0.138        0.335        0.418
     97   300       0.0736        0.073     0.000158     0.000499         1.42         2.98       0.0953        0.139        0.224        0.247
     97   400       0.0313        0.031     0.000111     0.000258        0.876         1.94       0.0768        0.116        0.163        0.178
     97   500        0.143        0.143     0.000118      0.00036         1.92         4.18       0.0749         0.12        0.201         0.21
     97   600       0.0753       0.0742     0.000206     0.000921         1.51         3.01       0.0939        0.158        0.271        0.335
     97   700      0.00587      0.00372      9.7e-05      0.00205         0.46        0.674       0.0656        0.109        0.398          0.5
     97   800       0.0445       0.0437      0.00013     0.000708         1.19         2.31       0.0873        0.126        0.279        0.294
     97   900       0.0149       0.0143     0.000103     0.000531        0.819         1.32        0.076        0.112        0.212        0.255
     97  1000        0.136        0.136     7.62e-05     0.000127         1.69         4.08       0.0649       0.0964        0.109        0.125
     97  1100       0.0408       0.0404     9.76e-05     0.000274         0.98         2.22       0.0643        0.109        0.154        0.183
     97  1200       0.0433       0.0423     0.000152     0.000862        0.942         2.27       0.0877        0.136        0.251        0.324
     97  1300      0.00803      0.00748     5.94e-05     0.000487        0.524        0.956       0.0523       0.0852        0.228        0.244
     97  1400       0.0333       0.0328     0.000108     0.000401         1.05            2       0.0741        0.115        0.208        0.221
     97  1500       0.0606       0.0599      0.00015     0.000544         1.39          2.7       0.0824        0.135        0.237        0.258
     97  1600       0.0398       0.0393      8.3e-05     0.000401         1.23         2.19       0.0669        0.101        0.156        0.221
     97  1700       0.0334       0.0332     9.67e-05     7.46e-05        0.927         2.01       0.0728        0.109       0.0718       0.0954
     97  1800        0.018       0.0173     0.000116     0.000579         0.81         1.45       0.0762        0.119        0.233        0.266
     97  1900       0.0499       0.0493     0.000128     0.000491          1.2         2.45       0.0849        0.125        0.221        0.245
     97  2000       0.0142       0.0139     8.76e-05     0.000192        0.606          1.3        0.069        0.103        0.139        0.153
     97  2039       0.0461       0.0453     0.000116     0.000678         1.22         2.35       0.0834        0.119        0.287        0.288

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     97   100       0.0105      0.00887     0.000106       0.0015        0.613         1.04       0.0713        0.114        0.347        0.427
     97   182        0.137        0.137      4.2e-05     0.000611         2.51         4.09       0.0561       0.0716        0.273        0.273


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              97 9614.509    0.001       0.0251      0.00012     0.000608       0.0258        0.832         1.75       0.0747        0.121         0.21        0.272
! Validation         97 9614.509    0.001       0.0246     0.000102      0.00098       0.0257        0.834         1.72       0.0731        0.112        0.285        0.346
Wall time: 9614.509777009487
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     98   100      0.00154      0.00133      7.4e-05     0.000139        0.288        0.403        0.065       0.0951        0.117         0.13
     98   200      0.00585      0.00497     9.12e-05     0.000784        0.469        0.779       0.0699        0.105        0.183        0.309
     98   300      0.00736      0.00711     7.93e-05     0.000166        0.543        0.932       0.0674       0.0984        0.116        0.142
     98   400      0.00325      0.00142     0.000163      0.00167        0.297        0.417       0.0987        0.141        0.359        0.451
     98   500       0.0125       0.0121     7.06e-05     0.000331        0.549         1.22       0.0648       0.0929        0.188        0.201
     98   600      0.00726      0.00591     9.65e-05      0.00126        0.448        0.849       0.0703        0.109        0.311        0.392
     98   700       0.0386       0.0379     0.000147     0.000559         1.11         2.15       0.0816        0.134        0.166        0.261
     98   800      0.00782      0.00703     0.000251     0.000534        0.648        0.927        0.122        0.175        0.233        0.255
     98   900       0.0279       0.0273     0.000116     0.000483        0.978         1.82        0.076        0.119        0.191        0.243
     98  1000      0.00786      0.00744      0.00015     0.000271        0.626        0.953       0.0723        0.135        0.162        0.182
     98  1100       0.0105      0.00964     0.000146     0.000755        0.731         1.08       0.0873        0.133        0.284        0.304
     98  1200      0.00881      0.00828     5.12e-05     0.000472        0.497         1.01       0.0535       0.0791        0.204         0.24
     98  1300       0.0219       0.0212     0.000182     0.000495        0.895         1.61        0.101        0.149        0.236        0.246
     98  1400       0.0659       0.0647     0.000162        0.001         1.25         2.81       0.0866        0.141        0.335         0.35
     98  1500       0.0609       0.0605     0.000183     0.000251         1.61         2.72       0.0887         0.15        0.161        0.175
     98  1600      0.00615       0.0058     8.13e-05     0.000268        0.619        0.842       0.0694       0.0996        0.166        0.181
     98  1700       0.0162       0.0159     6.67e-05     0.000228        0.733         1.39       0.0588       0.0902        0.141        0.167
     98  1800       0.0228       0.0225      0.00011     0.000112        0.891         1.66        0.075        0.116        0.104        0.117
     98  1900        0.011       0.0102     7.88e-05     0.000703        0.626         1.12        0.058       0.0981        0.256        0.293
     98  2000       0.0442       0.0432     0.000122     0.000883         1.23          2.3       0.0837        0.122        0.268        0.328
     98  2039      0.00757      0.00678     6.15e-05     0.000722        0.598         0.91       0.0621       0.0867        0.246        0.297

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     98   100      0.00342      0.00323     0.000115     8.36e-05        0.415        0.627       0.0679        0.118       0.0863        0.101
     98   182        0.151        0.151     9.48e-05     0.000329          2.6         4.29       0.0669        0.108          0.2          0.2


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              98 9713.349    0.001       0.0252     0.000118     0.000649       0.0259        0.829         1.75        0.076         0.12        0.216        0.281
! Validation         98 9713.349    0.001       0.0229     0.000114     0.000325       0.0233         0.79         1.65        0.075        0.118        0.154        0.199
Wall time: 9713.349634304643
! Best model       98    0.023
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     99   100      0.00678      0.00645     0.000173     0.000148         0.55        0.888       0.0824        0.145       0.0993        0.135
     99   200      0.00362      0.00311     0.000108     0.000396        0.449        0.616       0.0667        0.115        0.162         0.22
     99   300      0.00307      0.00188     0.000102      0.00109         0.37        0.479       0.0709        0.112        0.315        0.365
     99   400       0.0408       0.0397      0.00012     0.000975         1.06          2.2       0.0714        0.121        0.301        0.345
     99   500      0.00944      0.00918     9.85e-05      0.00016        0.687         1.06       0.0703         0.11         0.13         0.14
     99   600       0.0331       0.0325     0.000115     0.000523        0.884         1.99       0.0752        0.118        0.234        0.253
     99   700      0.00672      0.00613     0.000102     0.000488        0.495        0.865       0.0748        0.112        0.221        0.244
     99   800       0.0559       0.0546     0.000135      0.00119         1.25         2.58        0.087        0.129        0.325        0.382
     99   900       0.0381       0.0369     9.91e-05       0.0012         1.11         2.12       0.0778         0.11        0.333        0.382
     99  1000       0.0324       0.0322        6e-05     0.000149         1.02         1.98       0.0629       0.0856        0.108        0.135
     99  1100       0.0757       0.0751     0.000114     0.000523         1.52         3.03       0.0824        0.118        0.196        0.253
     99  1200       0.0241       0.0236     0.000115     0.000371        0.862          1.7       0.0709        0.118        0.176        0.213
     99  1300      0.00203      0.00134     6.69e-05     0.000618        0.292        0.405       0.0621       0.0903        0.272        0.275
     99  1400        0.112        0.111     0.000291      0.00107         1.57         3.68       0.0954        0.188        0.213        0.362
     99  1500       0.0563       0.0545     0.000143      0.00161         1.59         2.58       0.0825        0.132        0.393        0.443
     99  1600       0.0031      0.00245     7.59e-05     0.000577        0.339        0.547       0.0664       0.0963        0.241        0.265
     99  1700        0.116        0.115     8.35e-05     0.000434         1.94         3.75       0.0683        0.101        0.194         0.23
     99  1800       0.0418       0.0414     0.000115     0.000318         1.15         2.25       0.0807        0.118        0.124        0.197
     99  1900      0.00305      0.00279     8.49e-05     0.000169          0.4        0.584       0.0682        0.102       0.0927        0.144
     99  2000       0.0257       0.0253     8.62e-05     0.000345        0.904         1.76       0.0731        0.103        0.183        0.205
     99  2039       0.0394       0.0389     0.000138      0.00028         1.41         2.18       0.0743         0.13        0.152        0.185

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
     99   100      0.00471      0.00445     0.000152     0.000105        0.498        0.737       0.0768        0.136       0.0939        0.113
     99   182        0.148        0.146      0.00029      0.00187         2.54         4.23       0.0872        0.188        0.478        0.478


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train              99 9812.298    0.001       0.0249     0.000124     0.000555       0.0256        0.823         1.74       0.0763        0.123          0.2         0.26
! Validation         99 9812.298    0.001       0.0237     0.000158     0.000352       0.0242        0.832         1.68       0.0833        0.138        0.159        0.205
Wall time: 9812.298878543079
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    100   100      0.00143     0.000884     9.78e-05      0.00045        0.204        0.328       0.0679        0.109        0.193        0.234
    100   200       0.0294       0.0288     0.000115     0.000411         1.12         1.88       0.0778        0.119        0.177        0.224
    100   300      0.00292      0.00208     7.63e-05      0.00076        0.327        0.504       0.0502       0.0965        0.254        0.305
    100   400       0.0111       0.0103     0.000118     0.000676        0.767         1.12       0.0826         0.12        0.273        0.287
    100   500       0.0974       0.0966     0.000108     0.000666         2.11         3.43       0.0803        0.115        0.204        0.285
    100   600       0.0157       0.0152     0.000109     0.000365        0.843         1.36       0.0788        0.115         0.19        0.211
    100   700       0.0151       0.0147     0.000131     0.000243        0.821         1.34       0.0889        0.126        0.164        0.172
    100   800       0.0146       0.0144     0.000151     0.000116        0.813         1.32       0.0833        0.136        0.107        0.119
    100   900        0.021       0.0204      0.00012     0.000458        0.863         1.58        0.082        0.121        0.159        0.236
    100  1000       0.0621       0.0617     0.000162      0.00017         1.33         2.75       0.0815        0.141         0.13        0.144
    100  1100       0.0302       0.0299     8.07e-05     0.000293        0.983         1.91       0.0636       0.0993        0.169        0.189
    100  1200      0.00155      0.00107     4.89e-05     0.000436        0.263        0.361       0.0559       0.0772        0.186        0.231
    100  1300       0.0346       0.0335     0.000231     0.000813         1.14         2.02       0.0994        0.168        0.243        0.315
    100  1400      0.00696      0.00627      8.5e-05     0.000602        0.588        0.875       0.0718        0.102        0.239        0.271
    100  1500       0.0497       0.0494     0.000107     0.000225         1.23         2.45       0.0799        0.114        0.141        0.166
    100  1600       0.0456       0.0453     0.000145     0.000121         1.16         2.35        0.083        0.133        0.117        0.121
    100  1700       0.0489        0.048     9.17e-05     0.000713         1.37         2.42       0.0762        0.106        0.229        0.295
    100  1800       0.0299       0.0294     7.85e-05      0.00038        0.734         1.89       0.0634       0.0979        0.173        0.215
    100  1900      0.00163      0.00122     9.32e-05     0.000317        0.299        0.385       0.0695        0.107        0.176        0.197
    100  2000      0.00354      0.00294     8.77e-05     0.000512        0.392        0.599       0.0658        0.103        0.197         0.25
    100  2039      0.00353      0.00341     0.000126     5.36e-07        0.444        0.645       0.0756        0.124      0.00807      0.00809

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    100   100      0.00455      0.00386     0.000113     0.000578        0.487        0.687       0.0699        0.118        0.184        0.266
    100   182         0.15        0.149     9.28e-05     0.000195         2.58         4.27       0.0637        0.106        0.154        0.154


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             100 9911.198    0.001       0.0253     0.000118     0.000594        0.026         0.83         1.76       0.0749         0.12        0.207        0.269
! Validation        100 9911.198    0.001       0.0227     0.000109     0.000468       0.0233        0.777         1.65       0.0732        0.116         0.19        0.239
Wall time: 9911.199125342071
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    101   100       0.0252       0.0248     0.000106     0.000266        0.732         1.74       0.0635        0.114        0.162         0.18
    101   200      0.00553      0.00439     0.000212     0.000922        0.417        0.732       0.0858        0.161        0.294        0.335
    101   300       0.0126        0.012     7.77e-05      0.00047        0.595         1.21       0.0681       0.0974        0.198         0.24
    101   400       0.0512       0.0509     0.000171     0.000128         1.26         2.49        0.093        0.145        0.103        0.125
    101   500       0.0612       0.0608     8.12e-05     0.000291         1.35         2.72       0.0662       0.0995        0.184        0.189
    101   600       0.0364       0.0341     0.000209      0.00203         1.31         2.04       0.0961         0.16        0.459        0.498
    101   700       0.0284        0.027     0.000557     0.000919         1.15         1.81        0.113        0.261         0.28        0.335
    101   800       0.0164        0.016     7.39e-05     0.000361        0.854          1.4       0.0638        0.095        0.173         0.21
    101   900       0.0416       0.0412     0.000203     0.000194         1.41         2.24        0.105        0.157        0.133        0.154
    101  1000       0.0272       0.0269     8.23e-05      0.00015        0.751         1.81       0.0699          0.1        0.107        0.135
    101  1100       0.0102      0.00937     6.47e-05     0.000724        0.578         1.07       0.0566       0.0889        0.267        0.297
    101  1200       0.0447       0.0443     0.000109     0.000231         1.33         2.33       0.0711        0.115        0.126        0.168
    101  1300       0.0392       0.0389     0.000185     9.53e-05         1.16         2.18       0.0874         0.15       0.0823        0.108
    101  1400       0.0757       0.0749      0.00015      0.00064         1.35         3.02       0.0821        0.135        0.246         0.28
    101  1500       0.0132       0.0127     6.24e-05     0.000427        0.671         1.24       0.0603       0.0873        0.205        0.228
    101  1600       0.0259       0.0253     9.01e-05      0.00052         1.01         1.76       0.0651        0.105        0.195        0.252
    101  1700       0.0048      0.00137     8.89e-05      0.00334        0.274        0.409       0.0695        0.104        0.621        0.638
    101  1800       0.0541       0.0534     8.88e-05     0.000665        0.944         2.55       0.0632        0.104        0.221        0.285
    101  1900       0.0041      0.00304     0.000106      0.00096         0.36        0.609       0.0717        0.114        0.247        0.342
    101  2000      0.00178      0.00153     7.12e-05     0.000171        0.266        0.433        0.066       0.0933        0.114        0.145
    101  2039        0.088       0.0871     0.000162     0.000715         1.99         3.26          0.1        0.141        0.264        0.295

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    101   100      0.00418      0.00322     0.000167     0.000795        0.398        0.627       0.0802        0.143        0.251        0.312
    101   182        0.108        0.107     7.09e-05     8.72e-05         2.22         3.62       0.0656        0.093        0.103        0.103


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             101 10010.123    0.001       0.0248     0.000123     0.000563       0.0255         0.82         1.74       0.0759        0.122        0.202        0.262
! Validation        101 10010.123    0.001       0.0264     0.000131     0.000502       0.0271        0.888         1.78       0.0817        0.127        0.197        0.248
Wall time: 10010.124530754983
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    102   100      0.00412      0.00378      0.00013     0.000213        0.413        0.679       0.0752        0.126         0.15        0.161
    102   200        0.017       0.0165     0.000112     0.000411        0.836         1.42       0.0775        0.117        0.192        0.224
    102   300       0.0138       0.0135     0.000121     0.000204        0.716         1.28       0.0782        0.121        0.137        0.158
    102   400       0.0154       0.0148     0.000114     0.000446        0.823         1.35       0.0829        0.118         0.18        0.233
    102   500       0.0214         0.02     0.000123      0.00125        0.694         1.56       0.0799        0.123         0.34         0.39
    102   600       0.0204       0.0197     0.000151      0.00049        0.794         1.55       0.0804        0.136        0.221        0.245
    102   700      0.00905      0.00874      0.00011     0.000196        0.582         1.03       0.0781        0.116        0.139        0.155
    102   800       0.0429       0.0413       0.0002      0.00137         1.22         2.25       0.0893        0.156        0.292         0.41
    102   900       0.0133       0.0129     9.41e-05     0.000278        0.821         1.25       0.0657        0.107        0.166        0.184
    102  1000       0.0517       0.0508     0.000102     0.000783         1.09         2.49       0.0751        0.111        0.242        0.309
    102  1100      0.00511      0.00473     0.000138     0.000241        0.483         0.76        0.074         0.13        0.105        0.172
    102  1200       0.0198       0.0193     7.34e-05     0.000358         0.79         1.54       0.0641       0.0946         0.16        0.209
    102  1300       0.0259       0.0251     0.000199     0.000541        0.847         1.75       0.0944        0.156        0.255        0.257
    102  1400         0.12        0.119     0.000114      0.00101         1.45         3.81       0.0818        0.118        0.318        0.352
    102  1500       0.0311       0.0301     0.000115     0.000939        0.852         1.92       0.0817        0.119        0.326        0.338
    102  1600       0.0184       0.0175      0.00011     0.000809        0.875         1.46       0.0854        0.116         0.29        0.314
    102  1700       0.0245       0.0242     8.51e-05     0.000263        0.892         1.72       0.0653        0.102         0.16        0.179
    102  1800       0.0191        0.019      6.3e-05     4.13e-05        0.749         1.52       0.0593       0.0877       0.0669        0.071
    102  1900        0.048       0.0474     7.17e-05     0.000601        0.928          2.4        0.064       0.0935        0.204        0.271
    102  2000       0.0397       0.0395     0.000136     0.000137         1.12          2.2       0.0783        0.129        0.119        0.129
    102  2039       0.0122       0.0102     0.000122      0.00182        0.753         1.12       0.0806        0.122        0.466        0.472

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    102   100      0.00776      0.00513     0.000124      0.00251        0.559        0.791       0.0753        0.123        0.418        0.553
    102   182        0.163        0.161     6.14e-05      0.00244         2.68         4.43       0.0627       0.0866        0.546        0.546


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             102 10109.140    0.001       0.0248     0.000123     0.000588       0.0255        0.825         1.74       0.0754        0.122        0.206        0.268
! Validation        102 10109.140    0.001       0.0253      0.00012      0.00207       0.0275        0.879         1.74       0.0794        0.121        0.399        0.502
Wall time: 10109.14150864631
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    103   100       0.0366       0.0359     8.62e-05      0.00065         1.05         2.09       0.0684        0.103        0.246        0.282
    103   200       0.0203       0.0193     0.000158      0.00083        0.743         1.53       0.0943        0.139        0.302        0.318
    103   300       0.0235       0.0224     7.09e-05      0.00106        0.766         1.65       0.0658       0.0931        0.282         0.36
    103   400       0.0229       0.0225     7.14e-05     0.000268        0.802         1.66       0.0618       0.0933        0.159        0.181
    103   500       0.0238       0.0237     4.32e-05     0.000127        0.695          1.7       0.0517       0.0726       0.0946        0.124
    103   600       0.0124       0.0108     9.82e-05      0.00152        0.665         1.15       0.0746        0.109        0.289        0.431
    103   700       0.0629       0.0627     0.000103      0.00012         1.56         2.77       0.0711        0.112        0.113        0.121
    103   800      0.00278       0.0025     0.000117     0.000157        0.342        0.553        0.065         0.12        0.125        0.138
    103   900         0.02       0.0195     0.000136     0.000377        0.862         1.54       0.0886        0.129        0.188        0.214
    103  1000      0.00346      0.00328     9.02e-05     9.09e-05        0.455        0.633       0.0679        0.105       0.0879        0.105
    103  1100      0.00332      0.00263      6.2e-05      0.00063        0.392        0.567       0.0635        0.087        0.215        0.277
    103  1200       0.0236       0.0231     5.47e-05     0.000479        0.694         1.68        0.052       0.0817        0.167        0.242
    103  1300       0.0158       0.0154      5.7e-05      0.00036        0.848         1.37       0.0549       0.0834        0.199         0.21
    103  1400       0.0161       0.0156     0.000189     0.000224        0.759         1.38       0.0898        0.152        0.163        0.165
    103  1500       0.0287       0.0284     9.29e-05     0.000208        0.986         1.86       0.0704        0.107        0.147        0.159
    103  1600       0.0554       0.0544     0.000477     0.000505         1.56         2.58        0.127        0.241        0.221        0.248
    103  1700        0.042       0.0413     0.000245     0.000403        0.915         2.25       0.0996        0.173        0.143        0.222
    103  1800       0.0022      0.00135     7.48e-05     0.000773        0.272        0.407       0.0616       0.0955         0.22        0.307
    103  1900       0.0035       0.0033     8.71e-05     0.000106        0.447        0.635       0.0723        0.103        0.095        0.114
    103  2000      0.00671      0.00598     5.58e-05     0.000671        0.458        0.854       0.0537       0.0826        0.261        0.286
    103  2039      0.00246      0.00179     6.97e-05     0.000602        0.366        0.467       0.0685       0.0922        0.264        0.271

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    103   100      0.00553      0.00508     0.000103     0.000338        0.564        0.788       0.0671        0.112        0.154        0.203
    103   182        0.138        0.138     3.87e-05     0.000361         2.49          4.1       0.0535       0.0688         0.21         0.21


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             103 10208.095    0.001       0.0245     0.000124     0.000595       0.0252        0.822         1.73       0.0749        0.123        0.208         0.27
! Validation        103 10208.095    0.001       0.0224     0.000115     0.000852       0.0233        0.778         1.63       0.0718        0.118        0.244        0.323
Wall time: 10208.096530646086
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    104   100       0.0438       0.0406     0.000222      0.00296         1.16         2.23        0.112        0.165        0.474        0.602
    104   200      0.00239      0.00196     4.83e-05     0.000387        0.345        0.489       0.0562       0.0768         0.19        0.217
    104   300       0.0116       0.0112     8.39e-05     0.000379        0.822         1.17       0.0679        0.101        0.165        0.215
    104   400       0.0111       0.0108     9.05e-05     0.000134        0.693         1.15       0.0666        0.105        0.112        0.128
    104   500     0.000943     0.000794      5.8e-05     9.12e-05        0.238        0.311       0.0624       0.0841        0.101        0.105
    104   600       0.0045      0.00298     4.96e-05      0.00147        0.384        0.603        0.049       0.0778        0.329        0.424
    104   700       0.0396       0.0392     0.000118     0.000231        0.872         2.19       0.0743         0.12        0.149        0.168
    104   800       0.0407       0.0402     0.000129     0.000321         1.18         2.22       0.0815        0.125        0.177        0.198
    104   900       0.0238       0.0235     0.000135      0.00021         0.83         1.69       0.0841        0.128        0.148         0.16
    104  1000       0.0508       0.0492     0.000108      0.00151         1.08         2.45       0.0763        0.115        0.391        0.429
    104  1100       0.0228       0.0222     0.000474     9.44e-05        0.987         1.65        0.123         0.24       0.0953        0.107
    104  1200      0.00392      0.00356     6.89e-05     0.000288        0.389        0.659       0.0642       0.0917        0.157        0.187
    104  1300      0.00264      0.00224     8.73e-05     0.000319        0.344        0.522       0.0744        0.103        0.173        0.197
    104  1400      0.00434      0.00406     0.000189     9.47e-05        0.484        0.704       0.0891        0.152       0.0822        0.108
    104  1500      0.00198      0.00187     0.000101     8.72e-06        0.312        0.478       0.0672        0.111       0.0273       0.0326
    104  1600       0.0101      0.00991     7.04e-05     0.000109        0.702          1.1        0.064       0.0927       0.0907        0.115
    104  1700       0.0101      0.00886     0.000101      0.00116        0.604         1.04       0.0729        0.111        0.331        0.376
    104  1800      0.00524      0.00461     0.000101     0.000535        0.464         0.75       0.0685        0.111        0.212        0.256
    104  1900       0.0714        0.071     0.000146     0.000232         1.27         2.94       0.0846        0.134        0.162        0.168
    104  2000       0.0122       0.0118     0.000107     0.000267        0.564          1.2       0.0715        0.114        0.151        0.181
    104  2039       0.0659       0.0656     0.000153     0.000185         1.56         2.83       0.0933        0.136        0.131         0.15

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    104   100      0.00509      0.00479     0.000139     0.000164        0.475        0.765       0.0766         0.13        0.133        0.141
    104   182        0.131        0.131     6.05e-05     0.000485         2.47            4       0.0603        0.086        0.243        0.243


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             104 10307.055    0.001       0.0245     0.000125      0.00057       0.0252        0.817         1.73       0.0752        0.124        0.205        0.264
! Validation        104 10307.055    0.001       0.0238     0.000118     0.000438       0.0244        0.821         1.69       0.0776         0.12        0.183        0.231
Wall time: 10307.056220456958
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    105   100       0.0276       0.0263     0.000122      0.00115         1.01         1.79       0.0818        0.122        0.323        0.375
    105   200       0.0104         0.01     0.000129      0.00024        0.715         1.11       0.0753        0.126        0.163        0.171
    105   300       0.0404       0.0401     9.89e-05     0.000256        0.924         2.21       0.0688         0.11         0.13        0.177
    105   400       0.0222       0.0213     0.000102     0.000783        0.683         1.61       0.0709        0.112        0.258        0.309
    105   500      0.00107     0.000866     9.72e-05     0.000104        0.224        0.325       0.0626        0.109       0.0862        0.113
    105   600       0.0554       0.0548     0.000132      0.00047         1.53         2.59       0.0901        0.127        0.208        0.239
    105   700      0.00667      0.00588     0.000421     0.000363        0.547        0.848        0.135        0.227        0.172        0.211
    105   800       0.0131       0.0124     9.25e-05     0.000668        0.724         1.23       0.0738        0.106        0.235        0.286
    105   900      0.00719       0.0068     8.92e-05     0.000296        0.551        0.911       0.0724        0.104        0.183         0.19
    105  1000       0.0111       0.0105     0.000159     0.000387        0.716         1.13       0.0886        0.139        0.188        0.217
    105  1100       0.0124       0.0118     9.62e-05     0.000499        0.673          1.2        0.071        0.108         0.24        0.247
    105  1200       0.0372       0.0365     9.17e-05     0.000571         1.27         2.11       0.0724        0.106        0.222        0.264
    105  1300       0.0497       0.0493     0.000134     0.000261         1.09         2.45       0.0869        0.128        0.164        0.178
    105  1400      0.00134     0.000762     3.69e-05     0.000542        0.207        0.305       0.0457       0.0672        0.209        0.257
    105  1500      0.00849      0.00828     9.42e-05     0.000113        0.724         1.01       0.0718        0.107       0.0887        0.118
    105  1600       0.0216        0.021     0.000213      0.00033        0.901          1.6       0.0975        0.161        0.176        0.201
    105  1700       0.0199       0.0191     4.89e-05     0.000811        0.814         1.53        0.054       0.0773        0.275        0.315
    105  1800       0.0275       0.0265     6.37e-05     0.000862        0.973          1.8       0.0622       0.0882        0.287        0.324
    105  1900       0.0831       0.0824     0.000216     0.000445         1.74         3.17       0.0949        0.163        0.215        0.233
    105  2000       0.0214       0.0207     9.15e-05     0.000569        0.826         1.59       0.0665        0.106        0.196        0.264
    105  2039      0.00227      0.00211     0.000101     5.28e-05        0.377        0.508       0.0714        0.111       0.0582       0.0803

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    105   100      0.00863      0.00791     0.000211     0.000506        0.642        0.983       0.0805         0.16        0.215        0.249
    105   182        0.123         0.12     7.86e-05      0.00297         2.38         3.82       0.0679        0.098        0.602        0.602


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             105 10405.980    0.001       0.0245     0.000124     0.000593       0.0253        0.823         1.73       0.0746        0.123        0.206        0.269
! Validation        105 10405.980    0.001       0.0224     0.000156      0.00129       0.0238        0.796         1.64       0.0803        0.138        0.329        0.396
Wall time: 10405.980857141316
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    106   100       0.0288       0.0283     0.000113     0.000326        0.945         1.86       0.0766        0.117        0.181        0.199
    106   200       0.0125       0.0119     0.000223     0.000368        0.871         1.21       0.0896        0.165        0.199        0.212
    106   300       0.0244       0.0233     0.000122     0.000993        0.948         1.69       0.0805        0.122        0.298        0.348
    106   400      0.00216      0.00191     5.39e-05     0.000203        0.342        0.483       0.0504       0.0812        0.127        0.157
    106   500      0.00919      0.00855     0.000136     0.000508        0.719         1.02       0.0797        0.129        0.248        0.249
    106   600       0.0177       0.0173     8.32e-05     0.000282        0.955         1.45       0.0722        0.101        0.132        0.185
    106   700       0.0135       0.0128     0.000216     0.000484        0.814         1.25       0.0943        0.162        0.208        0.243
    106   800       0.0045      0.00412     0.000139     0.000243        0.393        0.709       0.0835         0.13        0.168        0.172
    106   900       0.0111       0.0103     8.52e-05     0.000762        0.615         1.12        0.068        0.102        0.265        0.305
    106  1000       0.0405       0.0396     0.000135     0.000785            1          2.2       0.0832        0.128        0.295        0.309
    106  1100      0.00191      0.00142      7.4e-05     0.000409        0.278        0.417       0.0596        0.095        0.169        0.223
    106  1200       0.0135       0.0124     8.25e-05      0.00102        0.742         1.23       0.0646          0.1        0.334        0.353
    106  1300       0.0513        0.051     6.89e-05     0.000163         1.13          2.5       0.0547       0.0917        0.132        0.141
    106  1400       0.0158       0.0147     9.57e-05     0.000966        0.755         1.34       0.0635        0.108        0.268        0.343
    106  1500      0.00237      0.00181     0.000113     0.000446        0.349         0.47       0.0752        0.118         0.22        0.233
    106  1600       0.0138       0.0135     9.36e-05     0.000183        0.578         1.28       0.0553        0.107        0.124         0.15
    106  1700       0.0594       0.0583     0.000109     0.000986         1.28         2.67       0.0803        0.116        0.293        0.347
    106  1800        0.111        0.111     0.000141     0.000189         1.51         3.68       0.0828        0.131        0.123        0.152
    106  1900      0.00222      0.00162     7.01e-05     0.000528        0.344        0.445       0.0612       0.0925        0.195        0.254
    106  2000       0.0198       0.0192      8.5e-05     0.000565        0.628         1.53       0.0679        0.102        0.248        0.263
    106  2039       0.0455        0.045     0.000128     0.000356         1.57         2.34       0.0875        0.125        0.193        0.209

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    106   100      0.00813      0.00739     7.55e-05     0.000657        0.562         0.95       0.0608        0.096        0.173        0.283
    106   182        0.184        0.183     0.000185      0.00136         2.89         4.72       0.0702         0.15        0.408        0.408


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             106 10505.016    0.001       0.0242     0.000127     0.000624        0.025         0.82         1.72       0.0738        0.125        0.213        0.276
! Validation        106 10505.016    0.001       0.0228     9.22e-05     0.000508       0.0234        0.768         1.64       0.0662        0.106        0.195        0.248
Wall time: 10505.016873627901
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    107   100       0.0443       0.0441      0.00014     0.000112         1.02         2.32       0.0735        0.131        0.105        0.117
    107   200       0.0034      0.00184     9.02e-05      0.00146        0.329        0.474       0.0726        0.105        0.365        0.423
    107   300       0.0125       0.0121     0.000133     0.000213        0.688         1.22       0.0662        0.128        0.127        0.161
    107   400       0.0139       0.0135     0.000147     0.000203         0.72         1.28       0.0714        0.134        0.127        0.157
    107   500       0.0362       0.0356     0.000121      0.00051         1.02         2.08       0.0834        0.122        0.193         0.25
    107   600      0.00167      0.00112     0.000105     0.000445        0.277         0.37       0.0661        0.113         0.21        0.233
    107   700       0.0621       0.0617     0.000134     0.000204         1.66         2.74       0.0819        0.128        0.132        0.158
    107   800       0.0407       0.0387     0.000149      0.00185         1.05         2.17       0.0764        0.135         0.42        0.475
    107   900      0.00423      0.00389     4.78e-05     0.000297        0.416        0.689       0.0456       0.0764        0.169        0.191
    107  1000       0.0061      0.00578     0.000171     0.000151        0.528         0.84        0.091        0.145        0.115        0.136
    107  1100       0.0152       0.0151     4.68e-05     9.56e-06        0.783         1.36       0.0516       0.0756       0.0316       0.0342
    107  1200      0.00516      0.00431     0.000157     0.000697        0.493        0.725        0.073        0.138        0.202        0.292
    107  1300       0.0347       0.0345     0.000112     9.44e-05        0.938         2.05        0.075        0.117        0.092        0.107
    107  1400      0.00755      0.00724     8.75e-05     0.000225        0.544         0.94       0.0644        0.103        0.155        0.166
    107  1500       0.0108       0.0103     0.000264     0.000272        0.657         1.12       0.0909        0.179        0.164        0.182
    107  1600       0.0106       0.0102     0.000243      0.00015        0.631         1.12       0.0883        0.172        0.123        0.136
    107  1700       0.0236       0.0234     0.000131     0.000113        0.978         1.69        0.082        0.126        0.105        0.118
    107  1800      0.00217      0.00191     9.15e-05     0.000167        0.336        0.482        0.069        0.106        0.104        0.143
    107  1900       0.0232       0.0228     6.69e-05     0.000389        0.937         1.67        0.062       0.0904        0.166        0.218
    107  2000      0.00772        0.007     5.72e-05     0.000663        0.651        0.925       0.0586       0.0835        0.282        0.285
    107  2039       0.0159       0.0158     8.46e-05     9.49e-06         1.02         1.39       0.0668        0.102        0.032        0.034

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    107   100      0.00407       0.0038     0.000105     0.000162        0.412        0.681        0.066        0.113         0.12        0.141
    107   182         0.14         0.14     5.13e-05     0.000256         2.57         4.13       0.0628       0.0791        0.177        0.177


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             107 10603.856    0.001       0.0244     0.000122     0.000581       0.0251        0.813         1.73       0.0724        0.122        0.205        0.266
! Validation        107 10603.856    0.001       0.0233     0.000102     0.000559       0.0239        0.783         1.67       0.0711        0.112        0.195        0.262
Wall time: 10603.856724515557
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    108   100      0.00417      0.00394     0.000131     9.84e-05        0.493        0.693       0.0826        0.126       0.0969         0.11
    108   200      0.00539       0.0032     0.000109      0.00208         0.37        0.625       0.0748        0.116        0.417        0.504
    108   300       0.0221       0.0218     0.000125     0.000182        0.742         1.63       0.0743        0.123        0.147        0.149
    108   400       0.0217       0.0205     5.93e-05      0.00106        0.777         1.58       0.0553       0.0851        0.316        0.359
    108   500       0.0215       0.0199     0.000102      0.00151        0.861         1.56       0.0759        0.112        0.263        0.429
    108   600       0.0468       0.0462     0.000112     0.000444         1.33         2.38        0.075        0.117        0.212        0.233
    108   700       0.0946       0.0938     0.000156     0.000643         1.85         3.38       0.0906        0.138        0.231         0.28
    108   800      0.00342      0.00299     4.31e-05      0.00039        0.419        0.604       0.0502       0.0725        0.162        0.218
    108   900       0.0372       0.0367     8.18e-05     0.000422         1.19         2.12       0.0677       0.0999        0.164        0.227
    108  1000        0.029       0.0285     0.000108     0.000325        0.936         1.87       0.0711        0.115        0.165        0.199
    108  1100       0.0102      0.00952     5.64e-05     0.000639        0.543         1.08        0.058       0.0829        0.231        0.279
    108  1200        0.011       0.0107     7.42e-05     0.000257        0.533         1.14       0.0616       0.0952        0.149        0.177
    108  1300      0.00623      0.00568     8.64e-05     0.000459        0.546        0.833        0.066        0.103        0.198        0.237
    108  1400       0.0556       0.0552     6.91e-05      0.00032         1.16          2.6       0.0578       0.0919        0.165        0.198
    108  1500      0.00614      0.00574      9.7e-05     0.000299        0.599        0.837       0.0758        0.109        0.157        0.191
    108  1600       0.0459       0.0451     0.000101     0.000627         1.17         2.35       0.0733        0.111        0.234        0.277
    108  1700       0.0178       0.0171     0.000111      0.00058        0.775         1.45        0.078        0.116        0.248        0.266
    108  1800       0.0346       0.0343     7.85e-05     0.000128        0.971         2.05       0.0681       0.0979        0.104        0.125
    108  1900        0.041       0.0405     0.000147     0.000412         1.26         2.22       0.0944        0.134         0.22        0.224
    108  2000        0.013       0.0127       0.0001     0.000192        0.673         1.24       0.0741        0.111        0.144        0.153
    108  2039      0.00224      0.00191     5.66e-05     0.000274        0.337        0.483       0.0567       0.0831        0.154        0.183

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    108   100      0.00602      0.00579     9.86e-05     0.000134        0.556        0.841       0.0659         0.11        0.115        0.128
    108   182        0.136        0.135     7.97e-05      0.00142         2.47         4.06       0.0583       0.0986        0.416        0.416


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             108 10702.728    0.001       0.0243     0.000122     0.000584        0.025        0.815         1.72       0.0733        0.122        0.206        0.267
! Validation        108 10702.728    0.001       0.0221     0.000108     0.000621       0.0228        0.778         1.62       0.0704        0.115        0.218        0.275
Wall time: 10702.729090109468
! Best model      108    0.023
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    109   100       0.0227       0.0224     0.000169     0.000146        0.975         1.65       0.0798        0.144        0.126        0.133
    109   200      0.00158      0.00118     9.83e-05     0.000302        0.283        0.379       0.0683         0.11        0.126        0.192
    109   300       0.0125       0.0122     5.86e-05     0.000215        0.531         1.22       0.0541       0.0846        0.136        0.162
    109   400      0.00471      0.00455     9.69e-05     6.82e-05        0.467        0.745       0.0547        0.109       0.0741       0.0913
    109   500       0.0306       0.0304     0.000116     0.000135         1.03         1.92       0.0704        0.119        0.103        0.129
    109   600        0.005      0.00484     5.98e-05     9.81e-05        0.488        0.769       0.0585       0.0855        0.109        0.109
    109   700      0.00262      0.00223     0.000135     0.000255        0.396        0.522       0.0864        0.128        0.161        0.176
    109   800       0.0121       0.0111     8.76e-05     0.000909        0.712         1.17       0.0678        0.103         0.31        0.333
    109   900       0.0091      0.00733     9.89e-05      0.00167        0.606        0.946       0.0705         0.11        0.335        0.451
    109  1000       0.0327       0.0321     0.000186     0.000464        0.905         1.98       0.0809        0.151        0.177        0.238
    109  1100       0.0283        0.028     0.000159     0.000117         1.11         1.85       0.0914        0.139        0.114        0.119
    109  1200       0.0407       0.0401     0.000132     0.000472         1.21         2.21       0.0822        0.127        0.189         0.24
    109  1300       0.0172        0.017     7.45e-05     0.000151        0.613         1.44       0.0626       0.0953        0.111        0.136
    109  1400       0.0552       0.0542     0.000172     0.000875         1.45         2.57       0.0964        0.145        0.237        0.327
    109  1500       0.0793       0.0788     6.14e-05     0.000473         1.22          3.1       0.0562       0.0866         0.19         0.24
    109  1600       0.0684       0.0678     7.36e-05     0.000517         1.25         2.88       0.0653       0.0948        0.242        0.251
    109  1700       0.0142       0.0136     0.000146     0.000451        0.752         1.29       0.0684        0.134        0.181        0.235
    109  1800      0.00419      0.00315     7.71e-05     0.000962        0.418         0.62       0.0683        0.097        0.295        0.343
    109  1900      0.00334      0.00251     5.97e-05     0.000765        0.389        0.554       0.0571       0.0854        0.255        0.306
    109  2000       0.0281       0.0277     0.000162     0.000282        0.899         1.84       0.0724        0.141        0.157        0.185
    109  2039      0.00635      0.00606     0.000154     0.000131         0.51         0.86        0.077        0.137        0.105        0.127

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    109   100      0.00613      0.00576     0.000147     0.000228        0.595        0.838       0.0738        0.134         0.12        0.167
    109   182        0.173        0.172     0.000134     0.000216         2.79         4.59       0.0664        0.128        0.162        0.162


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             109 10801.685    0.001       0.0242     0.000121     0.000602       0.0249        0.812         1.72       0.0724        0.121        0.208        0.271
! Validation        109 10801.685    0.001       0.0223     0.000121     0.000422       0.0229        0.779         1.63       0.0735        0.122        0.174        0.227
Wall time: 10801.685657031834
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    110   100       0.0585       0.0575      7.9e-05     0.000905         1.25         2.65       0.0662       0.0982        0.274        0.332
    110   200       0.0365       0.0354     6.76e-05      0.00108         1.03         2.08       0.0611       0.0909        0.334        0.364
    110   300       0.0119        0.011     0.000353     0.000576        0.735         1.16       0.0905        0.208        0.244        0.265
    110   400       0.0189       0.0177     0.000134      0.00105        0.763         1.47       0.0738        0.128        0.325        0.358
    110   500       0.0128       0.0124     0.000116     0.000321        0.758         1.23        0.079        0.119        0.188        0.198
    110   600       0.0164       0.0159     0.000113     0.000403        0.739         1.39       0.0801        0.117        0.213        0.222
    110   700       0.0155       0.0136     0.000105      0.00183        0.689         1.29        0.078        0.113        0.454        0.472
    110   800       0.0258       0.0248      0.00026     0.000788        0.907         1.74       0.0897        0.178        0.218         0.31
    110   900       0.0111       0.0108     0.000132     0.000168        0.637         1.15       0.0759        0.127        0.123        0.143
    110  1000       0.0323       0.0319     0.000307     8.07e-05        0.895         1.97       0.0915        0.193       0.0837       0.0993
    110  1100       0.0382        0.037       0.0001      0.00107        0.865         2.12       0.0734        0.111        0.341        0.362
    110  1200      0.00249        0.002     7.48e-05     0.000416        0.331        0.495       0.0609       0.0956        0.188        0.225
    110  1300       0.0424       0.0417     6.94e-05     0.000655        0.832         2.26       0.0573        0.092        0.255        0.283
    110  1400       0.0524       0.0506     0.000104      0.00173         1.09         2.48       0.0698        0.113        0.359         0.46
    110  1500       0.0903       0.0889     0.000161      0.00117         1.52         3.29       0.0862         0.14        0.335        0.379
    110  1600      0.00602      0.00545      3.4e-05     0.000536        0.421        0.816       0.0452       0.0644         0.23        0.256
    110  1700      0.00376      0.00278     0.000128     0.000846        0.452        0.583       0.0762        0.125        0.254        0.321
    110  1800      0.00767      0.00735     8.78e-05     0.000227        0.634        0.948       0.0713        0.104        0.152        0.166
    110  1900      0.00992      0.00952     0.000113     0.000288        0.631         1.08       0.0759        0.118        0.163        0.188
    110  2000        0.131        0.131     0.000149     0.000549         2.07         3.99       0.0885        0.135        0.238        0.259
    110  2039       0.0357       0.0347     0.000145      0.00086         1.26         2.06       0.0918        0.133        0.294        0.324

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    110   100      0.00663      0.00625     0.000156     0.000227        0.581        0.874       0.0762        0.138        0.145        0.167
    110   182        0.179        0.179     0.000136     1.06e-05         2.86         4.67       0.0703        0.129        0.036        0.036


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             110 10900.603    0.001       0.0241     0.000122     0.000631       0.0249        0.813         1.72       0.0725        0.122        0.213        0.277
! Validation        110 10900.603    0.001       0.0227     0.000126     0.000497       0.0233        0.803         1.64        0.077        0.124        0.191        0.247
Wall time: 10900.605580858886
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    111   100       0.0477       0.0469     8.82e-05     0.000706         1.44         2.39       0.0672        0.104        0.247        0.294
    111   200       0.0105      0.00985     9.38e-05     0.000517        0.722          1.1       0.0646        0.107        0.172        0.251
    111   300      0.00356      0.00332     9.37e-05     0.000146        0.411        0.636        0.062        0.107        0.125        0.133
    111   400        0.035       0.0347     9.02e-05     0.000189        0.847         2.06        0.069        0.105        0.122        0.152
    111   500      0.00354       0.0027     5.64e-05     0.000779         0.48        0.574       0.0581        0.083        0.271        0.308
    111   600      0.00725      0.00682     7.54e-05     0.000356        0.592        0.912       0.0697       0.0959         0.17        0.209
    111   700       0.0226       0.0209      8.1e-05      0.00165        0.837          1.6       0.0666       0.0994        0.442        0.449
    111   800       0.0346       0.0344     3.79e-05     8.59e-05        0.894         2.05       0.0502       0.0681       0.0803        0.102
    111   900      0.00184      0.00167     6.49e-05     0.000105        0.335        0.452       0.0536        0.089       0.0933        0.113
    111  1000       0.0234       0.0232     0.000132     0.000101        0.989         1.68       0.0743        0.127        0.106        0.111
    111  1100      0.00175      0.00155     0.000146     5.95e-05        0.324        0.435       0.0716        0.133       0.0651       0.0852
    111  1200       0.0233       0.0231     0.000132     8.14e-05         0.93         1.68       0.0751        0.127         0.08       0.0997
    111  1300      0.00724      0.00547     8.79e-05      0.00168         0.55        0.817       0.0679        0.104        0.386        0.453
    111  1400      0.00334      0.00231     0.000166     0.000859        0.353        0.531       0.0797        0.142        0.283        0.324
    111  1500       0.0684       0.0668     8.52e-05      0.00151         1.41         2.86       0.0717        0.102        0.352         0.43
    111  1600      0.00161      0.00101     0.000147     0.000454        0.275         0.35       0.0841        0.134        0.209        0.235
    111  1700       0.0115       0.0109     5.54e-05     0.000571        0.483         1.15       0.0544       0.0823        0.235        0.264
    111  1800       0.0254       0.0247     5.04e-05     0.000676        0.917         1.74       0.0534       0.0784        0.268        0.287
    111  1900       0.0193       0.0177     0.000371      0.00125        0.933         1.47        0.121        0.213        0.336        0.391
    111  2000      0.00236      0.00213     9.29e-05     0.000136        0.346         0.51       0.0687        0.106        0.118        0.129
    111  2039       0.0353       0.0346     0.000592     5.27e-05         1.29         2.06       0.0977        0.269         0.07       0.0802

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    111   100      0.00545      0.00517     0.000108     0.000172        0.498        0.794       0.0697        0.115        0.118        0.145
    111   182        0.129        0.129     4.17e-05     0.000238         2.41         3.97       0.0542       0.0714         0.17         0.17


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             111 10999.570    0.001        0.024     0.000124     0.000539       0.0247         0.81         1.71       0.0737        0.123        0.198        0.256
! Validation        111 10999.570    0.001       0.0225     0.000111     0.000378        0.023         0.77         1.64       0.0716        0.117        0.169        0.215
Wall time: 10999.570720858872
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    112   100      0.00416      0.00316     0.000149     0.000849        0.429        0.621       0.0879        0.135        0.307        0.322
    112   200      0.00211      0.00197     7.56e-05      6.2e-05        0.393        0.491       0.0618       0.0961        0.074        0.087
    112   300       0.0339       0.0326     8.56e-05      0.00114         1.17            2       0.0648        0.102        0.339        0.373
    112   400       0.0116       0.0104     7.53e-05      0.00118         0.58         1.13       0.0646       0.0959        0.321         0.38
    112   500      0.00799      0.00747     0.000158      0.00036        0.617        0.955       0.0707        0.139        0.177         0.21
    112   600      0.00901      0.00836     0.000107     0.000544        0.548         1.01       0.0712        0.114        0.246        0.258
    112   700       0.0265       0.0256     8.68e-05     0.000821        0.764         1.77       0.0658        0.103        0.273        0.317
    112   800       0.0564        0.056     0.000118     0.000257         1.26         2.62       0.0669         0.12        0.156        0.177
    112   900      0.00154      0.00133     0.000123      9.1e-05        0.277        0.402       0.0694        0.123       0.0792        0.105
    112  1000      0.00521        0.004     0.000357     0.000854         0.53        0.699       0.0807        0.209        0.226        0.323
    112  1100      0.00555      0.00464        7e-05     0.000835        0.492        0.753       0.0634       0.0925        0.295        0.319
    112  1200       0.0106      0.00867      7.9e-05      0.00186        0.673         1.03       0.0608       0.0982        0.416        0.477
    112  1300        0.027       0.0253     0.000132      0.00158        0.892         1.76       0.0725        0.127        0.425        0.439
    112  1400       0.0365       0.0353      7.5e-05      0.00113            1         2.07       0.0634       0.0957         0.25        0.372
    112  1500       0.0269       0.0265     0.000131     0.000228        0.947          1.8       0.0842        0.126        0.149        0.167
    112  1600      0.00253      0.00202     0.000103     0.000406        0.329        0.497       0.0696        0.112        0.175        0.223
    112  1700       0.0411       0.0395     0.000142      0.00142         1.06          2.2       0.0779        0.132        0.318        0.416
    112  1800       0.0151       0.0149     8.92e-05     7.33e-05        0.795         1.35       0.0662        0.104       0.0823       0.0946
    112  1900      0.00716      0.00566     0.000117      0.00139        0.547        0.831       0.0811        0.119        0.309        0.412
    112  2000       0.0443       0.0441     0.000126     0.000151         1.35         2.32        0.083        0.124        0.101        0.136
    112  2039       0.0412        0.041       0.0001     0.000117          1.3         2.24       0.0765        0.111        0.102        0.119

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    112   100      0.00717      0.00656     8.22e-05     0.000526         0.53        0.895       0.0663          0.1        0.193        0.253
    112   182        0.121         0.12     6.82e-05     0.000589         2.34         3.83       0.0663       0.0913        0.268        0.268


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             112 11098.420    0.001       0.0239     0.000126     0.000604       0.0246        0.808         1.71        0.073        0.124        0.207        0.271
! Validation        112 11098.420    0.001       0.0225     0.000108     0.000686       0.0233        0.785         1.64        0.072        0.115        0.224         0.29
Wall time: 11098.421762563288
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    113   100      0.00862      0.00705     0.000118      0.00145        0.572        0.927       0.0767         0.12        0.391        0.421
    113   200       0.0396       0.0381     0.000148      0.00133         1.21         2.16       0.0804        0.134        0.362        0.403
    113   300       0.0372       0.0369     0.000137     0.000178         1.24         2.12       0.0814        0.129        0.137        0.147
    113   400       0.0431       0.0428     0.000116     0.000214         1.04         2.29       0.0759        0.119        0.147        0.162
    113   500       0.0658       0.0645     0.000325     0.000985         1.61         2.81        0.106        0.199        0.313        0.347
    113   600      0.00426      0.00407     9.46e-05     9.26e-05        0.498        0.705       0.0769        0.107       0.0837        0.106
    113   700       0.0306       0.0301     0.000113     0.000401         0.99         1.92       0.0764        0.118         0.19        0.221
    113   800      0.00606      0.00559     0.000166     0.000306        0.464        0.826       0.0801        0.142        0.134        0.193
    113   900      0.00262      0.00242     0.000129     6.34e-05        0.349        0.544       0.0758        0.125       0.0799        0.088
    113  1000       0.0065      0.00598     0.000148     0.000377          0.6        0.854       0.0883        0.134        0.176        0.214
    113  1100      0.00711      0.00668     8.01e-05     0.000348        0.571        0.903       0.0658       0.0989         0.18        0.206
    113  1200      0.00284      0.00254     9.61e-05     0.000199        0.365        0.557       0.0687        0.108        0.101        0.156
    113  1300       0.0655       0.0649     5.13e-05     0.000484         1.38         2.82        0.056       0.0791        0.211        0.243
    113  1400       0.0049      0.00482      5.2e-05     2.49e-05        0.522        0.767       0.0527       0.0797       0.0527       0.0551
    113  1500        0.093        0.092     9.86e-05      0.00098         1.22         3.35       0.0674         0.11        0.243        0.346
    113  1600       0.0968       0.0952     0.000126      0.00149         1.95         3.41       0.0883        0.124        0.358        0.427
    113  1700       0.0122       0.0116     9.82e-05     0.000523        0.837         1.19       0.0757        0.109        0.221        0.253
    113  1800       0.0349       0.0334     0.000119      0.00131         1.04         2.02       0.0807         0.12        0.356          0.4
    113  1900      0.00998      0.00948     9.37e-05     0.000408        0.509         1.08       0.0653        0.107        0.181        0.223
    113  2000      0.00753      0.00653     0.000216     0.000788        0.599        0.893       0.0818        0.162        0.255         0.31
    113  2039      0.00115     0.000504     6.29e-05     0.000579        0.159        0.248       0.0439       0.0877        0.266        0.266

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    113   100      0.00442      0.00411     0.000108     0.000206        0.459        0.708       0.0628        0.115        0.134        0.159
    113   182        0.124        0.123     5.44e-05     0.000861         2.35         3.88       0.0566       0.0815        0.324        0.324


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             113 11197.193    0.001       0.0239      0.00013      0.00057       0.0246        0.815         1.71       0.0733        0.126        0.204        0.264
! Validation        113 11197.193    0.001       0.0218     9.39e-05     0.000392       0.0223        0.759         1.61       0.0666        0.107        0.175        0.218
Wall time: 11197.19449929893
! Best model      113    0.022
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    114   100       0.0433       0.0427     0.000164     0.000455         1.27         2.28       0.0851        0.142        0.204        0.236
    114   200      0.00497      0.00457     6.19e-05     0.000336        0.553        0.747       0.0587       0.0869        0.156        0.203
    114   300      0.00769      0.00748     3.33e-05      0.00017        0.411        0.956       0.0427       0.0637        0.131        0.144
    114   400       0.0186       0.0175     0.000143      0.00102        0.874         1.46       0.0811        0.132        0.336        0.353
    114   500      0.00313      0.00087      4.9e-05      0.00221        0.241        0.326       0.0536       0.0774        0.416        0.519
    114   600       0.0256       0.0253      7.6e-05     0.000273        0.874         1.76       0.0648       0.0963        0.111        0.183
    114   700       0.0721        0.071     7.67e-05      0.00098          1.2         2.94       0.0638       0.0968        0.231        0.346
    114   800       0.0148       0.0138     9.79e-05     0.000957        0.728          1.3         0.08        0.109        0.323        0.342
    114   900       0.0134       0.0133     6.38e-05     4.96e-05         0.74         1.28        0.061       0.0882       0.0596       0.0778
    114  1000       0.0539       0.0531     6.85e-05     0.000752            1         2.55       0.0641       0.0915        0.214        0.303
    114  1100       0.0335        0.032     8.05e-05      0.00141          0.8         1.98       0.0587       0.0991        0.407        0.416
    114  1200      0.00307      0.00234        6e-05     0.000664        0.401        0.535       0.0616       0.0856        0.252        0.285
    114  1300       0.0136       0.0135     0.000129     6.69e-05        0.608         1.28       0.0801        0.126       0.0824       0.0904
    114  1400       0.0212       0.0207      5.3e-05     0.000531        0.795         1.59       0.0569       0.0804        0.205        0.255
    114  1500      0.00685       0.0066     0.000126     0.000133        0.624        0.897       0.0834        0.124       0.0973        0.127
    114  1600       0.0415       0.0413     8.39e-05     0.000123         1.07         2.24       0.0683        0.101        0.105        0.123
    114  1700      0.00412      0.00331     7.63e-05     0.000725        0.435        0.636       0.0611       0.0965         0.22        0.298
    114  1800       0.0177        0.017     0.000184     0.000436        0.754         1.44       0.0782         0.15        0.188        0.231
    114  1900       0.0711       0.0697     0.000153      0.00116         1.49         2.92       0.0917        0.137        0.275        0.377
    114  2000       0.0154       0.0147     0.000139     0.000562        0.813         1.34       0.0841         0.13        0.214        0.262
    114  2039       0.0121       0.0117     0.000183     0.000259        0.681         1.19       0.0793        0.149         0.15        0.178

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    114   100      0.00502      0.00455     0.000128     0.000343        0.531        0.745        0.073        0.125        0.147        0.205
    114   182        0.159        0.159     0.000132     8.71e-05         2.76         4.41       0.0717        0.127        0.103        0.103


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             114 11296.118    0.001       0.0238     0.000122     0.000601       0.0245        0.809          1.7       0.0711        0.122        0.208        0.271
! Validation        114 11296.118    0.001       0.0236     0.000131     0.000651       0.0244         0.82         1.68       0.0784        0.126        0.214        0.282
Wall time: 11296.118624180555
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    115   100       0.0381       0.0375     0.000117     0.000505        0.849         2.14       0.0753        0.119        0.217        0.248
    115   200      0.00522      0.00463     0.000129     0.000454        0.516        0.752       0.0781        0.125         0.17        0.236
    115   300      0.00506      0.00434     5.87e-05     0.000665        0.496        0.728       0.0555       0.0847        0.281        0.285
    115   400       0.0317       0.0313     7.45e-05     0.000397        0.959         1.95       0.0606       0.0954        0.183         0.22
    115   500      0.00663      0.00588     0.000131     0.000616        0.541        0.848       0.0644        0.126        0.249        0.274
    115   600      0.00743      0.00719     0.000119     0.000114         0.65        0.937       0.0783        0.121        0.105        0.118
    115   700      0.00493      0.00481     8.64e-05     3.11e-05        0.463        0.766       0.0631        0.103       0.0583       0.0616
    115   800      0.00164      0.00138     7.18e-05     0.000194        0.311         0.41        0.057       0.0936        0.123        0.154
    115   900       0.0213        0.021     8.03e-05     0.000198        0.798          1.6       0.0687        0.099        0.117        0.155
    115  1000       0.0472       0.0454     0.000157      0.00163         1.34         2.35       0.0828        0.138        0.445        0.446
    115  1100       0.0023      0.00147     0.000103     0.000726         0.28        0.423       0.0679        0.112        0.271        0.298
    115  1200      0.00231       0.0018     0.000133     0.000377        0.272        0.469       0.0737        0.128        0.159        0.214
    115  1300      0.00857      0.00733     3.24e-05       0.0012        0.583        0.946       0.0493       0.0629        0.309        0.383
    115  1400        0.016       0.0152     0.000255     0.000466        0.685         1.36        0.097        0.177        0.217        0.238
    115  1500       0.0312       0.0297     0.000644     0.000901        0.922          1.9        0.103         0.28        0.289        0.332
    115  1600       0.0264       0.0261     7.52e-05     0.000145         1.04         1.79       0.0702       0.0958        0.105        0.133
    115  1700       0.0482       0.0471     0.000112     0.000997         1.06          2.4       0.0746        0.117        0.324        0.349
    115  1800      0.00516      0.00466     7.25e-05     0.000425          0.5        0.754        0.064       0.0941        0.181        0.228
    115  1900      0.00321      0.00275      0.00012     0.000346        0.391        0.579       0.0682        0.121        0.176        0.206
    115  2000      0.00377      0.00362     0.000106     4.75e-05        0.462        0.664       0.0686        0.114       0.0671       0.0761
    115  2039      0.00902      0.00874     0.000153     0.000127        0.698         1.03       0.0905        0.137       0.0882        0.125

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    115   100      0.00561      0.00527     0.000185     0.000164        0.541        0.802       0.0764         0.15        0.118        0.141
    115   182        0.127        0.126     0.000135     0.000309         2.45         3.93       0.0702        0.129        0.194        0.194


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             115 11395.013    0.001       0.0236     0.000134     0.000527       0.0243        0.808          1.7       0.0734        0.128        0.196        0.254
! Validation        115 11395.013    0.001       0.0226     0.000161     0.000353       0.0231        0.827         1.64       0.0791         0.14         0.16        0.208
Wall time: 11395.01485543698
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    116   100      0.00652      0.00591     0.000123     0.000485        0.499        0.849       0.0704        0.122        0.173        0.243
    116   200       0.0487       0.0479     0.000176      0.00058         1.37         2.42       0.0743        0.147        0.249        0.266
    116   300        0.018       0.0177      0.00015     0.000155        0.624         1.47       0.0859        0.135        0.109        0.138
    116   400      0.00781      0.00748      7.3e-05      0.00026        0.569        0.955       0.0577       0.0944        0.173        0.178
    116   500       0.0718       0.0712     0.000221     0.000409         1.28         2.95       0.0997        0.164         0.19        0.223
    116   600       0.0134       0.0131     0.000102     0.000218        0.657         1.26       0.0659        0.112        0.128        0.163
    116   700      0.00562       0.0052     0.000118     0.000292        0.521        0.797       0.0808         0.12        0.182        0.189
    116   800       0.0566        0.056     0.000213     0.000318         1.36         2.62       0.0861        0.161        0.174        0.197
    116   900      0.00342      0.00274     0.000113     0.000567        0.386        0.578       0.0782        0.117        0.246        0.263
    116  1000       0.0156       0.0153     8.36e-05      0.00019        0.731         1.37       0.0714        0.101         0.13        0.152
    116  1100       0.0136       0.0129     6.22e-05     0.000582        0.654         1.26       0.0591       0.0871        0.234        0.266
    116  1200      0.00505      0.00452      0.00015     0.000372        0.483        0.743       0.0705        0.135         0.13        0.213
    116  1300       0.0253        0.025     5.59e-05     0.000301        0.925         1.75       0.0583       0.0826        0.169        0.192
    116  1400      0.00475      0.00455     5.71e-05     0.000146        0.459        0.745       0.0574       0.0835        0.105        0.133
    116  1500       0.0416       0.0397     0.000102      0.00179         1.23          2.2       0.0782        0.112        0.398        0.467
    116  1600       0.0242       0.0233     6.74e-05     0.000846         0.82         1.69       0.0631       0.0907        0.291        0.321
    116  1700       0.0228       0.0219     0.000147     0.000716        0.945         1.64       0.0736        0.134        0.221        0.296
    116  1800      0.00717      0.00665     5.52e-05      0.00046        0.573        0.901       0.0592       0.0821        0.235        0.237
    116  1900       0.0185       0.0154     0.000616      0.00246         0.84         1.37        0.103        0.274        0.404        0.548
    116  2000       0.0219       0.0213     9.34e-05     0.000486        0.851         1.61       0.0678        0.107        0.218        0.244
    116  2039        0.109        0.108     8.42e-05     0.000174         1.78         3.64        0.061        0.101        0.131        0.146

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    116   100      0.00763      0.00713     0.000176     0.000328        0.618        0.933       0.0671        0.147        0.177          0.2
    116   182        0.149        0.149      3.9e-05     7.63e-06         2.54         4.27       0.0509        0.069       0.0305       0.0305


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             116 11493.893    0.001       0.0235     0.000128     0.000516       0.0241        0.806         1.69       0.0728        0.125        0.194        0.251
! Validation        116 11493.893    0.001       0.0224      0.00011     0.000445       0.0229        0.784         1.63       0.0657        0.116        0.181        0.234
Wall time: 11493.893944822252
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    117   100       0.0152       0.0148     5.04e-05     0.000376        0.681         1.34       0.0518       0.0785        0.142        0.214
    117   200       0.0106       0.0101     3.85e-05     0.000474        0.622         1.11       0.0501       0.0685        0.195         0.24
    117   300      0.00227      0.00152     0.000112      0.00063         0.31        0.431       0.0753        0.117        0.259        0.277
    117   400      0.00825      0.00735     0.000245     0.000648        0.659        0.947       0.0959        0.173        0.235        0.281
    117   500      0.00695      0.00604     0.000457     0.000459        0.665        0.858        0.112        0.236        0.201        0.237
    117   600      0.00872      0.00727      0.00019      0.00126        0.647        0.942       0.0971        0.152        0.289        0.392
    117   700       0.0223       0.0212      0.00012     0.000966        0.831         1.61       0.0748        0.121        0.291        0.343
    117   800       0.0418       0.0409     0.000112     0.000799         1.12         2.23       0.0723        0.117        0.238        0.312
    117   900       0.0218       0.0212     0.000241     0.000408        0.867         1.61       0.0997        0.172        0.177        0.223
    117  1000       0.0448       0.0438     0.000121     0.000844         1.18         2.31       0.0768        0.122        0.223        0.321
    117  1100      0.00606      0.00534     0.000114     0.000613        0.481        0.807       0.0689        0.118        0.234        0.273
    117  1200       0.0366       0.0355     0.000259     0.000778         1.09         2.08        0.119        0.178        0.257        0.308
    117  1300       0.0144       0.0141     0.000152     0.000196        0.679         1.31       0.0781        0.136         0.14        0.155
    117  1400       0.0344       0.0335     0.000162     0.000733        0.844         2.02       0.0785        0.141        0.196        0.299
    117  1500       0.0264        0.026     0.000125     0.000244        0.968         1.78       0.0854        0.124        0.168        0.173
    117  1600      0.00177      0.00135     6.54e-05     0.000352        0.259        0.406       0.0634       0.0893        0.188        0.207
    117  1700       0.0167       0.0162     8.56e-05     0.000489        0.799          1.4       0.0741        0.102        0.194        0.244
    117  1800        0.058       0.0577     0.000119     0.000179         1.13         2.66       0.0691         0.12        0.135        0.148
    117  1900       0.0113      0.00959     0.000119      0.00159        0.623         1.08       0.0806         0.12        0.373         0.44
    117  2000       0.0204       0.0193     6.04e-05      0.00097        0.753         1.54       0.0568       0.0859        0.206        0.344
    117  2039      0.00399      0.00341     5.14e-05     0.000533        0.431        0.645       0.0597       0.0792        0.253        0.255

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    117   100      0.00693      0.00653     8.84e-05     0.000309        0.484        0.893       0.0602        0.104        0.158        0.194
    117   182       0.0833       0.0832     4.17e-05     5.66e-07         1.95         3.19       0.0521       0.0713      0.00831      0.00831


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             117 11592.873    0.001       0.0235     0.000131      0.00058       0.0242        0.806         1.69       0.0724        0.126        0.205        0.266
! Validation        117 11592.873    0.001       0.0252     8.76e-05     0.000535       0.0258        0.859         1.74       0.0634        0.104         0.19        0.256
Wall time: 11592.873730286956
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    118   100      0.00504      0.00489     0.000103     4.62e-05        0.528        0.772       0.0703        0.112       0.0658       0.0751
    118   200       0.0335       0.0328     9.95e-05     0.000634         0.95            2       0.0758         0.11        0.209        0.278
    118   300      0.00348      0.00305     7.92e-05     0.000352        0.359         0.61       0.0639       0.0983        0.191        0.207
    118   400       0.0332       0.0323     0.000441     0.000411         1.14         1.99         0.11        0.232        0.191        0.224
    118   500      0.00483      0.00458     5.11e-05     0.000193        0.471        0.748       0.0606        0.079        0.142        0.154
    118   600       0.0244       0.0237     9.99e-05     0.000535        0.791          1.7       0.0726         0.11        0.207        0.256
    118   700      0.00876      0.00853      0.00016     7.12e-05        0.609         1.02       0.0927         0.14       0.0884       0.0932
    118   800       0.0194       0.0188     6.06e-05     0.000562        0.879         1.51       0.0575        0.086         0.23        0.262
    118   900      0.00162      0.00116     4.57e-05     0.000421        0.257        0.376       0.0462       0.0747        0.191        0.227
    118  1000       0.0543       0.0535     0.000171     0.000712        0.945         2.55       0.0715        0.144        0.229        0.295
    118  1100       0.0153       0.0139     6.45e-05      0.00127        0.715          1.3       0.0522       0.0887         0.38        0.393
    118  1200       0.0223        0.022     0.000153     0.000138         1.02         1.64       0.0849        0.137        0.107         0.13
    118  1300       0.0145       0.0142      0.00012     0.000258        0.785         1.31       0.0733        0.121        0.173        0.177
    118  1400       0.0107       0.0103     5.98e-05     0.000294        0.655         1.12       0.0588       0.0854        0.158         0.19
    118  1500       0.0598       0.0594     9.39e-05     0.000297         1.38         2.69       0.0725        0.107        0.185         0.19
    118  1600      0.00686      0.00622     6.38e-05     0.000582        0.497        0.871       0.0555       0.0883        0.238        0.266
    118  1700       0.0457       0.0446     8.08e-05      0.00105         1.11         2.33        0.067       0.0993        0.299        0.358
    118  1800         0.03       0.0298     6.01e-05     0.000204        0.975         1.91       0.0612       0.0857        0.129        0.158
    118  1900       0.0124       0.0122     7.23e-05     9.05e-05        0.631         1.22       0.0643       0.0939        0.076        0.105
    118  2000       0.0301        0.028     7.89e-05      0.00194        0.722         1.85       0.0605       0.0982        0.462        0.487
    118  2039       0.0393       0.0393     3.94e-05     1.37e-06         1.22         2.19       0.0505       0.0694       0.0105       0.0129

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    118   100      0.00404      0.00342     0.000136     0.000483         0.42        0.646       0.0665        0.129        0.208        0.243
    118   182        0.135        0.134      7.6e-05     0.000474         2.47         4.05        0.057       0.0963        0.241        0.241


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             118 11691.803    0.001       0.0238     0.000127     0.000545       0.0244        0.805          1.7       0.0722        0.124          0.2        0.258
! Validation        118 11691.803    0.001       0.0222     0.000104     0.000453       0.0228        0.772         1.63       0.0668        0.113        0.182        0.235
Wall time: 11691.804403871298
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    119   100      0.00552      0.00492      0.00017     0.000422        0.536        0.775       0.0815        0.144        0.219        0.227
    119   200      0.00237      0.00194      0.00015     0.000282        0.312        0.486        0.085        0.135        0.148        0.185
    119   300       0.0508       0.0504     0.000184     0.000202         1.29         2.48       0.0802         0.15        0.153        0.157
    119   400       0.0108       0.0098     9.05e-05     0.000882        0.637         1.09       0.0742        0.105        0.299        0.328
    119   500       0.0246       0.0241     0.000258     0.000275        0.948         1.71       0.0902        0.177        0.181        0.183
    119   600      0.00802      0.00767      0.00011     0.000244        0.632        0.967       0.0817        0.116        0.146        0.173
    119   700      0.00287      0.00207     7.19e-05     0.000725        0.355        0.503       0.0582       0.0937        0.264        0.298
    119   800       0.0117       0.0111     7.29e-05     0.000568         0.79         1.16       0.0617       0.0944        0.258        0.263
    119   900      0.00519      0.00476     0.000124     0.000298        0.497        0.763       0.0771        0.123        0.166        0.191
    119  1000       0.0826       0.0821     0.000171     0.000385         1.34         3.17        0.086        0.144        0.174        0.217
    119  1100      0.00578      0.00311      0.00016      0.00251        0.504        0.617       0.0822         0.14        0.491        0.554
    119  1200       0.0808       0.0798      0.00018     0.000793         1.75         3.12       0.0805        0.148        0.299        0.311
    119  1300      0.00294      0.00237     3.86e-05     0.000537         0.35        0.538       0.0459       0.0686        0.228        0.256
    119  1400       0.0103      0.00988     0.000107     0.000337        0.619          1.1       0.0768        0.115        0.171        0.203
    119  1500      0.00585      0.00519     0.000199     0.000462          0.5        0.796       0.0692        0.156        0.171        0.237
    119  1600       0.0019      0.00163     6.53e-05     0.000208        0.302        0.446       0.0542       0.0893        0.143        0.159
    119  1700       0.0424       0.0413     0.000142     0.000942         1.04         2.25       0.0747        0.131        0.291        0.339
    119  1800       0.0224       0.0221     0.000153     0.000231         1.02         1.64       0.0978        0.137        0.128        0.168
    119  1900      0.00526        0.005     6.88e-05      0.00019        0.381        0.781       0.0524       0.0916        0.126        0.152
    119  2000      0.00647      0.00547     6.15e-05     0.000935        0.464        0.817       0.0596       0.0867        0.293        0.338
    119  2039      0.00724      0.00248     0.000103      0.00466        0.457         0.55       0.0827        0.112        0.754        0.754

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    119   100      0.00489        0.004      0.00013     0.000762        0.471        0.699       0.0686        0.126         0.29        0.305
    119   182        0.181         0.18     9.12e-05     0.000161         2.83         4.69         0.06        0.105         0.14         0.14


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             119 11790.656    0.001       0.0234     0.000131      0.00056       0.0241        0.807         1.69       0.0721        0.127        0.201        0.261
! Validation        119 11790.656    0.001       0.0247     0.000136      0.00107       0.0259        0.807         1.71       0.0698        0.129        0.299        0.363
Wall time: 11790.65723452717
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    120   100        0.115        0.115     8.81e-05     0.000418         2.27         3.75       0.0672        0.104        0.203        0.226
    120   200       0.0147       0.0142     7.09e-05     0.000405        0.887         1.32       0.0665        0.093        0.193        0.222
    120   300      0.00645      0.00563     6.62e-05     0.000758        0.531        0.829       0.0593       0.0899        0.291        0.304
    120   400      0.00503       0.0041     0.000105     0.000831        0.508        0.707       0.0757        0.113        0.213        0.319
    120   500      0.00671      0.00633      8.8e-05      0.00029        0.568        0.879       0.0663        0.104        0.126        0.188
    120   600       0.0103       0.0101     9.95e-05     8.91e-05        0.695         1.11       0.0707         0.11       0.0963        0.104
    120   700       0.0162       0.0155     0.000181     0.000544        0.699         1.38       0.0628        0.149        0.226        0.258
    120   800       0.0021      0.00155     5.72e-05     0.000495        0.331        0.435       0.0598       0.0835        0.215        0.246
    120   900       0.0128       0.0118     0.000828     0.000187        0.775          1.2        0.114        0.318        0.134        0.151
    120  1000       0.0661       0.0656     0.000116     0.000432         1.18         2.83       0.0756        0.119        0.199         0.23
    120  1100       0.0115       0.0106      7.2e-05     0.000863         0.61         1.14       0.0672       0.0938        0.308        0.325
    120  1200       0.0215        0.021        8e-05     0.000385         0.92          1.6       0.0656       0.0988        0.196        0.217
    120  1300       0.0112       0.0106     0.000148     0.000391        0.755         1.14       0.0804        0.134        0.156        0.218
    120  1400       0.0312       0.0293     7.25e-05      0.00179        0.876         1.89        0.057       0.0941        0.429        0.467
    120  1500       0.0294       0.0293     5.11e-05     0.000131        0.846         1.89       0.0543        0.079        0.108        0.126
    120  1600       0.0185       0.0175     0.000216     0.000757        0.982         1.46       0.0907        0.162        0.248        0.304
    120  1700      0.00728      0.00589     0.000144      0.00125        0.612        0.848        0.086        0.133        0.312        0.391
    120  1800       0.0019      0.00114     7.37e-05     0.000688        0.289        0.373        0.061       0.0949        0.271         0.29
    120  1900       0.0932       0.0926     0.000111     0.000553         1.69         3.36       0.0725        0.117         0.22         0.26
    120  2000       0.0527       0.0523     0.000104     0.000355         1.19         2.53       0.0778        0.113        0.143        0.208
    120  2039        0.008      0.00683     7.96e-05       0.0011        0.499        0.913       0.0568       0.0986        0.279        0.366

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    120   100      0.00765      0.00688      8.7e-05     0.000685        0.588        0.916       0.0658        0.103        0.222        0.289
    120   182        0.157        0.157     4.53e-05     1.03e-06         2.64         4.38       0.0564       0.0744       0.0112       0.0112


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             120 11889.468    0.001       0.0232     0.000132     0.000552       0.0239          0.8         1.68       0.0714        0.127          0.2        0.259
! Validation        120 11889.468    0.001       0.0216     0.000122     0.000475       0.0222        0.769          1.6       0.0728        0.122        0.186        0.241
Wall time: 11889.469024159014
! Best model      120    0.022
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    121   100       0.0274       0.0263     0.000167     0.000961        0.951         1.79       0.0818        0.143        0.329        0.343
    121   200      0.00881      0.00792     0.000134     0.000761        0.606        0.983       0.0803        0.128        0.197        0.305
    121   300       0.0134       0.0128     0.000128     0.000483        0.652         1.25       0.0815        0.125        0.234        0.243
    121   400       0.0372       0.0369      5.8e-05     0.000287        0.803         2.12       0.0523       0.0841         0.14        0.187
    121   500       0.0137       0.0133     6.06e-05     0.000329         0.68         1.27       0.0605        0.086        0.159        0.201
    121   600       0.0198       0.0197     0.000105     2.56e-05         1.06         1.55       0.0763        0.113       0.0369       0.0559
    121   700       0.0036      0.00259     9.55e-05     0.000908        0.383        0.563       0.0686        0.108        0.306        0.333
    121   800       0.0393        0.038       0.0006     0.000705         1.04         2.15        0.082        0.271        0.293        0.293
    121   900       0.0273       0.0255      0.00012      0.00168        0.977         1.77       0.0793        0.121        0.415        0.453
    121  1000       0.0228       0.0223     0.000165     0.000371        0.966         1.65        0.088        0.142        0.157        0.213
    121  1100       0.0203       0.0199     8.04e-05     0.000303        0.874         1.56       0.0685       0.0991        0.146        0.192
    121  1200      0.00899      0.00868      0.00011     0.000198        0.559         1.03       0.0768        0.116        0.138        0.155
    121  1300       0.0132       0.0125     0.000317     0.000436        0.778         1.23        0.106        0.197        0.206        0.231
    121  1400       0.0093      0.00892     8.87e-05     0.000294        0.582         1.04       0.0658        0.104        0.177         0.19
    121  1500      0.00805      0.00765      9.3e-05     0.000308        0.593        0.966       0.0698        0.107        0.178        0.194
    121  1600       0.0538       0.0511     0.000351      0.00229         1.39          2.5       0.0968        0.207        0.523        0.529
    121  1700       0.0405       0.0401      0.00016     0.000287        0.942         2.21       0.0692         0.14        0.142        0.187
    121  1800      0.00618       0.0059     0.000111     0.000169        0.522        0.849       0.0674        0.117        0.127        0.144
    121  1900         0.12         0.12     0.000146     0.000267         1.83         3.82        0.062        0.133         0.17        0.181
    121  2000       0.0132       0.0124     7.63e-05      0.00071        0.593         1.23       0.0652       0.0965        0.254        0.294
    121  2039       0.0287       0.0287     3.77e-05     1.25e-05        0.946         1.87       0.0516       0.0678       0.0389        0.039

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    121   100      0.00623      0.00571     0.000126     0.000399        0.542        0.835       0.0615        0.124        0.194        0.221
    121   182        0.124        0.124     3.87e-05     0.000377          2.3         3.89       0.0496       0.0688        0.214        0.214


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             121 11988.464    0.001       0.0232     0.000134     0.000538       0.0238          0.8         1.68       0.0727        0.128        0.198        0.256
! Validation        121 11988.464    0.001        0.022     0.000102     0.000501       0.0226        0.779         1.62       0.0636        0.112        0.185        0.248
Wall time: 11988.464767843485
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    122   100      0.00191      0.00162     0.000102     0.000185        0.346        0.445       0.0757        0.112        0.146         0.15
    122   200       0.0111       0.0104     0.000106     0.000618        0.694         1.13       0.0734        0.114        0.267        0.275
    122   300        0.016       0.0157     0.000132     0.000138        0.887         1.39        0.083        0.127       0.0947         0.13
    122   400        0.054       0.0538     0.000173     1.63e-05         1.31         2.56       0.0863        0.145       0.0388       0.0446
    122   500      0.00289       0.0021     6.03e-05     0.000731        0.272        0.506       0.0529       0.0858        0.208        0.299
    122   600       0.0118       0.0112     7.25e-05     0.000494        0.543         1.17       0.0625       0.0941        0.237        0.246
    122   700       0.0311       0.0305     0.000271     0.000395         1.16         1.93       0.0999        0.182        0.216         0.22
    122   800       0.0212       0.0209     0.000116     0.000124        0.905          1.6       0.0757        0.119       0.0998        0.123
    122   900      0.00891      0.00825     6.69e-05     0.000592        0.517            1       0.0578       0.0904        0.187        0.269
    122  1000       0.0273       0.0269     9.94e-05     0.000257         1.08         1.81       0.0721         0.11         0.14        0.177
    122  1100       0.0634       0.0633     0.000105     5.18e-05         1.34         2.78       0.0759        0.113       0.0766       0.0795
    122  1200       0.0162        0.016     9.87e-05     0.000105        0.899          1.4       0.0693         0.11        0.108        0.113
    122  1300       0.0544       0.0541     6.44e-05     0.000241         1.14         2.57       0.0597       0.0887        0.147        0.172
    122  1400       0.0106      0.00852     0.000133      0.00199        0.631         1.02        0.087        0.128        0.407        0.493
    122  1500        0.089       0.0886      0.00026     0.000117         1.64         3.29       0.0951        0.178       0.0837         0.12
    122  1600      0.00214     0.000812     5.74e-05      0.00127        0.249        0.315       0.0479       0.0837        0.366        0.394
    122  1700        0.015       0.0145     0.000137     0.000317        0.779         1.33        0.079        0.129        0.183        0.197
    122  1800        0.028       0.0272     0.000103     0.000763         1.01         1.82       0.0699        0.112         0.28        0.305
    122  1900       0.0039      0.00288     9.06e-05      0.00093        0.414        0.593       0.0731        0.105        0.281        0.337
    122  2000       0.0164       0.0153     9.44e-05      0.00105        0.693         1.37       0.0655        0.107         0.34        0.358
    122  2039     0.000301     0.000178     7.75e-05      4.6e-05        0.119        0.147       0.0591       0.0973       0.0731       0.0749

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    122   100      0.00373      0.00339     0.000112     0.000221         0.38        0.644       0.0666        0.117        0.133        0.164
    122   182        0.132        0.132     5.66e-05      1.3e-05         2.43         4.01       0.0515       0.0831       0.0398       0.0398


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             122 12087.339    0.001        0.023     0.000132      0.00055       0.0237        0.798         1.68       0.0717        0.127        0.199        0.259
! Validation        122 12087.339    0.001       0.0212     0.000115     0.000373       0.0216         0.76         1.59       0.0694        0.119        0.164        0.214
Wall time: 12087.340532891452
! Best model      122    0.022
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    123   100       0.0132        0.013     7.69e-05     0.000113        0.783         1.26       0.0649       0.0969        0.113        0.117
    123   200       0.0197       0.0196     9.08e-05     2.42e-05        0.749         1.55       0.0736        0.105       0.0456       0.0544
    123   300      0.00451      0.00361     0.000124     0.000773        0.494        0.664        0.086        0.123        0.288        0.307
    123   400         0.04       0.0396     0.000123     0.000308         1.16          2.2       0.0779        0.123        0.172        0.194
    123   500       0.0255       0.0245     0.000293     0.000642        0.897         1.73       0.0894        0.189        0.244         0.28
    123   600       0.0215       0.0209     6.47e-05     0.000477        0.771          1.6        0.061       0.0889        0.165        0.241
    123   700       0.0217       0.0215     8.05e-05     0.000149        0.868         1.62       0.0682       0.0992        0.109        0.135
    123   800       0.0103       0.0101     4.93e-05     0.000183        0.605         1.11       0.0501       0.0775        0.118         0.15
    123   900       0.0163       0.0157     0.000112     0.000469        0.666         1.38       0.0683        0.117        0.221        0.239
    123  1000       0.0468       0.0464      7.5e-05     0.000274         1.15         2.38       0.0571       0.0957        0.172        0.183
    123  1100       0.0142        0.014     6.88e-05     0.000122        0.641         1.31       0.0662       0.0916        0.101        0.122
    123  1200       0.0653       0.0649     0.000168     0.000232         1.46         2.82       0.0968        0.143        0.152        0.168
    123  1300       0.0122       0.0117     0.000109     0.000374        0.761          1.2       0.0747        0.115        0.178        0.214
    123  1400        0.004      0.00311     0.000106     0.000785        0.491        0.616       0.0713        0.114        0.239         0.31
    123  1500        0.043       0.0422     0.000142     0.000684         1.25         2.27       0.0818        0.132        0.238        0.289
    123  1600       0.0261       0.0247       0.0012     0.000203        0.954         1.74        0.126        0.383        0.116        0.157
    123  1700         0.02       0.0195     0.000328     0.000186        0.669         1.54       0.0838          0.2       0.0936        0.151
    123  1800      0.00508      0.00498     3.43e-05     6.59e-05         0.46         0.78       0.0474       0.0647        0.087       0.0897
    123  1900      0.00799      0.00741      0.00011     0.000465        0.613        0.951       0.0767        0.116        0.185        0.238
    123  2000       0.0174       0.0172     4.81e-05     7.23e-05        0.915         1.45       0.0528       0.0766        0.087        0.094
    123  2039       0.0706       0.0699     0.000122     0.000612          1.6         2.92       0.0769        0.122        0.265        0.273

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    123   100      0.00617      0.00544     8.89e-05     0.000633        0.497        0.815       0.0573        0.104        0.189        0.278
    123   182       0.0949        0.094      9.7e-05     0.000809         2.03         3.39       0.0568        0.109        0.314        0.314


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             123 12186.303    0.001        0.023     0.000133     0.000553       0.0237        0.801         1.68       0.0718        0.127          0.2         0.26
! Validation        123 12186.303    0.001       0.0214     8.59e-05     0.000658       0.0222        0.754         1.61       0.0595        0.102        0.213        0.283
Wall time: 12186.30423617363
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    124   100      0.00673       0.0049     0.000489      0.00133         0.52        0.774       0.0973        0.244        0.383        0.403
    124   200       0.0215         0.02     0.000114      0.00131         0.78         1.56       0.0725        0.118        0.367          0.4
    124   300       0.0188        0.018     0.000169      0.00064        0.803         1.48       0.0852        0.144         0.21         0.28
    124   400      0.00769      0.00587     0.000349      0.00148        0.502        0.846       0.0837        0.206        0.364        0.425
    124   500        0.022       0.0215     0.000227     0.000333        0.977         1.62       0.0879        0.166        0.195        0.202
    124   600      0.00493      0.00376     0.000856     0.000305        0.508        0.678       0.0968        0.323        0.153        0.193
    124   700       0.0443       0.0429     0.000106      0.00136         1.15         2.29       0.0728        0.114        0.354        0.407
    124   800       0.0206       0.0201     9.23e-05     0.000335         0.79         1.57       0.0664        0.106        0.179        0.202
    124   900       0.0136       0.0133     8.85e-05     0.000213        0.622         1.28       0.0673        0.104        0.146        0.161
    124  1000       0.0038      0.00355     0.000102     0.000149        0.455        0.658       0.0685        0.112        0.117        0.135
    124  1100       0.0372       0.0368     0.000115      0.00029         1.16         2.12         0.08        0.119        0.177        0.188
    124  1200      0.00635      0.00554     0.000103     0.000705        0.587        0.822       0.0798        0.112        0.264        0.293
    124  1300       0.0324        0.032     0.000113      0.00028        0.957         1.98       0.0783        0.118        0.156        0.185
    124  1400        0.126        0.126     0.000354     0.000122         1.49         3.92          0.1        0.208        0.102        0.122
    124  1500       0.0239       0.0237     7.78e-05     0.000102        0.726          1.7       0.0564       0.0975        0.101        0.111
    124  1600       0.0168        0.016        7e-05     0.000756          0.6          1.4       0.0585       0.0924        0.249        0.304
    124  1700      0.00266      0.00255     7.64e-05     3.36e-05         0.37        0.558       0.0568       0.0966       0.0622       0.0641
    124  1800       0.0312       0.0308     0.000104     0.000295        0.877         1.94       0.0711        0.113        0.144         0.19
    124  1900      0.00606      0.00579     8.47e-05     0.000184        0.577        0.841       0.0687        0.102        0.128         0.15
    124  2000       0.0334       0.0331     8.53e-05     0.000254         1.14         2.01       0.0689        0.102        0.155        0.176
    124  2039       0.0246       0.0243     0.000134     0.000165         1.08         1.72       0.0889        0.128        0.126        0.142

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    124   100      0.00542      0.00509     9.68e-05     0.000235          0.5        0.788       0.0663        0.109        0.139        0.169
    124   182         0.13         0.13     4.83e-05     0.000163         2.42         3.98        0.053       0.0768        0.141        0.141


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             124 12285.219    0.001       0.0229     0.000132     0.000519       0.0235        0.796         1.67       0.0714        0.127        0.195        0.252
! Validation        124 12285.219    0.001       0.0213     0.000117     0.000351       0.0217        0.758         1.59       0.0689         0.12        0.163        0.207
Wall time: 12285.219434149563
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    125   100      0.00221      0.00186     7.52e-05     0.000276        0.305        0.477       0.0636       0.0958        0.138        0.183
    125   200       0.0347       0.0346     7.45e-05     9.52e-05        0.863         2.05       0.0595       0.0954        0.089        0.108
    125   300        0.116        0.115     9.89e-05     0.000454         1.58         3.75       0.0787         0.11        0.181        0.235
    125   400       0.0434       0.0424     0.000249     0.000738         1.41         2.27        0.104        0.174        0.272          0.3
    125   500      0.00995      0.00848     5.78e-05      0.00141        0.463         1.02       0.0522        0.084        0.391        0.416
    125   600       0.0298       0.0294     0.000195     0.000242          1.1         1.89       0.0847        0.154        0.108        0.172
    125   700       0.0148       0.0141     0.000311     0.000365        0.569         1.31       0.0728        0.195        0.143        0.211
    125   800      0.00231      0.00188     5.09e-05     0.000382        0.316        0.479       0.0543       0.0788        0.176        0.216
    125   900       0.0208       0.0204     9.09e-05     0.000303        0.801         1.58        0.069        0.105        0.183        0.192
    125  1000       0.0596       0.0595     7.56e-05     3.34e-05          1.2         2.69       0.0668       0.0961       0.0502       0.0639
    125  1100        0.021       0.0202     9.74e-05     0.000744        0.905         1.57       0.0714        0.109        0.243        0.301
    125  1200      0.00363      0.00337     5.24e-05     0.000203         0.47        0.642       0.0463         0.08        0.133        0.157
    125  1300       0.0341       0.0335     9.66e-05     0.000522        0.807         2.02       0.0648        0.109        0.185        0.252
    125  1400       0.0173       0.0171     0.000143     0.000103        0.978         1.44        0.088        0.132       0.0961        0.112
    125  1500      0.00361      0.00331     0.000152     0.000144        0.458        0.636       0.0846        0.136        0.103        0.133
    125  1600       0.0943       0.0939     9.41e-05     0.000313         1.63         3.39       0.0661        0.107        0.157        0.196
    125  1700       0.0595       0.0594     4.86e-05     3.34e-05         1.39         2.69       0.0557        0.077       0.0545       0.0638
    125  1800       0.0367       0.0364     6.64e-05     0.000242         1.13         2.11       0.0652         0.09        0.131        0.172
    125  1900       0.0044      0.00277     0.000709      0.00092        0.422        0.582        0.104        0.294        0.275        0.335
    125  2000        0.035       0.0345     6.72e-05     0.000497        0.833         2.05       0.0555       0.0906        0.204        0.246
    125  2039       0.0127       0.0126     7.75e-05     9.03e-05        0.694         1.24       0.0578       0.0972       0.0962        0.105

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    125   100      0.00386      0.00328     8.68e-05     0.000492        0.436        0.633       0.0627        0.103        0.189        0.245
    125   182        0.132        0.131      0.00019      9.7e-05         2.64            4       0.0685        0.152        0.109        0.109


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             125 12384.032    0.001        0.023     0.000132     0.000554       0.0237        0.799         1.67       0.0715        0.127        0.198         0.26
! Validation        125 12384.032    0.001       0.0226     9.73e-05     0.000417       0.0231        0.789         1.64       0.0633        0.109        0.174        0.226
Wall time: 12384.032730296254
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    126   100      0.00202      0.00171     7.63e-05     0.000234        0.307        0.457       0.0678       0.0965        0.145        0.169
    126   200       0.0293       0.0286     0.000557     9.46e-05        0.861         1.87       0.0949        0.261        0.106        0.107
    126   300       0.0347       0.0314      7.5e-05      0.00315        0.807         1.96       0.0633       0.0957        0.514         0.62
    126   400      0.00231      0.00203     0.000107     0.000176        0.318        0.498       0.0659        0.114        0.118        0.147
    126   500       0.0416       0.0414     0.000133     0.000151         1.23         2.25       0.0742        0.127        0.112        0.136
    126   600       0.0164       0.0158     5.44e-05     0.000561        0.706         1.39       0.0589       0.0815        0.171        0.262
    126   700       0.0645       0.0641     0.000123     0.000269         1.51          2.8       0.0702        0.122        0.166        0.181
    126   800      0.00427      0.00379     4.48e-05     0.000433        0.427         0.68       0.0478        0.074        0.228         0.23
    126   900      0.00335      0.00295     8.78e-05     0.000304        0.436        0.601       0.0578        0.104        0.164        0.193
    126  1000      0.00588      0.00573     3.23e-05     0.000115        0.494        0.836       0.0457       0.0628        0.117        0.118
    126  1100        0.015       0.0146     8.19e-05     0.000254        0.698         1.34       0.0619          0.1        0.172        0.176
    126  1200      0.00455      0.00422      7.1e-05     0.000258        0.444        0.718       0.0607       0.0931        0.166        0.177
    126  1300      0.00621      0.00589     0.000181     0.000135        0.619        0.848       0.0832        0.148        0.113        0.128
    126  1400      0.00406      0.00363     0.000128     0.000299        0.428        0.666       0.0809        0.125        0.189        0.191
    126  1500        0.159        0.158     0.000136     0.000471         1.96         4.39       0.0815        0.129        0.187         0.24
    126  1600      0.00265      0.00179     0.000221     0.000641        0.378        0.467       0.0791        0.164        0.248         0.28
    126  1700      0.00233      0.00219     5.43e-05     8.31e-05         0.32        0.517       0.0562       0.0814       0.0859        0.101
    126  1800      0.00536      0.00469     7.49e-05     0.000596         0.43        0.757       0.0664       0.0956        0.214         0.27
    126  1900      0.00211      0.00164      5.2e-05     0.000414        0.366        0.447       0.0572       0.0796        0.176        0.225
    126  2000       0.0372        0.037     7.84e-05     0.000147          1.1         2.13        0.067       0.0978       0.0985        0.134
    126  2039       0.0991       0.0971     7.47e-05      0.00202         1.98         3.44       0.0675       0.0955        0.374        0.497

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    126   100      0.00488      0.00469     9.63e-05     8.87e-05        0.459        0.757       0.0683        0.108       0.0868        0.104
    126   182        0.111         0.11      5.9e-05     0.000128          2.3         3.67       0.0525       0.0849        0.125        0.125


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             126 12482.893    0.001       0.0227     0.000134     0.000505       0.0234        0.795         1.67       0.0718        0.128        0.191        0.248
! Validation        126 12482.893    0.001       0.0212     0.000122      0.00033       0.0217        0.768         1.59         0.07        0.122        0.157        0.201
Wall time: 12482.893812783062
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    127   100       0.0633       0.0619     0.000131      0.00122         1.54         2.75       0.0793        0.126        0.367        0.386
    127   200       0.0366       0.0362     6.18e-05     0.000307         1.25          2.1        0.059       0.0869        0.168        0.194
    127   300        0.017       0.0162     0.000274     0.000579        0.873         1.41       0.0946        0.183        0.246        0.266
    127   400       0.0239       0.0229      0.00011     0.000968        0.934         1.67       0.0791        0.116        0.309        0.344
    127   500       0.0101      0.00925     0.000111     0.000725        0.648         1.06       0.0794        0.116         0.26        0.298
    127   600       0.0239       0.0233     0.000203     0.000401         0.95         1.69       0.0768        0.158        0.187        0.221
    127   700       0.0465       0.0454     0.000502       0.0006         1.36         2.35        0.122        0.247        0.251        0.271
    127   800       0.0056      0.00374     0.000446      0.00142        0.495        0.675        0.103        0.233        0.384        0.417
    127   900      0.00238      0.00197     7.36e-05     0.000337        0.319         0.49       0.0596       0.0948        0.163        0.203
    127  1000       0.0283       0.0281     8.52e-05     0.000112        0.827         1.85       0.0694        0.102        0.106        0.117
    127  1100      0.00364      0.00339     9.06e-05     0.000155        0.403        0.643        0.072        0.105        0.134        0.138
    127  1200        0.118        0.118     9.82e-05     0.000438         1.77         3.79        0.066        0.109        0.155        0.231
    127  1300       0.0251       0.0247     8.03e-05     0.000316        0.893         1.74       0.0675        0.099        0.136        0.197
    127  1400      0.00596      0.00568     7.44e-05     0.000204        0.529        0.833       0.0614       0.0953        0.138        0.158
    127  1500       0.0259       0.0254     5.69e-05     0.000409        0.862         1.76       0.0517       0.0834        0.192        0.223
    127  1600       0.0023      0.00137     3.37e-05     0.000901        0.295        0.409       0.0477       0.0642        0.317        0.332
    127  1700      0.00137     0.000862     4.12e-05     0.000467        0.235        0.324       0.0485       0.0709         0.23        0.239
    127  1800       0.0485       0.0481     7.06e-05     0.000323         1.26         2.42       0.0608       0.0929        0.155        0.199
    127  1900       0.0376       0.0363      0.00013      0.00118         1.18         2.11       0.0752        0.126        0.358        0.379
    127  2000       0.0363        0.035      0.00012      0.00119         1.04         2.07       0.0777        0.121        0.361        0.382
    127  2039      0.00657      0.00594     0.000156     0.000482        0.557        0.851       0.0986        0.138        0.185        0.242

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    127   100      0.00543      0.00502     0.000118     0.000294        0.493        0.783       0.0736         0.12        0.185        0.189
    127   182        0.147        0.145     0.000151      0.00144         2.63         4.21       0.0761        0.136        0.419        0.419


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             127 12581.692    0.001       0.0227      0.00013     0.000488       0.0233        0.792         1.67        0.071        0.126        0.189        0.244
! Validation        127 12581.692    0.001       0.0211      0.00012     0.000413       0.0216        0.784         1.58       0.0762        0.121         0.18        0.223
Wall time: 12581.693495631218
! Best model      127    0.022
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    128   100       0.0142        0.014     0.000153     4.61e-05        0.793         1.31       0.0916        0.137       0.0574        0.075
    128   200      0.00259      0.00241     5.54e-05     0.000122        0.357        0.543       0.0534       0.0822        0.118        0.122
    128   300       0.0408       0.0403     0.000157     0.000376         1.11         2.22       0.0906        0.138        0.171        0.214
    128   400       0.0109       0.0104     5.92e-05     0.000398        0.618         1.13       0.0577        0.085        0.179         0.22
    128   500       0.0223       0.0215     0.000129     0.000631         1.05         1.62       0.0866        0.125        0.244        0.278
    128   600       0.0126       0.0123     0.000128     0.000224        0.756         1.22        0.083        0.125        0.158        0.165
    128   700      0.00661      0.00643     9.43e-05     8.49e-05        0.549        0.886       0.0634        0.107       0.0987        0.102
    128   800       0.0221       0.0217     5.83e-05     0.000356        0.908         1.63       0.0608       0.0843        0.181        0.208
    128   900      0.00213      0.00156     8.86e-05     0.000486        0.321        0.436       0.0669        0.104        0.217        0.244
    128  1000       0.0278       0.0265     0.000116      0.00117         1.07          1.8       0.0781        0.119        0.332        0.378
    128  1100       0.0403       0.0392     0.000136      0.00102         1.08         2.19       0.0812        0.129        0.332        0.352
    128  1200      0.00774      0.00697     0.000104      0.00066        0.639        0.923       0.0687        0.113        0.219        0.284
    128  1300       0.0719       0.0716     7.89e-05     0.000171         1.55         2.96       0.0631       0.0981        0.138        0.144
    128  1400      0.00329      0.00288     7.01e-05     0.000343        0.376        0.592       0.0594       0.0925        0.176        0.205
    128  1500      0.00351      0.00333     6.16e-05      0.00012         0.44        0.638       0.0614       0.0867        0.116        0.121
    128  1600      0.00523      0.00507     8.53e-05     7.44e-05        0.469        0.786       0.0589        0.102       0.0834       0.0953
    128  1700      0.00489      0.00448     5.35e-05     0.000354        0.479         0.74       0.0525       0.0808        0.201        0.208
    128  1800       0.0116       0.0114     0.000105     0.000147        0.635         1.18       0.0622        0.113         0.12        0.134
    128  1900      0.00531      0.00492     7.89e-05     0.000314         0.44        0.775        0.064       0.0982        0.145        0.196
    128  2000        0.012       0.0116     3.43e-05     0.000371        0.632         1.19       0.0419       0.0647         0.19        0.213
    128  2039       0.0746        0.074     0.000122     0.000499         1.59         3.01       0.0725        0.122        0.246        0.247

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    128   100      0.00611      0.00568     8.63e-05     0.000352        0.501        0.832       0.0632        0.103        0.174        0.207
    128   182        0.111        0.111     5.85e-05     4.09e-05         2.29         3.69       0.0501       0.0845       0.0707       0.0707


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             128 12680.634    0.001       0.0226     0.000128     0.000542       0.0233        0.795         1.66       0.0709        0.125        0.197        0.257
! Validation        128 12680.634    0.001       0.0214     0.000102     0.000449       0.0219        0.756          1.6       0.0642        0.112        0.181        0.235
Wall time: 12680.634965009987
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    129   100       0.0151       0.0148     0.000203     0.000102        0.736         1.34       0.0926        0.157       0.0986        0.112
    129   200      0.00446      0.00398     6.78e-05     0.000413        0.499        0.697       0.0606        0.091        0.206        0.224
    129   300      0.00704      0.00653     9.11e-05     0.000418        0.571        0.893       0.0695        0.105        0.183        0.226
    129   400       0.0465       0.0447     9.77e-05      0.00166          1.3         2.34       0.0688        0.109        0.369         0.45
    129   500      0.00704      0.00669     0.000107     0.000244        0.546        0.904       0.0691        0.114        0.155        0.173
    129   600      0.00378      0.00285     0.000138     0.000784        0.441         0.59       0.0867         0.13        0.291        0.309
    129   700      0.00334      0.00297     9.91e-05     0.000268        0.381        0.602       0.0641         0.11        0.156        0.181
    129   800       0.0114       0.0113     7.17e-05     2.99e-05        0.557         1.17       0.0637       0.0936        0.057       0.0604
    129   900      0.00316      0.00263     8.75e-05     0.000445        0.392        0.566       0.0644        0.103        0.199        0.233
    129  1000        0.025       0.0248     6.56e-05     0.000116        0.845         1.74       0.0528       0.0895        0.108        0.119
    129  1100      0.00635      0.00601     8.85e-05     0.000255        0.523        0.856       0.0709        0.104        0.125        0.176
    129  1200       0.0296       0.0294     7.65e-05     0.000128        0.893         1.89       0.0602       0.0967        0.103        0.125
    129  1300      0.00362      0.00332     0.000128     0.000172        0.472        0.637       0.0723        0.125        0.132        0.145
    129  1400       0.0426       0.0422     0.000101     0.000301          1.4         2.27       0.0691        0.111        0.119        0.192
    129  1500        0.039       0.0373     8.67e-05      0.00164         1.07         2.13        0.061        0.103        0.385        0.448
    129  1600       0.0523       0.0519     7.93e-05     0.000413         1.14         2.52       0.0659       0.0984        0.216        0.224
    129  1700       0.0373       0.0366     0.000198     0.000482         1.08         2.11       0.0907        0.155        0.153        0.242
    129  1800      0.00355      0.00306      9.8e-05     0.000392         0.44        0.611        0.065        0.109        0.181        0.219
    129  1900       0.0394       0.0389     9.03e-05     0.000396         1.13         2.18        0.071        0.105        0.192         0.22
    129  2000       0.0317       0.0308     6.71e-05     0.000835         1.03         1.94       0.0669       0.0905        0.298        0.319
    129  2039        0.022       0.0212     8.03e-05     0.000716         0.92         1.61       0.0584        0.099        0.295        0.296

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    129   100       0.0054      0.00475     6.09e-05     0.000592        0.496        0.761       0.0527       0.0862        0.223        0.269
    129   182        0.151        0.151      2.7e-05     4.91e-05         2.56         4.29       0.0407       0.0574       0.0774       0.0774


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             129 12779.535    0.001       0.0224     0.000129     0.000524       0.0231        0.791         1.65       0.0703        0.125        0.195        0.253
! Validation        129 12779.535    0.001       0.0221     7.56e-05     0.000462       0.0227        0.754         1.62       0.0565       0.0962        0.187        0.238
Wall time: 12779.535832829773
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    130   100       0.0253       0.0242     0.000544     0.000517        0.743         1.72       0.0864        0.258        0.217        0.251
    130   200      0.00556      0.00512     5.13e-05     0.000388        0.454        0.791       0.0545       0.0791        0.189        0.218
    130   300       0.0324       0.0321     0.000108     0.000241        0.844         1.98         0.07        0.115        0.162        0.172
    130   400       0.0328         0.03      0.00201     0.000802         1.15         1.91        0.148        0.495        0.272        0.313
    130   500       0.0587       0.0583     0.000134     0.000263         1.29         2.67       0.0769        0.128        0.115        0.179
    130   600       0.0139       0.0136      9.9e-05     0.000224        0.719         1.29       0.0668         0.11        0.145        0.165
    130   700       0.0178       0.0176     5.99e-05     0.000132         0.75         1.47       0.0566       0.0855        0.106        0.127
    130   800      0.00294      0.00238     6.52e-05     0.000498        0.385        0.539       0.0546       0.0892        0.216        0.246
    130   900      0.00585      0.00526     0.000166     0.000432        0.433        0.801       0.0776        0.142        0.183         0.23
    130  1000        0.122        0.122     0.000123     5.74e-05         1.54         3.86       0.0684        0.123       0.0687       0.0837
    130  1100       0.0105      0.00945     0.000134     0.000959        0.572         1.07       0.0845        0.128        0.296        0.342
    130  1200       0.0171       0.0164     8.04e-05     0.000627         0.84         1.42       0.0687       0.0991        0.228        0.277
    130  1300      0.00193      0.00116     7.97e-05     0.000694        0.296        0.376       0.0664       0.0986        0.261        0.291
    130  1400       0.0214       0.0203     4.66e-05      0.00109        0.704         1.57       0.0533       0.0754        0.252        0.364
    130  1500       0.0279        0.027     0.000119      0.00073        0.773         1.82       0.0784        0.121        0.284        0.298
    130  1600       0.0429       0.0421     9.94e-05     0.000669         1.22         2.27       0.0703         0.11        0.233        0.286
    130  1700       0.0464       0.0451     0.000104      0.00121         1.17         2.35       0.0704        0.113        0.325        0.384
    130  1800      0.00201      0.00136     8.61e-05     0.000567        0.305        0.407       0.0655        0.103        0.224        0.263
    130  1900       0.0186       0.0181     8.56e-05     0.000462        0.897         1.49       0.0691        0.102         0.18        0.237
    130  2000       0.0056      0.00502     5.87e-05     0.000522        0.463        0.783        0.055       0.0847        0.215        0.252
    130  2039      0.00763      0.00638     0.000105      0.00115        0.533        0.882       0.0714        0.113        0.353        0.375

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    130   100      0.00402      0.00356     7.97e-05      0.00038        0.419         0.66       0.0598       0.0986        0.178        0.215
    130   182        0.116        0.115     3.41e-05     0.000475         2.27         3.75       0.0472       0.0645        0.241        0.241


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             130 12878.352    0.001       0.0222     0.000131     0.000503       0.0229        0.785         1.65       0.0706        0.127        0.192        0.248
! Validation        130 12878.352    0.001       0.0216     8.98e-05      0.00072       0.0224        0.758         1.61       0.0619        0.105        0.228        0.297
Wall time: 12878.35284935683
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    131   100       0.0485       0.0482     0.000141     0.000212         1.41         2.43       0.0921        0.131         0.14        0.161
    131   200      0.00282       0.0027     8.12e-05     3.25e-05        0.369        0.574       0.0655       0.0995       0.0613        0.063
    131   300       0.0244        0.024     7.15e-05     0.000351        0.874         1.71       0.0623       0.0934        0.175        0.207
    131   400       0.0226       0.0222     8.58e-05     0.000305        0.738         1.65       0.0533        0.102        0.167        0.193
    131   500      0.00443      0.00385     5.21e-05     0.000529         0.43        0.685       0.0559       0.0797        0.211        0.254
    131   600       0.0956       0.0942     0.000822     0.000624         1.82         3.39        0.115        0.317        0.253        0.276
    131   700       0.0224       0.0219     0.000228     0.000273        0.838         1.64        0.072        0.167        0.154        0.183
    131   800       0.0177       0.0172     7.68e-05     0.000364        0.692         1.45       0.0559       0.0968        0.191        0.211
    131   900      0.00871      0.00838     0.000139     0.000198        0.618         1.01         0.08         0.13        0.152        0.156
    131  1000      0.00389      0.00269     5.01e-05      0.00115        0.304        0.573       0.0549       0.0782        0.327        0.375
    131  1100      0.00456      0.00388      0.00011     0.000571        0.545        0.688       0.0724        0.116        0.184        0.264
    131  1200      0.00545      0.00485     0.000448      0.00015        0.547        0.769       0.0749        0.234        0.114        0.135
    131  1300       0.0498       0.0491     5.02e-05     0.000701        0.948         2.45       0.0481       0.0783        0.225        0.293
    131  1400       0.0476       0.0474     8.81e-05     0.000116         1.05         2.41       0.0608        0.104        0.116        0.119
    131  1500      0.00675      0.00655     0.000109     9.84e-05        0.469        0.894       0.0683        0.115       0.0916         0.11
    131  1600       0.0155       0.0147     9.79e-05     0.000692        0.614         1.34       0.0688        0.109        0.224        0.291
    131  1700        0.014       0.0131     0.000126     0.000762        0.861         1.26       0.0865        0.124        0.209        0.305
    131  1800       0.0276       0.0272     0.000134      0.00027         1.02         1.82       0.0807        0.128        0.164        0.182
    131  1900       0.0356       0.0338     0.000247       0.0015         1.12         2.03       0.0893        0.173        0.226        0.428
    131  2000      0.00352      0.00264     7.68e-05     0.000798         0.45        0.568       0.0615       0.0969         0.25        0.312
    131  2039       0.0243       0.0226      0.00048      0.00123         1.06         1.66        0.132        0.242        0.307        0.387

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    131   100      0.00498      0.00467     0.000108     0.000203        0.519        0.755       0.0717        0.115        0.149        0.157
    131   182        0.137        0.136     6.56e-05     0.000164         2.46         4.08       0.0558       0.0895        0.142        0.142


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             131 12977.287    0.001       0.0224      0.00013     0.000531       0.0231        0.786         1.66       0.0698        0.126        0.195        0.255
! Validation        131 12977.287    0.001       0.0211     0.000131     0.000312       0.0215        0.761         1.58       0.0745        0.127        0.154        0.195
Wall time: 12977.288466155529
! Best model      131    0.021
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    132   100      0.00757      0.00698     9.27e-05       0.0005        0.602        0.923       0.0647        0.106        0.233        0.247
    132   200       0.0337       0.0317     0.000392      0.00166         1.23         1.97       0.0946        0.219        0.394        0.451
    132   300      0.00664      0.00627     7.98e-05     0.000287        0.474        0.875       0.0648       0.0987        0.136        0.187
    132   400      0.00483      0.00449     0.000107     0.000227        0.455        0.741         0.07        0.115        0.147        0.166
    132   500      0.00675       0.0062     0.000244     0.000311        0.503         0.87       0.0873        0.173        0.177        0.195
    132   600      0.00783      0.00751     0.000119     0.000205         0.58        0.957        0.075         0.12        0.116        0.158
    132   700       0.0122       0.0117     0.000183      0.00034        0.566          1.2       0.0733        0.149        0.168        0.204
    132   800       0.0045      0.00425     0.000179      6.8e-05        0.473        0.721       0.0722        0.148       0.0798       0.0911
    132   900      0.00697      0.00656     8.57e-05     0.000318        0.466        0.895       0.0686        0.102        0.144        0.197
    132  1000       0.0333       0.0326     0.000114     0.000614         1.16         1.99       0.0795        0.118        0.184        0.274
    132  1100       0.0103      0.00952     0.000117      0.00071         0.64         1.08       0.0638        0.119        0.246        0.294
    132  1200      0.00677      0.00495     0.000379      0.00144        0.538        0.777       0.0802        0.215        0.332        0.419
    132  1300       0.0378       0.0366     0.000185      0.00101         1.03         2.11       0.0764         0.15        0.308        0.351
    132  1400       0.0158       0.0152     0.000191     0.000443        0.667         1.36       0.0703        0.153        0.208        0.233
    132  1500       0.0419       0.0415     8.88e-05     0.000289         1.34         2.25       0.0747        0.104        0.166        0.188
    132  1600       0.0269       0.0263     0.000136     0.000433            1         1.79       0.0871        0.129        0.141         0.23
    132  1700      0.00341       0.0029     0.000102     0.000411        0.435        0.595       0.0676        0.112        0.184        0.224
    132  1800      0.00479      0.00359     8.03e-05      0.00112        0.425        0.662       0.0658        0.099        0.308         0.37
    132  1900       0.0236       0.0229      0.00011     0.000569        0.691         1.67       0.0656        0.116        0.215        0.263
    132  2000       0.0257       0.0249     5.33e-05     0.000731        0.749         1.74       0.0538       0.0807         0.28        0.299
    132  2039       0.0664       0.0649     9.85e-05      0.00137         1.39         2.82       0.0723         0.11        0.354        0.409

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    132   100      0.00602      0.00502     7.19e-05     0.000932        0.508        0.783       0.0608       0.0937        0.227        0.337
    132   182        0.128        0.127     6.38e-05     0.000755         2.42         3.93       0.0544       0.0883        0.303        0.303


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             132 13076.206    0.001       0.0225      0.00013     0.000549       0.0232        0.788         1.66       0.0702        0.126        0.199        0.259
! Validation        132 13076.206    0.001       0.0204     0.000103     0.000726       0.0213        0.747         1.56       0.0667        0.112        0.244        0.298
Wall time: 13076.207341015339
! Best model      132    0.021
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    133   100       0.0123       0.0122     4.96e-05     1.28e-05        0.602         1.22       0.0497       0.0778       0.0293       0.0396
    133   200       0.0081      0.00504     4.65e-05      0.00301        0.435        0.785       0.0451       0.0753        0.427        0.606
    133   300       0.0156       0.0153     0.000152     9.01e-05        0.809         1.37       0.0761        0.136       0.0897        0.105
    133   400       0.0451       0.0449     0.000136     6.41e-05         1.25         2.34       0.0692        0.129       0.0712       0.0885
    133   500      0.00837      0.00746     0.000171     0.000736        0.531        0.955       0.0957        0.145        0.256          0.3
    133   600       0.0169       0.0161     7.86e-05     0.000758        0.794          1.4       0.0641        0.098        0.248        0.304
    133   700      0.00233      0.00184      3.1e-05     0.000453        0.328        0.475       0.0452       0.0615        0.201        0.235
    133   800       0.0293       0.0286     4.59e-05     0.000615        0.693         1.87       0.0545       0.0749        0.214        0.274
    133   900       0.0172       0.0153     7.71e-05      0.00189        0.703         1.37       0.0584        0.097        0.432        0.481
    133  1000       0.0827       0.0823     7.29e-05      0.00032         1.27         3.17       0.0656       0.0944        0.168        0.198
    133  1100      0.00725      0.00681     8.02e-05     0.000363        0.535        0.912       0.0616        0.099         0.15        0.211
    133  1200      0.00549      0.00495     6.37e-05     0.000479        0.524        0.777       0.0612       0.0882        0.185        0.242
    133  1300      0.00182      0.00133     7.55e-05     0.000407        0.271        0.404        0.065        0.096        0.179        0.223
    133  1400      0.00289      0.00261      6.9e-05     0.000213        0.359        0.565        0.059       0.0918        0.118        0.161
    133  1500       0.0328       0.0306     0.000233      0.00201         1.09         1.93       0.0807        0.169        0.439        0.495
    133  1600       0.0347        0.034     0.000103     0.000609         0.97         2.04       0.0696        0.112        0.233        0.273
    133  1700       0.0364        0.035     8.94e-05      0.00132         1.08         2.07       0.0737        0.104        0.356        0.401
    133  1800      0.00643      0.00595     7.13e-05     0.000403        0.507        0.852       0.0654       0.0933        0.214        0.222
    133  1900       0.0186       0.0181     9.76e-05     0.000431        0.807         1.49       0.0717        0.109        0.189        0.229
    133  2000       0.0295       0.0292     0.000139     0.000129        0.984         1.89       0.0751         0.13        0.109        0.126
    133  2039      0.00784      0.00771     7.59e-05     5.61e-05        0.561         0.97       0.0654       0.0963         0.06       0.0827

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    133   100      0.00849      0.00809     0.000176     0.000221        0.645        0.994       0.0817        0.147        0.132        0.164
    133   182         0.11        0.109     5.06e-05     2.23e-07         2.26         3.66       0.0593       0.0786      0.00522      0.00522


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             133 13175.119    0.001       0.0222     0.000131     0.000525       0.0228        0.783         1.65       0.0706        0.127        0.195        0.253
! Validation        133 13175.119    0.001       0.0209     0.000143     0.000301       0.0213        0.786         1.58       0.0774        0.132        0.152        0.192
Wall time: 13175.119999334216
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    134   100     0.000889      0.00075     6.44e-05     7.49e-05        0.244        0.303       0.0626       0.0887       0.0943       0.0956
    134   200      0.00895       0.0084     9.64e-05     0.000458        0.673         1.01       0.0675        0.109        0.197        0.236
    134   300       0.0826       0.0816     6.28e-05     0.000882          1.2         3.16       0.0544       0.0876        0.184        0.328
    134   400       0.0158       0.0155     9.66e-05     0.000161        0.738         1.38       0.0713        0.109        0.108         0.14
    134   500       0.0937        0.093     7.34e-05     0.000681         1.38         3.37        0.064       0.0947        0.198        0.288
    134   600        0.023       0.0226     8.42e-05     0.000388         1.02         1.66       0.0638        0.101        0.203        0.218
    134   700      0.00634      0.00614     7.93e-05     0.000118        0.618        0.866       0.0696       0.0984       0.0932         0.12
    134   800       0.0294       0.0283     8.02e-05      0.00103        0.867         1.86       0.0686       0.0989        0.302        0.355
    134   900      0.00908      0.00855     4.19e-05     0.000489        0.511         1.02       0.0507       0.0716          0.2        0.244
    134  1000        0.125        0.125     8.09e-05       0.0002         1.43          3.9       0.0679       0.0994         0.13        0.156
    134  1100      0.00389      0.00365      5.7e-05      0.00018        0.418        0.668       0.0542       0.0834        0.126        0.148
    134  1200      0.00114     0.000849      3.5e-05     0.000253        0.239        0.322       0.0473       0.0654        0.151        0.176
    134  1300      0.00179      0.00121     8.27e-05     0.000502          0.3        0.384       0.0663          0.1        0.223        0.248
    134  1400      0.00704      0.00684     8.08e-05      0.00012        0.555        0.914       0.0664       0.0993        0.117        0.121
    134  1500       0.0143       0.0134     7.76e-05     0.000858        0.705         1.28       0.0599       0.0973         0.28        0.324
    134  1600      0.00764      0.00704     0.000256     0.000343        0.584        0.927       0.0899        0.177        0.189        0.205
    134  1700       0.0226       0.0221      9.9e-05     0.000346        0.788         1.64       0.0706         0.11        0.188        0.206
    134  1800      0.00313      0.00288      6.9e-05      0.00018        0.434        0.593       0.0667       0.0918        0.143        0.148
    134  1900       0.0134       0.0106      0.00049      0.00233        0.778         1.14        0.102        0.245        0.322        0.533
    134  2000       0.0184       0.0174     6.77e-05     0.000964        0.806         1.46        0.059       0.0909         0.27        0.343
    134  2039       0.0351       0.0344     8.89e-05     0.000534         1.03         2.05       0.0723        0.104        0.209        0.255

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    134   100       0.0071        0.006     9.01e-05      0.00101        0.488        0.856       0.0686        0.105        0.291        0.351
    134   182       0.0881       0.0876     0.000195     0.000261         2.17         3.27       0.0717        0.154        0.178        0.178


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             134 13274.066    0.001       0.0221     0.000129     0.000497       0.0228        0.786         1.64       0.0707        0.126        0.191        0.246
! Validation        134 13274.066    0.001       0.0211     0.000141     0.000584       0.0219        0.778          1.6       0.0739        0.131        0.207        0.267
Wall time: 13274.06688477844
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    135   100      0.00318       0.0026     9.82e-05     0.000476         0.43        0.564       0.0709        0.109        0.211        0.241
    135   200       0.0373       0.0367      0.00014     0.000514         1.28         2.12       0.0859        0.131        0.216         0.25
    135   300      0.00207      0.00164     6.63e-05     0.000368        0.286        0.447       0.0521         0.09        0.161        0.212
    135   400      0.00487       0.0042     0.000108     0.000564        0.518        0.716       0.0785        0.115        0.234        0.262
    135   500       0.0462       0.0457     9.15e-05     0.000442         1.05         2.36        0.067        0.106        0.182        0.232
    135   600      0.00413      0.00306     0.000594     0.000476         0.47        0.611        0.094        0.269        0.175        0.241
    135   700      0.00633      0.00588     0.000208     0.000236        0.509        0.848       0.0807        0.159        0.151         0.17
    135   800      0.00924      0.00654     0.000895       0.0018         0.64        0.894        0.102         0.33        0.459        0.469
    135   900       0.0296       0.0293     0.000137     0.000254         1.18         1.89       0.0868        0.129        0.163        0.176
    135  1000       0.0158       0.0145      0.00036     0.000946        0.746         1.33       0.0864        0.209        0.265         0.34
    135  1100        0.016       0.0156     0.000133     0.000231        0.677         1.38       0.0793        0.128        0.133        0.168
    135  1200      0.00801      0.00757     3.08e-05     0.000412         0.65        0.961       0.0456       0.0613        0.221        0.224
    135  1300       0.0136       0.0129     8.03e-05     0.000625         0.69         1.26       0.0699        0.099        0.231        0.276
    135  1400      0.00538      0.00496     9.39e-05     0.000333        0.425        0.778       0.0646        0.107         0.15        0.202
    135  1500       0.0249       0.0242     5.06e-05      0.00069        0.796         1.72       0.0564       0.0786        0.204         0.29
    135  1600       0.0485       0.0479     0.000204     0.000421         1.29         2.42       0.0816        0.158         0.17        0.227
    135  1700       0.0885       0.0877      6.6e-05     0.000745         1.53         3.27       0.0597       0.0898        0.277        0.302
    135  1800        0.102        0.101     0.000168      0.00052         1.52         3.52       0.0968        0.143        0.233        0.252
    135  1900      0.00771      0.00737     0.000131     0.000206        0.639        0.949       0.0847        0.126        0.141        0.159
    135  2000       0.0118       0.0113     6.41e-05     0.000417        0.751         1.18        0.059       0.0885        0.184        0.226
    135  2039       0.0295       0.0294      8.8e-05     3.94e-05        0.973         1.89       0.0717        0.104       0.0541       0.0694

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    135   100      0.00664      0.00633     0.000123     0.000193        0.549        0.879       0.0757        0.122         0.13        0.154
    135   182        0.145        0.144     7.47e-05     0.000455         2.54         4.19        0.054       0.0955        0.236        0.236


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             135 13372.881    0.001       0.0218     0.000132     0.000511       0.0225         0.78         1.63       0.0705        0.127        0.193         0.25
! Validation        135 13372.881    0.001        0.021     0.000129     0.000414       0.0216        0.769         1.58       0.0747        0.126        0.168        0.225
Wall time: 13372.882109507918
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    136   100       0.0471       0.0467     0.000103     0.000341         1.11         2.39       0.0753        0.112        0.146        0.204
    136   200       0.0276        0.027     0.000198     0.000396        0.865         1.82       0.0937        0.155        0.153         0.22
    136   300        0.023       0.0216     7.24e-05      0.00138        0.911         1.62       0.0597        0.094        0.402        0.411
    136   400       0.0175       0.0164     0.000105     0.000955        0.759         1.42       0.0765        0.113        0.312        0.341
    136   500       0.0314        0.031     8.34e-05     0.000272        0.879         1.95       0.0668        0.101         0.15        0.182
    136   600       0.0113       0.0101      6.6e-05       0.0012        0.706         1.11       0.0563       0.0898         0.26        0.382
    136   700      0.00171      0.00143     9.71e-05     0.000183        0.285        0.418       0.0697        0.109        0.127        0.149
    136   800       0.0352       0.0346     0.000118     0.000499        0.957         2.05       0.0742         0.12        0.174        0.247
    136   900      0.00936      0.00882     5.04e-05     0.000485        0.549         1.04       0.0483       0.0785        0.216        0.243
    136  1000      0.00737      0.00715      0.00018     4.93e-05        0.583        0.934       0.0942        0.148        0.067       0.0776
    136  1100      0.00777      0.00745     5.06e-05     0.000261        0.606        0.954       0.0579       0.0786        0.156        0.178
    136  1200      0.00292      0.00271     5.76e-05     0.000159        0.363        0.575       0.0552       0.0838        0.114        0.139
    136  1300       0.0181        0.017     0.000469     0.000644        0.909         1.44       0.0966        0.239        0.224         0.28
    136  1400        0.031       0.0308     0.000111     0.000148        0.915         1.94       0.0773        0.117        0.124        0.134
    136  1500       0.0328        0.032     0.000212     0.000526         1.24         1.98       0.0975        0.161        0.205        0.253
    136  1600       0.0225       0.0213     0.000525     0.000629         1.01         1.61        0.105        0.253        0.192        0.277
    136  1700      0.00512      0.00493     7.99e-05     0.000105        0.503        0.776       0.0629       0.0988       0.0992        0.113
    136  1800      0.00254      0.00229     9.55e-05     0.000156        0.344        0.528       0.0673        0.108       0.0943        0.138
    136  1900       0.0118      0.00957     7.23e-05      0.00216        0.576         1.08       0.0583       0.0939        0.446        0.513
    136  2000      0.00866      0.00823     0.000181     0.000245        0.605            1       0.0868        0.149        0.157        0.173
    136  2039      0.00471       0.0046     6.36e-05     5.16e-05         0.47        0.749       0.0653       0.0881       0.0619       0.0794

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    136   100       0.0051      0.00454     5.99e-05     0.000495        0.523        0.745       0.0591       0.0855         0.17        0.246
    136   182        0.126        0.126     7.15e-05     3.99e-06         2.36         3.93       0.0623       0.0934       0.0221       0.0221


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             136 13471.776    0.001        0.022      0.00013     0.000481       0.0226        0.785         1.64       0.0711        0.126        0.188        0.242
! Validation        136 13471.776    0.001       0.0204     0.000115     0.000517        0.021        0.742         1.56       0.0689        0.118        0.197        0.252
Wall time: 13471.77757947892
! Best model      136    0.021
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    137   100       0.0082      0.00692     0.000212      0.00108          0.6        0.919        0.102        0.161        0.314        0.362
    137   200       0.0571       0.0556     0.000108      0.00136         1.47         2.61       0.0762        0.115        0.293        0.408
    137   300      0.00874      0.00764     0.000616     0.000485        0.554        0.966       0.0901        0.274        0.191        0.243
    137   400      0.00281      0.00246     6.62e-05      0.00028        0.415        0.548       0.0607       0.0899        0.168        0.185
    137   500       0.0416       0.0407     0.000316     0.000609         1.37         2.23        0.107        0.196        0.268        0.273
    137   600       0.0282       0.0269     7.61e-05       0.0013        0.839         1.81       0.0663       0.0964        0.345        0.399
    137   700      0.00192      0.00126     6.61e-05     0.000594        0.314        0.392       0.0552       0.0898        0.238        0.269
    137   800       0.0177       0.0173     0.000269     0.000155        0.765         1.45       0.0755        0.181         0.12        0.138
    137   900        0.105        0.104     0.000134     0.000611         1.43         3.56       0.0771        0.128        0.234        0.273
    137  1000      0.00561      0.00398     9.91e-05      0.00153        0.485        0.697       0.0668         0.11        0.355        0.433
    137  1100      0.00257      0.00241     7.03e-05      8.9e-05        0.369        0.542       0.0605       0.0926       0.0876        0.104
    137  1200      0.00336      0.00326     6.29e-05     4.12e-05        0.447        0.631       0.0573       0.0876       0.0504       0.0709
    137  1300       0.0201       0.0194     0.000285     0.000467         0.95         1.54       0.0925        0.187        0.218        0.239
    137  1400      0.00721      0.00705     0.000115      4.7e-05        0.567        0.928       0.0623        0.119       0.0655       0.0757
    137  1500      0.00758      0.00733     0.000101     0.000146        0.596        0.946       0.0717        0.111        0.099        0.134
    137  1600       0.0115       0.0108     8.12e-05     0.000536        0.584         1.15       0.0689       0.0996        0.207        0.256
    137  1700      0.00553      0.00503     8.79e-05     0.000416        0.544        0.783       0.0729        0.104        0.198        0.225
    137  1800       0.0055      0.00389     0.000212       0.0014        0.419        0.689       0.0899        0.161        0.312        0.413
    137  1900      0.00402       0.0035     7.25e-05     0.000449         0.38        0.653       0.0563       0.0941        0.215        0.234
    137  2000       0.0105       0.0102     5.87e-05     0.000255        0.632         1.12       0.0587       0.0846        0.145        0.177
    137  2039      0.00126     0.000478     0.000105     0.000676         0.19        0.241       0.0604        0.113        0.222        0.287

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    137   100      0.00813      0.00767     7.63e-05     0.000384        0.613        0.967       0.0641       0.0965        0.169        0.216
    137   182        0.101        0.101     7.88e-05     9.52e-05          2.2         3.51        0.064       0.0981        0.108        0.108


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             137 13570.778    0.001        0.022     0.000131     0.000514       0.0227        0.786         1.64       0.0708        0.127        0.193         0.25
! Validation        137 13570.778    0.001        0.021     0.000121      0.00036       0.0215         0.78         1.59       0.0729        0.122        0.166         0.21
Wall time: 13570.779146365821
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    138   100       0.0145       0.0135     8.96e-05      0.00091          0.7         1.29        0.068        0.105        0.285        0.333
    138   200      0.00755      0.00638      0.00061     0.000563        0.541        0.883        0.089        0.273        0.248        0.262
    138   300       0.0329       0.0325      0.00011     0.000234        0.983         1.99       0.0706        0.116        0.165        0.169
    138   400     0.000861     0.000518      5.4e-05     0.000289        0.184        0.252       0.0524       0.0812        0.181        0.188
    138   500      0.00251      0.00167      6.9e-05     0.000767        0.331        0.452       0.0621       0.0918        0.262        0.306
    138   600      0.00275      0.00234     6.39e-05      0.00035        0.373        0.534       0.0543       0.0883        0.165        0.207
    138   700       0.0116      0.00993     0.000112       0.0016        0.612          1.1       0.0755        0.117        0.375        0.441
    138   800       0.0378       0.0375     0.000148     0.000108          1.2         2.14         0.09        0.134        0.111        0.115
    138   900      0.00592      0.00556     6.88e-05      0.00029        0.499        0.824       0.0625       0.0917        0.161        0.188
    138  1000       0.0245       0.0233     0.000192      0.00101        0.865         1.69       0.0932        0.153        0.288        0.352
    138  1100       0.0248       0.0246     7.07e-05     0.000125        0.903         1.73       0.0615       0.0929          0.1        0.124
    138  1200       0.0209       0.0206     8.86e-05     0.000179        0.891         1.59       0.0702        0.104        0.132        0.148
    138  1300       0.0139       0.0134      0.00019     0.000239        0.848         1.28       0.0856        0.152        0.118        0.171
    138  1400      0.00837      0.00778     8.71e-05     0.000509        0.613        0.974       0.0698        0.103        0.202        0.249
    138  1500       0.0114       0.0107      0.00016     0.000609          0.7         1.14       0.0703         0.14        0.225        0.273
    138  1600      0.00756      0.00731     6.37e-05      0.00019        0.536        0.944       0.0576       0.0882        0.137        0.152
    138  1700        0.143        0.143     0.000137     0.000237         1.91         4.18       0.0715        0.129        0.148         0.17
    138  1800       0.0151       0.0148     4.97e-05     0.000245        0.842         1.34       0.0562       0.0779        0.121        0.173
    138  1900        0.034       0.0334     5.52e-05     0.000559        0.844         2.02       0.0545       0.0821        0.206        0.261
    138  2000       0.0461       0.0457     9.35e-05     0.000304         1.09         2.36       0.0637        0.107        0.176        0.193
    138  2039       0.0976       0.0969     0.000169      0.00051         1.69         3.44       0.0951        0.144        0.217        0.249

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    138   100       0.0106      0.00949     7.67e-05      0.00103        0.576         1.08       0.0667       0.0967        0.271        0.355
    138   182        0.136        0.136     0.000142     0.000374         2.74         4.07       0.0726        0.132        0.214        0.214


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             138 13669.696    0.001       0.0218     0.000129     0.000499       0.0225         0.78         1.63       0.0704        0.126        0.191        0.247
! Validation        138 13669.696    0.001       0.0214     0.000138     0.000341       0.0219        0.787          1.6       0.0767         0.13        0.162        0.204
Wall time: 13669.696629188955
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    139   100       0.0228       0.0226     0.000101      0.00016        0.979         1.66       0.0674        0.111        0.127         0.14
    139   200      0.00361      0.00252     0.000624     0.000468         0.34        0.555       0.0898        0.276        0.161        0.239
    139   300      0.00768      0.00726     6.74e-05     0.000358         0.61        0.941       0.0583       0.0907         0.15        0.209
    139   400       0.0445       0.0439     0.000182     0.000387         1.39         2.32       0.0945        0.149        0.214        0.217
    139   500      0.00544      0.00501     0.000176     0.000257        0.445        0.782       0.0639        0.147        0.154        0.177
    139   600      0.00881      0.00851     6.82e-05     0.000238        0.626         1.02       0.0616       0.0913         0.11        0.171
    139   700       0.0465       0.0459     0.000111      0.00042         1.19         2.37       0.0711        0.117          0.2        0.226
    139   800       0.0292       0.0284     0.000524     0.000315         1.09         1.86       0.0931        0.253         0.18        0.196
    139   900      0.00343      0.00316     0.000118     0.000156        0.391        0.621       0.0741         0.12        0.115        0.138
    139  1000       0.0562       0.0552     8.93e-05     0.000946         1.51          2.6       0.0666        0.104        0.302         0.34
    139  1100      0.00369      0.00302     7.37e-05       0.0006        0.387        0.607       0.0624       0.0949        0.248        0.271
    139  1200       0.0591       0.0581     0.000104     0.000873         1.14         2.66       0.0653        0.113        0.281        0.326
    139  1300       0.0113       0.0101     0.000456     0.000748        0.695         1.11       0.0953        0.236        0.248        0.302
    139  1400       0.0253       0.0251     6.05e-05     0.000215        0.715         1.75       0.0511       0.0859        0.151        0.162
    139  1500       0.0101      0.00957     9.57e-05     0.000421        0.656         1.08       0.0684        0.108        0.153        0.227
    139  1600       0.0131       0.0129     7.03e-05     0.000148        0.769         1.26        0.058       0.0927        0.108        0.135
    139  1700      0.00765      0.00685     8.61e-05     0.000713        0.524        0.915       0.0694        0.103         0.21        0.295
    139  1800       0.0288       0.0284     0.000182     0.000125        0.988         1.86       0.0656        0.149       0.0926        0.124
    139  1900      0.00644      0.00603     0.000111     0.000299        0.492        0.858       0.0729        0.116        0.166        0.191
    139  2000       0.0125       0.0113     0.000373      0.00083          0.8         1.18       0.0918        0.214         0.27        0.318
    139  2039       0.0627       0.0621     0.000536      8.7e-05         1.75         2.75        0.137        0.256       0.0983        0.103

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    139   100      0.00627       0.0057     9.08e-05     0.000486        0.542        0.834       0.0676        0.105         0.21        0.244
    139   182        0.116        0.116     5.75e-05     8.49e-06          2.3         3.77        0.057       0.0838       0.0322       0.0322


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             139 13768.481    0.001       0.0216     0.000131     0.000479       0.0222        0.778         1.62        0.071        0.126        0.186        0.242
! Validation        139 13768.481    0.001       0.0222     0.000129     0.000386       0.0227        0.824         1.63       0.0746        0.126        0.173        0.218
Wall time: 13768.482497513294
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    140   100        0.012       0.0116     5.03e-05     0.000315        0.634         1.19       0.0522       0.0783        0.187        0.196
    140   200       0.0374       0.0367     0.000205     0.000463         1.27         2.12       0.0859        0.158         0.22        0.238
    140   300        0.019       0.0168     0.000397       0.0018        0.811         1.43        0.112         0.22        0.448        0.469
    140   400      0.00288      0.00271     0.000102     6.48e-05        0.341        0.575       0.0706        0.112       0.0845        0.089
    140   500       0.0337       0.0332     0.000132     0.000325         1.13         2.01       0.0805        0.127        0.114        0.199
    140   600      0.00984      0.00945     5.84e-05     0.000331        0.664         1.07       0.0604       0.0844        0.156        0.201
    140   700       0.0141       0.0135     0.000116     0.000459         0.71         1.28       0.0738        0.119        0.183        0.237
    140   800      0.00362       0.0033     0.000101     0.000221        0.436        0.634       0.0629        0.111        0.123        0.164
    140   900      0.00797      0.00776     4.44e-05     0.000162        0.592        0.974       0.0534       0.0736        0.103        0.141
    140  1000      0.00608      0.00547     0.000116     0.000492        0.436        0.817       0.0725        0.119        0.186        0.245
    140  1100       0.0663        0.066     0.000197     0.000121         1.76         2.84          0.1        0.155        0.116        0.121
    140  1200       0.0293        0.029     0.000129     0.000149        0.833         1.88       0.0728        0.125        0.127        0.135
    140  1300       0.0651       0.0649     7.33e-05     0.000112         1.29         2.82       0.0642       0.0946        0.103        0.117
    140  1400       0.0212        0.021     5.92e-05     0.000143        0.894          1.6       0.0522        0.085        0.125        0.132
    140  1500       0.0179       0.0171     0.000124      0.00065        0.882         1.45        0.067        0.123        0.267        0.282
    140  1600      0.00501       0.0047     8.72e-05     0.000224        0.472        0.757       0.0732        0.103         0.11        0.165
    140  1700      0.00273      0.00253     5.58e-05     0.000143        0.322        0.556       0.0509       0.0825        0.129        0.132
    140  1800       0.0339       0.0333     0.000238     0.000336         1.21         2.02       0.0832         0.17        0.151        0.203
    140  1900       0.0133       0.0131       0.0001     7.48e-05        0.684         1.27       0.0657        0.111       0.0866       0.0955
    140  2000       0.0306       0.0299     9.48e-05     0.000588         1.08         1.91       0.0759        0.108        0.203        0.268
    140  2039       0.0025      0.00225      0.00013     0.000125        0.399        0.524       0.0898        0.126        0.107        0.124

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    140   100      0.00441      0.00372     5.82e-05     0.000634        0.384        0.674       0.0574       0.0843         0.21        0.278
    140   182        0.132        0.131     7.49e-05     0.000986         2.48         3.99       0.0559       0.0956        0.347        0.347


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             140 13867.427    0.001       0.0217     0.000129     0.000531       0.0223        0.781         1.63       0.0704        0.125        0.196        0.255
! Validation        140 13867.427    0.001       0.0213     0.000142     0.000523        0.022        0.782          1.6        0.073        0.132        0.204        0.252
Wall time: 13867.42818659544
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    141   100       0.0308       0.0295     0.000109      0.00122        0.906          1.9       0.0735        0.115        0.294        0.385
    141   200       0.0321       0.0317      0.00018     0.000195        0.858         1.97       0.0794        0.148        0.119        0.154
    141   300       0.0227       0.0214     8.83e-05       0.0012        0.933         1.62       0.0642        0.104         0.28        0.382
    141   400       0.0137       0.0132     0.000234     0.000221        0.862         1.27       0.0944        0.169          0.1        0.164
    141   500       0.0353       0.0347      7.8e-05     0.000512         1.06         2.06         0.06       0.0976        0.203         0.25
    141   600        0.035       0.0344     9.16e-05     0.000461         1.01         2.05       0.0643        0.106         0.23        0.237
    141   700        0.151         0.15     5.29e-05     0.000375          2.2         4.28       0.0538       0.0804        0.199        0.214
    141   800      0.00953      0.00863     0.000143     0.000761        0.715         1.03       0.0839        0.132        0.263        0.305
    141   900       0.0167       0.0162     8.15e-05     0.000364        0.623         1.41       0.0582       0.0998        0.123        0.211
    141  1000      0.00946      0.00905     8.89e-05     0.000319        0.552         1.05       0.0603        0.104        0.157        0.197
    141  1100      0.00342      0.00281     3.02e-05     0.000588        0.391        0.585       0.0431       0.0607        0.261        0.268
    141  1200       0.0113       0.0107     0.000131     0.000491        0.686         1.14       0.0685        0.127        0.214        0.245
    141  1300       0.0173       0.0169     0.000134     0.000228        0.882         1.44       0.0852        0.128        0.148        0.167
    141  1400       0.0276       0.0273     8.27e-05     0.000182        0.849         1.83       0.0636        0.101        0.115        0.149
    141  1500       0.0114       0.0111     8.66e-05     0.000196        0.739         1.16       0.0717        0.103        0.137        0.155
    141  1600       0.0447       0.0439       0.0006     0.000236         1.18         2.31         0.11        0.271        0.148         0.17
    141  1700       0.0202       0.0199     5.44e-05     0.000278        0.728         1.56       0.0554       0.0815         0.16        0.184
    141  1800       0.0312       0.0306     6.03e-05     0.000539        0.811         1.93       0.0547       0.0858          0.2        0.257
    141  1900       0.0451       0.0446     0.000121     0.000358         1.13         2.33       0.0756        0.122        0.185        0.209
    141  2000       0.0124       0.0112     0.000108       0.0011        0.772         1.17       0.0752        0.115        0.336        0.366
    141  2039        0.111        0.111     6.76e-05     0.000524         1.64         3.67       0.0543       0.0909        0.224        0.253

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    141   100      0.00368      0.00305     7.05e-05     0.000564        0.389         0.61       0.0596       0.0928        0.243        0.262
    141   182        0.143        0.142     0.000179     0.000524         2.67         4.17       0.0662        0.148        0.253        0.253


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             141 13966.272    0.001       0.0215     0.000129     0.000491       0.0221        0.781         1.62       0.0696        0.126         0.19        0.245
! Validation        141 13966.272    0.001       0.0206     0.000127     0.000524       0.0213        0.751         1.56       0.0684        0.125        0.198        0.253
Wall time: 13966.272461421788
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    142   100       0.0576       0.0571     0.000208     0.000233         1.52         2.64       0.0799        0.159        0.139        0.169
    142   200      0.00312      0.00239      0.00034     0.000392        0.416         0.54       0.0963        0.204        0.202        0.219
    142   300       0.0138        0.013     8.05e-05     0.000678        0.621         1.26       0.0603       0.0991        0.273        0.288
    142   400       0.0104      0.00974     4.77e-05     0.000603        0.551         1.09       0.0479       0.0763        0.218        0.271
    142   500      0.00474      0.00416     0.000143     0.000437        0.417        0.712       0.0753        0.132        0.223        0.231
    142   600      0.00886      0.00777     5.66e-05      0.00103        0.561        0.974       0.0532       0.0831        0.284        0.355
    142   700      0.00801      0.00759     7.74e-05      0.00034         0.53        0.963       0.0605       0.0972        0.125        0.204
    142   800      0.00407      0.00313     9.19e-05     0.000845        0.411        0.618       0.0706        0.106        0.311        0.321
    142   900        0.015       0.0149     5.45e-05     4.44e-05         0.73         1.35       0.0541       0.0816       0.0616       0.0736
    142  1000      0.00854       0.0079      7.5e-05     0.000564        0.682        0.982         0.07       0.0957        0.228        0.262
    142  1100       0.0087      0.00802     0.000151     0.000531        0.555         0.99         0.07        0.136        0.213        0.255
    142  1200      0.00816      0.00683     4.03e-05      0.00129        0.491        0.913       0.0484       0.0702        0.343        0.397
    142  1300      0.00573      0.00482     0.000126     0.000788        0.437        0.767       0.0761        0.124         0.28         0.31
    142  1400       0.0308       0.0298     8.66e-05      0.00089         1.08         1.91       0.0709        0.103        0.291         0.33
    142  1500       0.0258       0.0254     0.000186     0.000214        0.883         1.76       0.0766        0.151        0.143        0.162
    142  1600       0.0033      0.00281     5.51e-05     0.000436        0.432        0.585       0.0591        0.082        0.168        0.231
    142  1700       0.0655       0.0653     0.000205     3.01e-05         1.06         2.82       0.0713        0.158       0.0459       0.0606
    142  1800      0.00527      0.00428     0.000495     0.000494         0.53        0.723       0.0835        0.246        0.236        0.246
    142  1900       0.0225       0.0221     0.000146      0.00023        0.819         1.64       0.0896        0.133         0.15        0.167
    142  2000       0.0126       0.0124     7.22e-05     0.000161        0.688         1.23       0.0591       0.0939         0.12         0.14
    142  2039       0.0242       0.0231     0.000195     0.000852            1         1.68       0.0892        0.154        0.311        0.323

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    142   100      0.00779      0.00624     5.85e-05      0.00149        0.529        0.873       0.0576       0.0845        0.317        0.426
    142   182        0.117        0.117     4.52e-05     0.000105         2.27         3.78       0.0483       0.0742        0.113        0.113


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             142 14065.000    0.001       0.0214     0.000129     0.000485        0.022        0.777         1.62       0.0703        0.126        0.188        0.243
! Validation        142 14065.000    0.001       0.0213     0.000108     0.000578        0.022        0.756          1.6       0.0669        0.115         0.21        0.266
Wall time: 14065.001089692116
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    143   100       0.0272       0.0259     6.26e-05      0.00123        0.801         1.78       0.0579       0.0874         0.33        0.388
    143   200        0.018       0.0171     0.000254     0.000726        0.798         1.44       0.0905        0.176        0.217        0.298
    143   300      0.00916      0.00872     9.54e-05     0.000349        0.639         1.03       0.0731        0.108        0.162        0.206
    143   400       0.0189       0.0185     5.94e-05     0.000296        0.943          1.5       0.0533       0.0852        0.183         0.19
    143   500       0.0567       0.0561     0.000211     0.000344          1.4         2.62       0.0875        0.161        0.183        0.205
    143   600       0.0101      0.00929     0.000467     0.000302        0.642         1.06         0.12        0.239         0.12        0.192
    143   700       0.0413       0.0407     0.000176     0.000481        0.976         2.23       0.0784        0.147        0.198        0.242
    143   800       0.0113       0.0109     0.000104     0.000243        0.701         1.16       0.0684        0.113        0.145        0.172
    143   900        0.108        0.108     9.15e-05     0.000384         1.85         3.62       0.0688        0.106        0.183        0.216
    143  1000       0.0544       0.0539      0.00012     0.000366         1.37         2.57         0.08        0.121        0.208        0.211
    143  1100       0.0553       0.0547     8.04e-05     0.000557         1.28         2.58       0.0715       0.0991        0.219        0.261
    143  1200       0.0501       0.0498     0.000127     8.07e-05         1.13         2.47       0.0791        0.125       0.0979       0.0992
    143  1300       0.0275       0.0271     0.000182     0.000198         1.07         1.82       0.0869        0.149        0.135        0.156
    143  1400       0.0109      0.00849     0.000119      0.00226         0.72         1.02       0.0765        0.121        0.424        0.525
    143  1500       0.0195       0.0192     7.75e-05     0.000206        0.821         1.53       0.0639       0.0973        0.143        0.159
    143  1600       0.0169       0.0164     7.35e-05      0.00042        0.676         1.42       0.0584       0.0947        0.206        0.227
    143  1700      0.00491      0.00414     0.000103     0.000669        0.524        0.711       0.0709        0.112        0.215        0.286
    143  1800      0.00387      0.00362     8.98e-05     0.000161        0.374        0.665       0.0719        0.105        0.124         0.14
    143  1900        0.017       0.0167     0.000104     0.000229        0.854         1.43       0.0726        0.113        0.146        0.167
    143  2000       0.0208       0.0202     0.000373     0.000211        0.827         1.57       0.0823        0.213        0.141         0.16
    143  2039      0.00475      0.00468      4.1e-05     3.22e-05        0.524        0.756       0.0497       0.0708       0.0526       0.0627

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    143   100      0.00404      0.00307     5.16e-05     0.000919        0.419        0.612       0.0512       0.0793        0.249        0.335
    143   182         0.16        0.159      9.5e-05     0.000328         2.78         4.41       0.0571        0.108          0.2          0.2


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             143 14163.762    0.001       0.0213      0.00013     0.000495       0.0219        0.775         1.61       0.0701        0.126        0.191        0.246
! Validation        143 14163.762    0.001       0.0215     0.000106     0.000372        0.022        0.775          1.6       0.0642        0.114        0.164        0.213
Wall time: 14163.763170190156
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    144   100       0.0176       0.0174     8.04e-05     0.000104        0.753         1.46       0.0631       0.0991        0.108        0.113
    144   200      0.00847      0.00813     8.93e-05     0.000244        0.665        0.996       0.0639        0.104        0.157        0.173
    144   300      0.00232      0.00162     0.000114     0.000592         0.33        0.444       0.0646        0.118        0.217        0.269
    144   400       0.0129       0.0123      6.2e-05     0.000494        0.626         1.23       0.0609        0.087        0.233        0.246
    144   500       0.0149        0.014     5.27e-05     0.000805         0.64         1.31       0.0541       0.0802        0.197        0.313
    144   600       0.0298       0.0295      8.9e-05     0.000238         0.91          1.9       0.0674        0.104        0.122         0.17
    144   700      0.00608      0.00583     5.44e-05     0.000196         0.46        0.844       0.0531       0.0815        0.136        0.155
    144   800       0.0279       0.0277     7.96e-05     8.17e-05        0.932         1.84       0.0648       0.0986       0.0837       0.0999
    144   900      0.00417      0.00396     8.88e-05     0.000127        0.496        0.695       0.0681        0.104        0.101        0.125
    144  1000      0.00431       0.0038     6.26e-05     0.000445        0.509        0.681       0.0565       0.0874        0.193        0.233
    144  1100      0.00706      0.00676     6.42e-05     0.000237        0.541        0.908       0.0625       0.0885        0.153         0.17
    144  1200      0.00529      0.00496     0.000136     0.000195        0.624        0.778       0.0835        0.129        0.126        0.154
    144  1300       0.0132       0.0113     8.32e-05      0.00184        0.662         1.18       0.0635        0.101        0.472        0.473
    144  1400       0.0499       0.0496     0.000142     0.000138         1.27         2.46       0.0903        0.132        0.103         0.13
    144  1500        0.004      0.00371     3.05e-05     0.000257        0.326        0.673       0.0418       0.0611         0.13        0.177
    144  1600       0.0401       0.0395     7.36e-05     0.000544        0.907          2.2       0.0617       0.0948        0.188        0.258
    144  1700       0.0314       0.0308      9.2e-05     0.000545        0.812         1.94       0.0705        0.106        0.222        0.258
    144  1800      0.00832       0.0076     5.31e-05     0.000666        0.612        0.963       0.0535       0.0805        0.242        0.285
    144  1900      0.00843      0.00776      0.00058      9.4e-05        0.573        0.973        0.102        0.266       0.0761        0.107
    144  2000       0.0431       0.0422     0.000511     0.000458         1.11         2.27          0.1         0.25        0.203        0.236
    144  2039      0.00117      0.00104     7.84e-05     5.45e-05        0.256        0.356       0.0639       0.0978       0.0595       0.0816

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    144   100       0.0102      0.00945     7.82e-05     0.000707        0.669         1.07        0.065       0.0977        0.239        0.294
    144   182         0.14         0.14     5.29e-05     5.95e-05         2.46         4.14       0.0585       0.0804       0.0852       0.0852


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             144 14262.606    0.001        0.021      0.00013     0.000495       0.0216        0.774          1.6       0.0697        0.126        0.191        0.246
! Validation        144 14262.606    0.001       0.0209     0.000127     0.000396       0.0215        0.772         1.58       0.0727        0.125        0.171         0.22
Wall time: 14262.606670863926
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    145   100       0.0209       0.0189     8.45e-05      0.00196         0.81         1.52       0.0671        0.102        0.383        0.489
    145   200       0.0189       0.0184      0.00035     0.000121        0.888          1.5        0.103        0.207       0.0971        0.121
    145   300        0.059       0.0588     8.13e-05      9.2e-05         1.26         2.68       0.0648       0.0996       0.0869        0.106
    145   400       0.0258       0.0253     0.000329     0.000167        0.933         1.76          0.1          0.2        0.103        0.143
    145   500      0.00832      0.00779     0.000158     0.000374        0.559        0.975        0.075        0.139        0.156        0.214
    145   600      0.00553      0.00535     5.95e-05     0.000115        0.498        0.808       0.0589       0.0852       0.0882        0.119
    145   700      0.00384      0.00317     0.000106     0.000571        0.401        0.622       0.0745        0.114        0.236        0.264
    145   800       0.0132       0.0128     7.93e-05     0.000321         0.69         1.25       0.0625       0.0984        0.167        0.198
    145   900      0.00666       0.0063     6.42e-05     0.000303        0.522        0.877       0.0577       0.0885         0.15        0.192
    145  1000       0.0114       0.0104     7.23e-05     0.000983         0.63         1.12         0.06        0.094        0.306        0.346
    145  1100      0.00688      0.00565     0.000388     0.000844         0.58         0.83       0.0837        0.218        0.269        0.321
    145  1200        0.031       0.0304     7.19e-05     0.000502         1.02         1.93       0.0598       0.0937        0.193        0.247
    145  1300       0.0111       0.0106      8.7e-05     0.000484        0.577         1.14       0.0615        0.103        0.184        0.243
    145  1400      0.00461      0.00406      6.7e-05     0.000475        0.419        0.704       0.0548       0.0904        0.197        0.241
    145  1500       0.0391       0.0386     0.000115     0.000358         1.06         2.17       0.0757        0.119        0.207        0.209
    145  1600       0.0137       0.0129     0.000138     0.000668         0.59         1.26       0.0717         0.13         0.27        0.286
    145  1700        0.025       0.0248      4.3e-05     0.000222        0.867         1.74       0.0502       0.0725         0.16        0.165
    145  1800       0.0116        0.011        6e-05     0.000557        0.631         1.16        0.053       0.0856        0.213        0.261
    145  1900         0.02       0.0176     0.000261      0.00211        0.899         1.47       0.0946        0.179        0.357        0.508
    145  2000        0.021       0.0201     7.03e-05     0.000783        0.866         1.57       0.0628       0.0926        0.287        0.309
    145  2039      0.00596      0.00571     0.000175     8.13e-05        0.542        0.835       0.0696        0.146       0.0985       0.0996

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    145   100       0.0128       0.0111     0.000148      0.00148        0.762         1.17       0.0653        0.135         0.33        0.426
    145   182        0.126        0.126     0.000126     2.53e-05         2.51         3.91       0.0658        0.124       0.0555       0.0555


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             145 14361.395    0.001       0.0212     0.000128     0.000513       0.0218        0.773         1.61         0.07        0.125        0.193         0.25
! Validation        145 14361.395    0.001       0.0218     0.000136     0.000662       0.0226        0.783         1.62       0.0695        0.129        0.221        0.285
Wall time: 14361.39589856565
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    146   100      0.00796      0.00685     6.78e-05      0.00104        0.559        0.915       0.0597        0.091        0.261        0.357
    146   200       0.0228       0.0218     0.000228     0.000766         1.05         1.63       0.0929        0.167        0.305        0.306
    146   300       0.0233       0.0226     0.000378     0.000379        0.777         1.66       0.0889        0.215        0.207        0.215
    146   400       0.0237       0.0231     9.24e-05     0.000497        0.906         1.68       0.0618        0.106        0.232        0.246
    146   500      0.00478      0.00442     0.000324     4.11e-05        0.457        0.734        0.086        0.199       0.0661       0.0708
    146   600        0.029       0.0285     9.93e-05     0.000411        0.849         1.87       0.0723         0.11        0.195        0.224
    146   700       0.0464       0.0461     0.000102     0.000257         1.21         2.37       0.0703        0.111        0.123        0.177
    146   800       0.0305       0.0302     0.000102     0.000273        0.949         1.92       0.0661        0.112        0.174        0.182
    146   900      0.00155      0.00128     5.79e-05     0.000204        0.275        0.396       0.0597       0.0841        0.142        0.158
    146  1000       0.0134       0.0126      9.1e-05     0.000723        0.587         1.24       0.0703        0.105        0.227        0.297
    146  1100       0.0389       0.0387     6.91e-05     0.000131         1.19         2.17       0.0626       0.0918        0.107        0.126
    146  1200      0.00611      0.00507     0.000359     0.000672        0.517        0.787        0.101        0.209        0.242        0.286
    146  1300       0.0108      0.00921     0.000364      0.00125        0.667         1.06       0.0824        0.211        0.353        0.391
    146  1400      0.00491      0.00456     0.000102     0.000248        0.541        0.746       0.0644        0.111        0.166        0.174
    146  1500       0.0619       0.0617     9.78e-05     9.07e-05         1.34         2.75       0.0686        0.109       0.0851        0.105
    146  1600      0.00341      0.00243     9.43e-05     0.000886        0.372        0.545       0.0654        0.107        0.235        0.329
    146  1700       0.0032       0.0024     3.81e-05     0.000759        0.397        0.542       0.0483       0.0682        0.273        0.304
    146  1800        0.053       0.0528     9.55e-05     0.000126         1.21         2.54       0.0719        0.108        0.105        0.124
    146  1900       0.0186       0.0182     7.43e-05     0.000368        0.964         1.49       0.0628       0.0952        0.197        0.212
    146  2000        0.012       0.0098     8.72e-05      0.00208        0.599         1.09       0.0674        0.103        0.341        0.504
    146  2039       0.0419       0.0418     5.26e-05     3.75e-05         1.41         2.26       0.0587       0.0801       0.0672       0.0676

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    146   100      0.00358      0.00258     5.36e-05     0.000947        0.323        0.561       0.0509       0.0809        0.303         0.34
    146   182         0.12         0.12     0.000111     0.000112         2.48         3.82        0.057        0.117        0.117        0.117


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             146 14460.213    0.001       0.0212     0.000133     0.000489       0.0218        0.775         1.61       0.0706        0.127        0.189        0.244
! Validation        146 14460.213    0.001       0.0198     0.000108     0.000405       0.0203        0.728         1.54        0.064        0.115        0.175        0.223
Wall time: 14460.214107051492
! Best model      146    0.020
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    147   100      0.00507      0.00472     4.18e-05     0.000304         0.44        0.759         0.05       0.0714        0.162        0.193
    147   200       0.0252       0.0244     5.53e-05     0.000673        0.932         1.73       0.0541       0.0822        0.261        0.287
    147   300       0.0179       0.0175     0.000111     0.000308        0.814         1.46       0.0652        0.116        0.136        0.194
    147   400       0.0131       0.0124     6.33e-05     0.000642        0.667         1.23       0.0581       0.0879        0.216         0.28
    147   500       0.0646       0.0643      0.00011      0.00019         1.36          2.8       0.0776        0.116        0.121        0.152
    147   600       0.0503       0.0499     0.000103     0.000318         1.13         2.47        0.073        0.112        0.184        0.197
    147   700      0.00401      0.00296     5.28e-05     0.000997        0.354        0.601       0.0562       0.0803        0.267        0.349
    147   800        0.032       0.0313     0.000215     0.000506          1.1         1.95       0.0722        0.162        0.229        0.249
    147   900       0.0282       0.0277     6.57e-05     0.000428        0.826         1.84       0.0605       0.0896        0.219        0.229
    147  1000         0.01      0.00896     9.96e-05     0.000944        0.534         1.05       0.0672         0.11        0.276         0.34
    147  1100       0.0088      0.00725     0.000439      0.00111        0.587        0.941       0.0808        0.231        0.336        0.368
    147  1200      0.00633      0.00601     7.98e-05     0.000242        0.558        0.856       0.0671       0.0987         0.14        0.172
    147  1300       0.0142       0.0138     9.84e-05     0.000309        0.754          1.3       0.0702         0.11        0.168        0.194
    147  1400        0.027       0.0266     0.000105      0.00034         1.05          1.8       0.0718        0.113        0.199        0.204
    147  1500       0.0077      0.00724     7.51e-05     0.000386        0.564         0.94        0.061       0.0958        0.192        0.217
    147  1600      0.00272      0.00203     0.000626     6.23e-05        0.334        0.498       0.0903        0.276       0.0801       0.0872
    147  1700       0.0118       0.0113     9.56e-05     0.000377        0.785         1.18       0.0624        0.108        0.184        0.215
    147  1800       0.0594        0.059     7.93e-05     0.000372         1.46         2.68       0.0688       0.0984        0.181        0.213
    147  1900       0.0334        0.033     0.000155     0.000224         1.18         2.01       0.0746        0.138        0.145        0.165
    147  2000       0.0819       0.0815      0.00027      9.3e-05         1.42         3.15       0.0733        0.181       0.0845        0.107
    147  2039      0.00601      0.00579     6.34e-05     0.000156        0.573        0.841       0.0568        0.088        0.125        0.138

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    147   100      0.00449       0.0038     6.42e-05     0.000626        0.446        0.681       0.0579       0.0885        0.204        0.276
    147   182         0.16        0.159     0.000168     0.000249         2.71         4.41       0.0689        0.143        0.174        0.174


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             147 14559.159    0.001       0.0209     0.000131      0.00051       0.0216        0.772          1.6         0.07        0.127        0.192         0.25
! Validation        147 14559.159    0.001       0.0212     0.000136     0.000356       0.0217        0.766         1.59         0.07        0.129        0.158        0.209
Wall time: 14559.16059049964
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    148   100       0.0335       0.0316     7.16e-05      0.00181        0.886         1.96        0.059       0.0935        0.405         0.47
    148   200      0.00942      0.00854      6.7e-05     0.000807        0.527         1.02       0.0613       0.0904        0.253        0.314
    148   300      0.00458      0.00446      4.6e-05     7.75e-05        0.357        0.738       0.0535       0.0749       0.0835       0.0973
    148   400       0.0132       0.0127     0.000179     0.000335        0.687         1.24       0.0744        0.148        0.181        0.202
    148   500      0.00462      0.00423     0.000168     0.000214        0.478        0.719       0.0786        0.143        0.131        0.162
    148   600      0.00174      0.00135     7.84e-05     0.000304        0.291        0.407       0.0666       0.0978         0.15        0.193
    148   700      0.00621      0.00551     9.37e-05     0.000613        0.476         0.82       0.0714        0.107        0.255        0.273
    148   800       0.0452       0.0449     8.21e-05     0.000197        0.988         2.34       0.0695          0.1        0.127        0.155
    148   900       0.0403       0.0402     0.000108     8.47e-05         1.15         2.21       0.0779        0.115       0.0776        0.102
    148  1000       0.0174       0.0151     5.14e-05      0.00228        0.834         1.36       0.0531       0.0792        0.507        0.528
    148  1100       0.0107       0.0105      7.3e-05     7.35e-05        0.767         1.13       0.0651       0.0944       0.0796       0.0947
    148  1200       0.0311       0.0306     0.000106     0.000384        0.869         1.93       0.0666        0.114        0.183        0.217
    148  1300       0.0148       0.0142     0.000111     0.000546        0.766         1.32        0.063        0.117        0.204        0.258
    148  1400      0.00942      0.00932     7.68e-05     2.08e-05        0.636         1.07       0.0635       0.0968       0.0381       0.0504
    148  1500       0.0187       0.0174      0.00012      0.00119        0.857         1.46       0.0827        0.121        0.293        0.381
    148  1600       0.0278       0.0274      0.00035     9.76e-05         1.09         1.83       0.0716        0.207       0.0924        0.109
    148  1700      0.00413      0.00393     0.000105     9.63e-05        0.435        0.692       0.0704        0.113       0.0869        0.108
    148  1800       0.0123       0.0118     0.000383      0.00013         0.82          1.2       0.0978        0.216        0.116        0.126
    148  1900       0.0363        0.035     6.76e-05      0.00125        0.837         2.07       0.0556       0.0908        0.351         0.39
    148  2000      0.00555      0.00452     4.87e-05     0.000979        0.446        0.743       0.0568       0.0771        0.279        0.346
    148  2039        0.016       0.0155     7.83e-05     0.000412        0.775         1.37       0.0718       0.0978        0.197        0.224

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    148   100      0.00508      0.00394     6.43e-05      0.00108        0.466        0.693       0.0613       0.0886        0.317        0.362
    148   182         0.13         0.13     4.86e-05     2.98e-05         2.39         3.98        0.057        0.077       0.0603       0.0603


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             148 14658.101    0.001       0.0208     0.000134     0.000488       0.0214         0.77         1.59       0.0707        0.128        0.188        0.244
! Validation        148 14658.101    0.001       0.0221     0.000162     0.000518       0.0228        0.811         1.63       0.0776        0.141        0.202        0.252
Wall time: 14658.101982913911
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    149   100      0.00503      0.00488     7.52e-05     7.88e-05        0.488        0.772       0.0541       0.0958        0.075       0.0981
    149   200      0.00499      0.00395     9.17e-05     0.000952        0.408        0.694       0.0675        0.106        0.288        0.341
    149   300       0.0369       0.0366     5.23e-05     0.000194        0.936         2.11       0.0551       0.0799        0.145        0.154
    149   400       0.0425       0.0419     8.67e-05     0.000479        0.922         2.26       0.0675        0.103        0.233        0.242
    149   500       0.0716       0.0713      0.00011     0.000228         1.49         2.95       0.0778        0.116        0.123        0.167
    149   600       0.0118        0.011      7.8e-05     0.000712        0.537         1.16       0.0586       0.0976        0.228        0.295
    149   700       0.0293       0.0292     4.82e-05     7.36e-05         1.12         1.89       0.0517       0.0767       0.0827       0.0948
    149   800       0.0137       0.0128      8.4e-05     0.000825        0.766         1.25       0.0686        0.101         0.29        0.317
    149   900       0.0172        0.017     5.28e-05     0.000155        0.614         1.44       0.0525       0.0803        0.116        0.137
    149  1000       0.0115       0.0112     7.33e-05     0.000212        0.672         1.17       0.0624       0.0946        0.137        0.161
    149  1100      0.00378      0.00314     6.49e-05     0.000575        0.431        0.619       0.0665        0.089        0.198        0.265
    149  1200      0.00596      0.00567     7.65e-05     0.000217        0.585        0.832       0.0718       0.0966        0.134        0.163
    149  1300      0.00924      0.00829     0.000382     0.000567        0.711         1.01        0.103        0.216        0.254        0.263
    149  1400       0.0139        0.013     0.000181     0.000662        0.716         1.26       0.0799        0.148        0.249        0.284
    149  1500       0.0275       0.0271     0.000107     0.000316         1.14         1.82       0.0719        0.114        0.165        0.196
    149  1600        0.024       0.0234     6.59e-05     0.000516        0.843         1.69       0.0594       0.0897        0.239        0.251
    149  1700       0.0383       0.0375     8.24e-05     0.000721          1.1         2.14       0.0724          0.1        0.222        0.297
    149  1800       0.0216       0.0203     0.000442      0.00086         1.14         1.57        0.118        0.232        0.264        0.324
    149  1900       0.0151       0.0147     8.71e-05     0.000369        0.753         1.34       0.0717        0.103        0.194        0.212
    149  2000      0.00229      0.00196     9.52e-05     0.000239         0.37        0.489       0.0716        0.108        0.149        0.171
    149  2039       0.0123        0.012     0.000337      1.4e-05        0.703         1.21       0.0738        0.203       0.0361       0.0413

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    149   100        0.017       0.0162     0.000243     0.000533        0.794         1.41       0.0668        0.172         0.21        0.255
    149   182        0.118        0.118     7.78e-05     7.76e-05         2.31         3.79       0.0546       0.0974       0.0974       0.0974


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             149 14756.983    0.001       0.0205     0.000137     0.000494       0.0211         0.77         1.58       0.0717         0.13         0.19        0.246
! Validation        149 14756.983    0.001         0.02     0.000159     0.000442       0.0206        0.773         1.55       0.0696         0.14        0.175        0.233
Wall time: 14756.983866877854
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    150   100       0.0144        0.014     0.000169     0.000206        0.874         1.31       0.0808        0.144        0.138        0.159
    150   200       0.0433       0.0428     0.000183     0.000278         1.14         2.29        0.079        0.149         0.17        0.184
    150   300      0.00868      0.00852     5.77e-05     0.000112        0.735         1.02       0.0577       0.0839       0.0981        0.117
    150   400      0.00242      0.00232     8.09e-05      2.2e-05        0.342        0.532       0.0574       0.0993       0.0418       0.0518
    150   500       0.0069      0.00543     4.62e-05      0.00142        0.456        0.815       0.0513       0.0751        0.358        0.416
    150   600      0.00507      0.00435     0.000329     0.000388         0.46        0.729       0.0838          0.2        0.194        0.218
    150   700       0.0171       0.0168     0.000187     0.000117        0.866         1.43          0.1        0.151        0.117         0.12
    150   800       0.0477       0.0472     7.26e-05     0.000398         1.06          2.4        0.063       0.0941         0.16        0.221
    150   900      0.00839      0.00777     8.17e-05     0.000538        0.638        0.974       0.0629       0.0999        0.226        0.256
    150  1000      0.00987      0.00972     7.46e-05     7.45e-05        0.667         1.09       0.0653       0.0955       0.0867       0.0954
    150  1100      0.00666      0.00628     0.000141     0.000241        0.614        0.876       0.0772        0.131        0.131        0.171
    150  1200       0.0186       0.0175     5.14e-05      0.00108        0.875         1.46       0.0555       0.0792        0.313        0.363
    150  1300        0.017       0.0162     0.000323      0.00046        0.764         1.41       0.0937        0.198        0.182        0.237
    150  1400       0.0359       0.0356     0.000117     0.000175         1.16         2.09       0.0759         0.12        0.115        0.146
    150  1500       0.0388       0.0385     0.000105     0.000257          1.1         2.17       0.0687        0.113        0.151        0.177
    150  1600      0.00611      0.00553     7.61e-05     0.000498        0.506        0.822       0.0658       0.0964        0.192        0.246
    150  1700      0.00283      0.00249     7.02e-05     0.000272        0.356        0.551       0.0554       0.0925        0.168        0.182
    150  1800       0.0206       0.0203     9.45e-05     0.000155        0.784         1.58       0.0669        0.107        0.114        0.137
    150  1900        0.015       0.0144      4.2e-05     0.000499        0.506         1.33       0.0494       0.0716        0.168        0.247
    150  2000       0.0119       0.0117      6.4e-05     5.34e-05        0.543          1.2         0.06       0.0884       0.0698       0.0807
    150  2039      0.00158      0.00126     6.43e-05     0.000254        0.241        0.392       0.0549       0.0886        0.149        0.176

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    150   100      0.00679      0.00556     5.72e-05      0.00118        0.488        0.824       0.0574       0.0835        0.345        0.379
    150   182        0.165        0.164     0.000344     3.33e-06         2.73         4.48       0.0799        0.205       0.0202       0.0202


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             150 14855.873    0.001       0.0204     0.000139     0.000476        0.021        0.768         1.58       0.0713         0.13        0.187        0.241
! Validation        150 14855.873    0.001       0.0197     0.000117      0.00063       0.0204        0.747         1.53       0.0691        0.119        0.222        0.278
Wall time: 14855.874243937433
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    151   100      0.00849       0.0079     0.000186     0.000405        0.604        0.982       0.0883        0.151        0.199        0.222
    151   200      0.00892      0.00818     0.000363     0.000373        0.603            1       0.0926         0.21        0.161        0.213
    151   300       0.0136      0.00983      0.00144      0.00233        0.764          1.1        0.144        0.419        0.411        0.533
    151   400        0.013       0.0121     0.000614     0.000335        0.682         1.21          0.1        0.274        0.189        0.202
    151   500      0.00568      0.00534     3.78e-05     0.000305        0.493        0.807       0.0468       0.0679        0.174        0.193
    151   600       0.0777        0.077      0.00013     0.000505         1.32         3.07       0.0864        0.126        0.221        0.248
    151   700       0.0248        0.024     0.000166     0.000609        0.968         1.71       0.0898        0.143         0.23        0.273
    151   800      0.00424      0.00297     4.95e-05      0.00121        0.381        0.602        0.052       0.0777        0.314        0.385
    151   900      0.00111     0.000522     7.32e-05     0.000511        0.206        0.252       0.0636       0.0945        0.241         0.25
    151  1000       0.0196       0.0188     9.63e-05     0.000659        0.829         1.51       0.0675        0.108         0.21        0.284
    151  1100        0.038       0.0375     0.000391     0.000149         1.08         2.14        0.103        0.219        0.119        0.135
    151  1200       0.0161       0.0156     0.000253     0.000216        0.854         1.38       0.0792        0.176        0.135        0.163
    151  1300       0.0023       0.0021     3.26e-05     0.000174        0.312        0.506       0.0407       0.0631        0.123        0.146
    151  1400       0.0089      0.00869     6.37e-05     0.000145         0.58         1.03       0.0569       0.0882       0.0996        0.133
    151  1500       0.0315       0.0306     8.14e-05     0.000845         1.03         1.93       0.0654       0.0997        0.279        0.321
    151  1600       0.0449       0.0447     0.000143     9.44e-05         1.27         2.34       0.0846        0.132       0.0979        0.107
    151  1700      0.00222      0.00205     4.02e-05     0.000134        0.394          0.5       0.0504       0.0701        0.122        0.128
    151  1800       0.0466       0.0449     8.96e-05      0.00163         1.26         2.34       0.0711        0.105        0.343        0.446
    151  1900       0.0256       0.0253     0.000147     0.000199         1.07         1.76       0.0835        0.134        0.139        0.156
    151  2000        0.034       0.0333     7.48e-05     0.000572        0.935         2.02       0.0595       0.0955        0.258        0.264
    151  2039      0.00707      0.00686     4.47e-05     0.000167        0.506        0.915        0.048       0.0739        0.103        0.143

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    151   100      0.00603       0.0057     5.81e-05     0.000273        0.583        0.834       0.0549       0.0842        0.147        0.182
    151   182        0.159        0.159     3.96e-05     0.000737         2.68          4.4       0.0454       0.0695          0.3          0.3


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             151 14955.002    0.001       0.0201      0.00014     0.000514       0.0208        0.762         1.57       0.0714        0.131        0.192         0.25
! Validation        151 14955.002    0.001       0.0216     0.000114     0.000433       0.0221        0.777          1.6       0.0644        0.118        0.181         0.23
Wall time: 14955.002811722457
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    152   100       0.0128       0.0125     0.000101     0.000185        0.657         1.23       0.0707        0.111        0.105         0.15
    152   200        0.028       0.0277     9.82e-05     0.000188          1.1         1.84       0.0723        0.109        0.108        0.152
    152   300       0.0134       0.0122     7.27e-05      0.00118        0.621         1.22       0.0659       0.0942        0.376        0.379
    152   400      0.00983      0.00946     6.58e-05     0.000301        0.648         1.07       0.0594       0.0896        0.163        0.192
    152   500      0.00501      0.00394     0.000883      0.00019        0.442        0.694         0.09        0.328         0.13        0.152
    152   600      0.00445      0.00391     0.000262     0.000282         0.48         0.69       0.0714        0.179         0.16        0.185
    152   700       0.0447        0.044     0.000123     0.000558          1.1         2.32       0.0722        0.123        0.251        0.261
    152   800      0.00297       0.0015     8.31e-05      0.00139         0.33        0.427       0.0651        0.101        0.391        0.413
    152   900      0.00641      0.00609     0.000161     0.000162         0.52        0.862       0.0923         0.14         0.11        0.141
    152  1000       0.0087      0.00811     0.000126     0.000461        0.554        0.995       0.0679        0.124        0.185        0.237
    152  1100      0.00511      0.00497     9.75e-05     3.98e-05        0.517        0.779       0.0645        0.109        0.068       0.0697
    152  1200       0.0124        0.012     5.81e-05     0.000253        0.671         1.21       0.0578       0.0842        0.149        0.176
    152  1300      0.00257      0.00185     0.000317     0.000406        0.359        0.475       0.0801        0.197        0.214        0.223
    152  1400       0.0226       0.0224     0.000118     4.19e-05        0.905         1.66       0.0782         0.12        0.058       0.0715
    152  1500       0.0382       0.0381     6.63e-05     6.45e-05         1.02         2.16       0.0577         0.09       0.0773       0.0887
    152  1600       0.0162       0.0159     7.35e-05     0.000225        0.779         1.39       0.0665       0.0947        0.143        0.166
    152  1700       0.0358       0.0341     0.000165      0.00152         1.19         2.04       0.0726        0.142        0.294        0.431
    152  1800      0.00572      0.00496     0.000175     0.000584          0.5        0.778       0.0807        0.146        0.226        0.267
    152  1900      0.00817      0.00739     9.43e-05     0.000687        0.612         0.95       0.0754        0.107         0.21         0.29
    152  2000       0.0032      0.00306     5.37e-05     8.47e-05        0.388        0.612       0.0491        0.081       0.0948        0.102
    152  2039       0.0569        0.056     7.78e-05     0.000842         1.63         2.61       0.0629       0.0975         0.32        0.321

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    152   100      0.00585      0.00454     5.55e-05      0.00126        0.487        0.744       0.0527       0.0823        0.238        0.392
    152   182        0.141        0.141     4.04e-05     0.000174          2.5         4.15       0.0466       0.0702        0.146        0.146


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             152 15053.959    0.001       0.0202     0.000138     0.000491       0.0209        0.763         1.57       0.0708         0.13        0.189        0.245
! Validation        152 15053.959    0.001       0.0208     0.000103     0.000542       0.0215        0.767         1.57       0.0635        0.112        0.203        0.258
Wall time: 15053.960421405733
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    153   100       0.0355       0.0346     8.76e-05     0.000793        0.872         2.06       0.0644        0.103         0.25        0.311
    153   200      0.00169       0.0015     7.62e-05     0.000116        0.302        0.428       0.0625       0.0965       0.0836        0.119
    153   300       0.0901       0.0897     0.000155     0.000198          1.6         3.31       0.0805        0.137        0.118        0.155
    153   400      0.00665      0.00526     4.77e-05      0.00134        0.499        0.802       0.0552       0.0763        0.297        0.404
    153   500      0.00397      0.00366     6.18e-05     0.000247        0.428        0.668       0.0597       0.0869        0.134        0.174
    153   600      0.00445      0.00434     5.72e-05     4.98e-05        0.402        0.728       0.0561       0.0836       0.0707        0.078
    153   700       0.0154        0.015     0.000103      0.00027        0.852         1.35        0.067        0.112        0.157        0.181
    153   800       0.0291       0.0285     0.000348     0.000255         1.02         1.86       0.0943        0.206        0.159        0.177
    153   900      0.00148     0.000986      0.00011     0.000384        0.291        0.347       0.0771        0.116        0.205        0.216
    153  1000       0.0658       0.0654     9.01e-05     0.000295         1.04         2.83       0.0688        0.105        0.139         0.19
    153  1100        0.015       0.0143     6.41e-05     0.000692        0.692         1.32       0.0587       0.0885        0.229        0.291
    153  1200       0.0116       0.0101     0.000212      0.00135        0.811         1.11        0.102        0.161        0.353        0.405
    153  1300       0.0208         0.02     0.000216     0.000622        0.925         1.56       0.0947        0.162        0.243        0.276
    153  1400       0.0364       0.0359     0.000247     0.000193         1.19         2.09       0.0915        0.174        0.119        0.154
    153  1500      0.00834      0.00804     6.36e-05     0.000228        0.542        0.991       0.0621       0.0881        0.144        0.167
    153  1600     0.000933     0.000701     7.99e-05     0.000152        0.188        0.292       0.0627       0.0988        0.113        0.136
    153  1700      0.00636      0.00609     7.21e-05     0.000193        0.482        0.862       0.0622       0.0938        0.134        0.153
    153  1800       0.0594       0.0576     0.000416      0.00144         1.54         2.65        0.115        0.225        0.363         0.42
    153  1900      0.00693      0.00649     0.000139     0.000293        0.537         0.89       0.0825         0.13        0.166        0.189
    153  2000      0.00497      0.00405     0.000101     0.000816          0.5        0.703       0.0668        0.111        0.281        0.316
    153  2039       0.0137       0.0136     6.44e-05     1.24e-05        0.833         1.29       0.0521       0.0887       0.0321        0.039

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    153   100      0.00274      0.00233     4.73e-05     0.000355        0.349        0.534       0.0523        0.076        0.151        0.208
    153   182        0.168        0.167     4.36e-05     0.000272          2.7         4.52       0.0452       0.0729        0.182        0.182


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             153 15152.796    0.001       0.0201      0.00014     0.000511       0.0207        0.763         1.57        0.072        0.131        0.193         0.25
! Validation        153 15152.796    0.001       0.0207      0.00014     0.000446       0.0213        0.771         1.56       0.0654        0.131        0.184        0.234
Wall time: 15152.7967107445
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    154   100       0.0281       0.0273     8.07e-05     0.000701        0.925         1.83       0.0607       0.0992        0.216        0.292
    154   200      0.00144      0.00128     5.69e-05     0.000104        0.282        0.395       0.0533       0.0834        0.102        0.113
    154   300       0.0643       0.0632     0.000551     0.000488         1.76         2.78        0.116        0.259        0.229        0.244
    154   400       0.0107       0.0101     7.31e-05     0.000555        0.701         1.11       0.0623       0.0945        0.233         0.26
    154   500      0.00247      0.00226     9.61e-05      0.00012         0.32        0.525       0.0675        0.108       0.0962        0.121
    154   600      0.00551      0.00516     0.000108     0.000239        0.526        0.794       0.0767        0.115        0.167        0.171
    154   700        0.018       0.0178     5.51e-05     0.000121        0.701         1.47       0.0531        0.082         0.11        0.121
    154   800      0.00801      0.00774     0.000108     0.000161        0.643        0.972       0.0717        0.115        0.128         0.14
    154   900      0.00939       0.0093     7.38e-05     9.54e-06        0.624         1.07       0.0672       0.0949       0.0334       0.0341
    154  1000       0.0295       0.0285     6.15e-05     0.000898        0.986         1.87       0.0622       0.0866        0.296        0.331
    154  1100      0.00951      0.00893      0.00013      0.00045        0.564         1.04       0.0658        0.126        0.193        0.234
    154  1200       0.0488        0.047     8.04e-05      0.00175          1.1          2.4       0.0694       0.0991        0.388        0.462
    154  1300      0.00479      0.00394     0.000372     0.000473        0.479        0.694       0.0834        0.213        0.211         0.24
    154  1400       0.0121       0.0111     8.24e-05     0.000997        0.681         1.16       0.0679          0.1        0.347        0.349
    154  1500      0.00929      0.00886     0.000245     0.000181        0.623         1.04       0.0959        0.173        0.126        0.149
    154  1600       0.0305       0.0293     0.000466     0.000701         1.14         1.89        0.103        0.239        0.256        0.293
    154  1700       0.0119       0.0111     0.000134     0.000588        0.748         1.17       0.0764        0.128        0.219        0.268
    154  1800      0.00301      0.00199     6.19e-05     0.000956        0.341        0.493       0.0502        0.087         0.32        0.342
    154  1900       0.0104      0.00994     0.000212     0.000224        0.611          1.1       0.0846        0.161        0.138        0.165
    154  2000       0.0625        0.062     0.000175     0.000358         1.26         2.75       0.0901        0.146        0.178        0.209
    154  2039        0.045        0.044     0.000184     0.000789         1.27         2.32       0.0888         0.15        0.293         0.31

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    154   100      0.00661      0.00499     7.71e-05      0.00154        0.492        0.781       0.0649        0.097        0.348        0.433
    154   182        0.142        0.141     0.000195      8.5e-07          2.5         4.16       0.0704        0.154       0.0102       0.0102


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             154 15251.784    0.001       0.0197      0.00014     0.000487       0.0203        0.755         1.55       0.0708        0.131        0.189        0.244
! Validation        154 15251.784    0.001         0.02     0.000169     0.000715       0.0209        0.758         1.54       0.0765        0.144         0.25        0.296
Wall time: 15251.78468581289
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    155   100      0.00479      0.00373       0.0001     0.000962        0.528        0.674       0.0754        0.111         0.28        0.343
    155   200      0.00215      0.00172     0.000221     0.000206        0.349        0.459       0.0694        0.164        0.139        0.158
    155   300      0.00569      0.00502     9.63e-05     0.000575        0.518        0.783       0.0743        0.108        0.239        0.265
    155   400       0.0275       0.0262     0.000183      0.00105         1.03         1.79       0.0943        0.149        0.231        0.358
    155   500      0.00721      0.00637     0.000317     0.000521        0.531        0.882       0.0942        0.197        0.183        0.252
    155   600      0.00432      0.00411     6.74e-05     0.000138        0.404        0.709       0.0602       0.0907        0.115         0.13
    155   700       0.0195       0.0189     0.000148     0.000403        0.851         1.52       0.0883        0.134        0.199        0.222
    155   800      0.00528      0.00373     0.000309      0.00124        0.476        0.675       0.0904        0.194        0.338         0.39
    155   900      0.00236       0.0018     3.99e-05     0.000515        0.342        0.469       0.0495       0.0698        0.176        0.251
    155  1000      0.00413      0.00368     0.000228     0.000225        0.507         0.67       0.0808        0.167        0.158        0.166
    155  1100      0.00815      0.00546     0.000939      0.00175        0.534        0.816         0.11        0.339        0.238        0.462
    155  1200       0.0263       0.0257     3.35e-05     0.000553        0.777         1.77       0.0443       0.0639        0.238         0.26
    155  1300      0.00149     0.000946     4.25e-05     0.000504        0.228         0.34       0.0494        0.072        0.247        0.248
    155  1400      0.00839      0.00823     6.16e-05       0.0001        0.452            1       0.0576       0.0867       0.0899        0.111
    155  1500       0.0671       0.0656     0.000165      0.00129         1.44         2.83       0.0794        0.142        0.382        0.397
    155  1600       0.0279       0.0272     5.92e-05     0.000591         1.04         1.82       0.0614        0.085        0.237        0.269
    155  1700       0.0122        0.012     9.43e-05     0.000149        0.823         1.21        0.068        0.107         0.11        0.135
    155  1800       0.0187       0.0178     4.87e-05     0.000843        0.875         1.47       0.0552       0.0771        0.224        0.321
    155  1900       0.0405       0.0398      0.00021     0.000458         1.46         2.21       0.0887         0.16         0.22        0.236
    155  2000       0.0299       0.0297     0.000148     3.75e-05        0.956         1.91       0.0828        0.134       0.0505       0.0676
    155  2039      0.00451      0.00411     0.000204       0.0002        0.559        0.708        0.111        0.158         0.14        0.156

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    155   100       0.0066      0.00515     8.16e-05      0.00137        0.487        0.793       0.0651       0.0998        0.353        0.408
    155   182         0.11         0.11     5.86e-05     0.000137         2.18         3.66       0.0524       0.0846         0.13         0.13


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             155 15351.127    0.001       0.0201     0.000139     0.000494       0.0207         0.76         1.57       0.0723         0.13         0.19        0.246
! Validation        155 15351.127    0.001       0.0193     0.000127     0.000903       0.0204        0.735         1.52       0.0714        0.125        0.244        0.333
Wall time: 15351.12900595367
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    156   100       0.0351       0.0349     9.91e-05     4.02e-05        0.975         2.06       0.0738         0.11       0.0513       0.0701
    156   200      0.00614      0.00597     5.14e-05     0.000122        0.545        0.854       0.0568       0.0792        0.119        0.122
    156   300       0.0385       0.0379     0.000489     9.08e-05         1.28         2.15       0.0972        0.244       0.0903        0.105
    156   400       0.0856       0.0853     0.000107     0.000191         1.39         3.23       0.0647        0.114        0.113        0.153
    156   500       0.0751       0.0743     0.000151     0.000606         1.85         3.01       0.0884        0.136        0.212        0.272
    156   600      0.00183      0.00166     3.94e-05     0.000136        0.268         0.45       0.0453       0.0694        0.126        0.129
    156   700       0.0104      0.00848     0.000139      0.00179        0.694         1.02       0.0715         0.13        0.405        0.467
    156   800        0.017       0.0167     8.79e-05     0.000205        0.898         1.43       0.0736        0.104        0.137        0.158
    156   900      0.00522      0.00443     5.51e-05     0.000744        0.489        0.735        0.054        0.082        0.267        0.301
    156  1000        0.004      0.00265     7.45e-05      0.00127        0.342        0.569       0.0661       0.0954        0.261        0.394
    156  1100      0.00679      0.00579     5.39e-05     0.000943        0.513        0.841       0.0539       0.0811        0.273        0.339
    156  1200      0.00471      0.00375     0.000102     0.000859        0.465        0.676       0.0774        0.112        0.274        0.324
    156  1300      0.00423      0.00394     6.35e-05     0.000224        0.482        0.694       0.0601       0.0881        0.147        0.165
    156  1400       0.0019      0.00143     5.37e-05     0.000413        0.305        0.418       0.0559        0.081        0.185        0.224
    156  1500       0.0274       0.0271     6.78e-05     0.000281        0.928         1.82       0.0623        0.091         0.17        0.185
    156  1600       0.0033      0.00317     7.11e-05     6.71e-05        0.398        0.622       0.0596       0.0932       0.0841       0.0905
    156  1700       0.0485       0.0483     0.000103     0.000144         1.46         2.43        0.073        0.112        0.122        0.133
    156  1800      0.00917      0.00865     7.63e-05     0.000443        0.539         1.03       0.0646       0.0965        0.218        0.233
    156  1900      0.00229      0.00199     5.01e-05     0.000255        0.344        0.492        0.054       0.0782        0.158        0.176
    156  2000       0.0309       0.0307     5.93e-05      0.00013         1.07         1.94       0.0567       0.0851       0.0977        0.126
    156  2039       0.0134        0.013     0.000272     0.000156        0.885         1.26        0.123        0.182         0.12        0.138

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    156   100      0.00436      0.00404     8.49e-05     0.000236        0.435        0.702       0.0614        0.102        0.135         0.17
    156   182        0.222        0.222     0.000312     0.000161         3.04          5.2       0.0788        0.195         0.14         0.14


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             156 15450.182    0.001       0.0199     0.000143     0.000507       0.0205         0.76         1.56        0.072        0.132        0.191        0.249
! Validation        156 15450.182    0.001         0.02     0.000144     0.000317       0.0205        0.737         1.53       0.0713        0.132        0.155        0.197
Wall time: 15450.18505486101
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    157   100      0.00807      0.00771     8.48e-05     0.000273        0.612         0.97       0.0702        0.102        0.172        0.183
    157   200      0.00595      0.00574     6.08e-05     0.000146        0.554        0.837       0.0555       0.0862       0.0933        0.133
    157   300       0.0292       0.0287     0.000171     0.000328        0.968         1.87       0.0867        0.145        0.163          0.2
    157   400      0.00578      0.00525     0.000111     0.000421        0.531          0.8       0.0718        0.116        0.188        0.227
    157   500       0.0483       0.0445     0.000209      0.00359         1.39         2.33       0.0879         0.16         0.51        0.662
    157   600      0.00537      0.00454     0.000117     0.000706        0.552        0.745       0.0855         0.12        0.286        0.293
    157   700       0.0226       0.0215     0.000384     0.000721        0.939         1.62       0.0846        0.216        0.243        0.297
    157   800        0.035       0.0347        6e-05     0.000324        0.969         2.06         0.06       0.0856        0.178        0.199
    157   900      0.00488      0.00452     4.48e-05     0.000315        0.443        0.743       0.0514       0.0739        0.194        0.196
    157  1000       0.0456       0.0452      0.00013     0.000278         1.15         2.35       0.0807        0.126        0.155        0.184
    157  1100       0.0244       0.0237     4.91e-05     0.000594        0.906          1.7       0.0528       0.0774        0.252        0.269
    157  1200      0.00453      0.00426     8.48e-05     0.000184        0.482        0.721        0.071        0.102        0.128         0.15
    157  1300        0.015        0.014     0.000214     0.000826        0.754         1.31       0.0881        0.162        0.234        0.318
    157  1400      0.00313      0.00297     7.03e-05     9.52e-05        0.438        0.602       0.0638       0.0926       0.0945        0.108
    157  1500       0.0326       0.0319     9.11e-05     0.000703        0.915         1.97        0.067        0.105        0.226        0.293
    157  1600       0.0062       0.0057     8.62e-05      0.00041        0.483        0.834       0.0699        0.103        0.183        0.224
    157  1700       0.0149       0.0144     0.000125     0.000347        0.766         1.33       0.0816        0.123        0.174        0.206
    157  1800       0.0417       0.0415     7.42e-05      0.00012         1.49         2.25       0.0671       0.0952        0.113        0.121
    157  1900      0.00259      0.00221     5.61e-05     0.000326        0.331         0.52       0.0569       0.0827        0.197        0.199
    157  2000       0.0113        0.011     0.000165     4.01e-05        0.683         1.16       0.0862        0.142       0.0628       0.0699
    157  2039      0.00221      0.00214     5.32e-05      1.8e-05        0.374        0.511       0.0547       0.0806       0.0353       0.0469

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    157   100       0.0045      0.00399     0.000118     0.000396        0.442        0.698        0.067         0.12        0.202         0.22
    157   182         0.19        0.189     0.000198     0.000605          2.9         4.81       0.0663        0.155        0.272        0.272


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             157 15550.053    0.001         0.02     0.000141     0.000494       0.0206        0.757         1.56       0.0715        0.131        0.188        0.246
! Validation        157 15550.053    0.001         0.02     0.000134     0.000373       0.0205         0.74         1.53       0.0694        0.128        0.164        0.213
Wall time: 15550.055150084198
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    158   100       0.0077      0.00748     0.000111     0.000107        0.538        0.955       0.0695        0.117       0.0989        0.114
    158   200      0.00706      0.00658     0.000128     0.000355        0.609        0.896        0.066        0.125        0.142        0.208
    158   300       0.0209       0.0202     0.000142     0.000536        0.818         1.57       0.0911        0.132         0.22        0.256
    158   400       0.0252       0.0248     0.000115     0.000344         1.04         1.74       0.0738        0.118        0.156        0.205
    158   500       0.0129       0.0126     0.000119     0.000262        0.622         1.24       0.0752        0.121        0.163        0.179
    158   600       0.0167       0.0151     0.000957     0.000717        0.848         1.36        0.122        0.342        0.252        0.296
    158   700      0.00791      0.00756     8.69e-05     0.000268        0.603         0.96       0.0662        0.103        0.129        0.181
    158   800       0.0379       0.0375     6.77e-05     0.000422        0.965         2.14       0.0565       0.0909        0.129        0.227
    158   900       0.0154       0.0142      0.00037     0.000847         0.93         1.31        0.103        0.213        0.244        0.322
    158  1000       0.0103      0.00985     4.32e-05     0.000381        0.568          1.1       0.0517       0.0726        0.181        0.216
    158  1100       0.0884       0.0871     0.000497     0.000765         1.41         3.26       0.0969        0.246        0.265        0.306
    158  1200       0.0334        0.033      0.00012     0.000321         1.21         2.01       0.0783        0.121        0.127        0.198
    158  1300       0.0165       0.0162     0.000155     0.000127        0.918         1.41       0.0892        0.138        0.104        0.125
    158  1400       0.0362       0.0356     5.12e-05     0.000589        0.825         2.08       0.0501       0.0791        0.229        0.268
    158  1500       0.0163       0.0158     6.91e-05     0.000403        0.792         1.39       0.0647       0.0919        0.191        0.222
    158  1600       0.0106       0.0104     4.33e-05     0.000143        0.569         1.13       0.0508       0.0727         0.11        0.132
    158  1700       0.0161       0.0155     0.000209     0.000393        0.872         1.38        0.102         0.16        0.137        0.219
    158  1800       0.0181       0.0171     0.000157     0.000847        0.918         1.45        0.081        0.138        0.272        0.322
    158  1900       0.0636       0.0627     0.000423     0.000424         1.52         2.77         0.12        0.227        0.211        0.228
    158  2000       0.0103       0.0101     0.000101     6.56e-05        0.765         1.11       0.0755        0.111        0.086       0.0895
    158  2039      0.00481      0.00453     0.000107     0.000177        0.487        0.744       0.0739        0.114        0.131        0.147

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    158   100      0.00478      0.00425     7.47e-05      0.00045        0.472        0.721       0.0653       0.0955        0.192        0.234
    158   182        0.129        0.128     6.41e-05     4.98e-05         2.38         3.96       0.0612       0.0885        0.078        0.078


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             158 15649.434    0.001       0.0195     0.000146     0.000511       0.0202         0.75         1.54       0.0719        0.133        0.191         0.25
! Validation        158 15649.434    0.001         0.02     0.000159     0.000334       0.0205        0.771         1.54       0.0775         0.14        0.155        0.202
Wall time: 15649.436410039663
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    159   100      0.00312      0.00262     0.000333     0.000167        0.395        0.565       0.0905        0.202         0.13        0.143
    159   200       0.0158       0.0154     9.08e-05     0.000268        0.751         1.37       0.0719        0.105        0.143        0.181
    159   300       0.0262       0.0258     0.000195      0.00019         1.06         1.77       0.0791        0.154        0.136        0.152
    159   400      0.00512       0.0049     0.000113     0.000105        0.507        0.773       0.0689        0.118       0.0888        0.113
    159   500       0.0532        0.053     8.51e-05     6.56e-05         1.18         2.54       0.0663        0.102       0.0793       0.0895
    159   600       0.0261       0.0252     0.000245     0.000657         1.05         1.75       0.0796        0.173        0.192        0.283
    159   700      0.00922       0.0091     4.48e-05     8.07e-05        0.577         1.05       0.0503        0.074       0.0913       0.0992
    159   800       0.0122       0.0115     6.96e-05     0.000613        0.641         1.19       0.0589       0.0922        0.188        0.274
    159   900      0.00855      0.00826     5.99e-05     0.000239        0.584            1       0.0542       0.0855        0.138        0.171
    159  1000        0.024       0.0238     0.000113     0.000153        0.852          1.7       0.0566        0.118        0.114        0.137
    159  1100      0.00981      0.00853     0.000129      0.00115         0.65         1.02       0.0751        0.125         0.21        0.375
    159  1200      0.00258      0.00189     0.000133     0.000555        0.361         0.48       0.0783        0.127        0.172         0.26
    159  1300       0.0108      0.00991     0.000119     0.000763        0.715          1.1       0.0786        0.121         0.26        0.305
    159  1400       0.0274       0.0264     0.000104     0.000892        0.968          1.8       0.0628        0.113        0.292         0.33
    159  1500       0.0256       0.0249     5.83e-05     0.000593         1.07         1.74       0.0595       0.0844        0.219        0.269
    159  1600      0.00391      0.00372     5.03e-05     0.000136        0.484        0.674       0.0539       0.0784        0.126        0.129
    159  1700       0.0312       0.0307     0.000113     0.000351         1.04         1.94       0.0763        0.117        0.166        0.207
    159  1800       0.0447       0.0439     0.000276     0.000547         1.13         2.31       0.0942        0.184        0.223        0.259
    159  1900       0.0107      0.00935     0.000177      0.00113        0.607         1.07       0.0811        0.147        0.355        0.372
    159  2000      0.00391      0.00347     9.01e-05     0.000354        0.407        0.651       0.0643        0.105        0.179        0.208
    159  2039         0.04         0.04     5.11e-05     1.43e-05         1.37         2.21       0.0573        0.079       0.0393       0.0418

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    159   100      0.00312      0.00278     7.97e-05     0.000259        0.351        0.583       0.0632       0.0986        0.159        0.178
    159   182        0.162        0.162     7.11e-05     0.000341         2.76         4.44       0.0545       0.0932        0.204        0.204


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             159 15748.962    0.001       0.0197     0.000145     0.000482       0.0203        0.754         1.55       0.0717        0.133        0.188        0.243
! Validation        159 15748.962    0.001       0.0203     0.000123     0.000327       0.0208        0.753         1.55       0.0701        0.123        0.153          0.2
Wall time: 15748.96307566762
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    160   100      0.00543      0.00516     6.07e-05     0.000205        0.485        0.794       0.0609       0.0861        0.117        0.158
    160   200      0.00693      0.00629     0.000123     0.000513        0.606        0.877       0.0791        0.123        0.238         0.25
    160   300       0.0627       0.0623     0.000231     0.000151         1.52         2.76        0.088        0.168        0.126        0.136
    160   400      0.00438      0.00425     6.91e-05     5.53e-05        0.516        0.721       0.0647       0.0918       0.0545       0.0822
    160   500       0.0159       0.0129     9.22e-05      0.00285        0.694         1.26       0.0719        0.106        0.442         0.59
    160   600      0.00165     0.000621        4e-05     0.000988        0.197        0.275        0.048       0.0699          0.3        0.347
    160   700       0.0236       0.0232     0.000136     0.000213        0.995         1.68       0.0695        0.129        0.124        0.161
    160   800       0.0156        0.015     0.000121     0.000492        0.599         1.35        0.081        0.122        0.217        0.245
    160   900       0.0374        0.036     0.000812     0.000549        0.996          2.1        0.119        0.315        0.194        0.259
    160  1000      0.00221      0.00186     0.000139     0.000208        0.348        0.477       0.0738         0.13        0.142        0.159
    160  1100       0.0227       0.0216     0.000162     0.000938         1.03         1.62       0.0898        0.141        0.271        0.338
    160  1200       0.0494       0.0492     6.74e-05     0.000103        0.953         2.45       0.0587       0.0907       0.0952        0.112
    160  1300       0.0196       0.0187     0.000101     0.000766        0.882         1.51       0.0693        0.111        0.241        0.306
    160  1400      0.00343      0.00303     2.09e-05     0.000378        0.327        0.608        0.037       0.0505        0.206        0.215
    160  1500       0.0406       0.0403     0.000116     0.000175         1.19         2.22       0.0795        0.119        0.131        0.146
    160  1600      0.00872      0.00784     0.000846      2.7e-05        0.614        0.978       0.0979        0.321       0.0532       0.0574
    160  1700         0.01      0.00978     6.32e-05     0.000198        0.662         1.09       0.0592       0.0878        0.153        0.155
    160  1800      0.00429      0.00397     6.92e-05     0.000252        0.529        0.696         0.06       0.0919        0.157        0.175
    160  1900       0.0037      0.00224     0.000172      0.00128        0.405        0.523       0.0733        0.145        0.336        0.395
    160  2000       0.0029       0.0026     4.25e-05     0.000251        0.417        0.564       0.0504       0.0721        0.129        0.175
    160  2039      0.00164      0.00136     0.000105     0.000178        0.344        0.408       0.0659        0.113        0.147        0.147

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    160   100      0.00711      0.00589     5.84e-05      0.00117        0.557        0.848       0.0572       0.0844        0.312        0.378
    160   182        0.182        0.182     0.000167     7.89e-05         3.02         4.71       0.0679        0.143       0.0981       0.0981


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             160 15848.585    0.001       0.0193      0.00014     0.000471         0.02        0.746         1.54       0.0712        0.131        0.183         0.24
! Validation        160 15848.585    0.001       0.0205     0.000128     0.000594       0.0212        0.763         1.55       0.0728        0.125        0.214         0.27
Wall time: 15848.586043268442
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    161   100       0.0114        0.011     7.79e-05     0.000281        0.763         1.16       0.0645       0.0975         0.17        0.185
    161   200      0.00685      0.00666     6.59e-05     0.000133        0.573        0.901       0.0645       0.0897        0.114        0.127
    161   300      0.00879      0.00816      0.00011     0.000525        0.621        0.998       0.0762        0.116        0.207        0.253
    161   400       0.0236       0.0231     7.04e-05      0.00042        0.825         1.68       0.0603       0.0927        0.215        0.226
    161   500        0.017       0.0161     0.000397      0.00047        0.775          1.4       0.0966         0.22        0.207         0.24
    161   600      0.00196      0.00163     6.75e-05     0.000267        0.276        0.445       0.0622       0.0908        0.157         0.18
    161   700       0.0241       0.0233     0.000358     0.000457         1.06         1.69       0.0825        0.209        0.209        0.236
    161   800       0.0123       0.0107     0.000222      0.00134        0.737         1.14       0.0841        0.165        0.283        0.404
    161   900      0.00246      0.00167     0.000392     0.000398        0.279        0.451       0.0813        0.219        0.183        0.221
    161  1000       0.0051      0.00221     5.02e-05      0.00284        0.341        0.519        0.054       0.0783        0.559        0.589
    161  1100      0.00499      0.00473     3.92e-05     0.000221        0.456         0.76       0.0472       0.0691        0.134        0.164
    161  1200       0.0277       0.0264     0.000574     0.000687         1.14          1.8        0.102        0.265        0.276         0.29
    161  1300       0.0145       0.0141     5.81e-05     0.000304         0.76         1.31       0.0561       0.0842         0.18        0.193
    161  1400      0.00475      0.00436     7.23e-05     0.000326        0.509        0.729       0.0643        0.094        0.187        0.199
    161  1500      0.00227       0.0019     6.91e-05     0.000299        0.348        0.482       0.0653       0.0918        0.163        0.191
    161  1600        0.007       0.0061     0.000272     0.000624        0.578        0.863       0.0949        0.182        0.253        0.276
    161  1700      0.00591      0.00567     0.000158     7.75e-05         0.44        0.832       0.0741        0.139       0.0898       0.0973
    161  1800        0.022       0.0218     6.54e-05     7.95e-05        0.795         1.63       0.0589       0.0893        0.071       0.0985
    161  1900       0.0156       0.0148     0.000684     0.000163        0.742         1.34        0.107        0.289        0.121        0.141
    161  2000       0.0283       0.0281     0.000165     6.36e-05        0.902         1.85       0.0879        0.142       0.0706       0.0881
    161  2039       0.0272       0.0255      5.7e-05      0.00166        0.916         1.77       0.0577       0.0834         0.45         0.45

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    161   100      0.00691      0.00559     5.38e-05      0.00127        0.472        0.826       0.0563       0.0811        0.251        0.394
    161   182        0.166        0.165     0.000119     0.000217         2.86         4.49       0.0629        0.121        0.163        0.163


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             161 15947.934    0.001       0.0193     0.000139     0.000486       0.0199        0.745         1.53       0.0712         0.13        0.188        0.243
! Validation        161 15947.934    0.001       0.0197     0.000126     0.000597       0.0205        0.755         1.53       0.0718        0.124        0.205         0.27
Wall time: 15947.934763528407
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    162   100      0.00094     0.000636     5.07e-05     0.000253        0.218        0.279       0.0558       0.0787        0.166        0.176
    162   200      0.00255       0.0023     9.47e-05     0.000153        0.363         0.53       0.0757        0.107        0.106        0.137
    162   300      0.00235      0.00212     8.63e-05      0.00015        0.336        0.509       0.0749        0.103         0.12        0.135
    162   400      0.00138     0.000907     0.000429     4.55e-05        0.265        0.333        0.088        0.229       0.0656       0.0745
    162   500       0.0078       0.0074     0.000277     0.000127        0.592        0.951       0.0796        0.184        0.111        0.124
    162   600       0.0014      0.00105     7.36e-05     0.000283        0.263        0.358       0.0589       0.0948        0.153        0.186
    162   700      0.00152      0.00119     4.61e-05      0.00028        0.293        0.382       0.0529        0.075        0.142        0.185
    162   800        0.029       0.0287     5.87e-05      0.00026        0.741         1.87       0.0557       0.0847        0.159        0.178
    162   900       0.0448       0.0445     0.000218     7.86e-05         1.03         2.33       0.0869        0.163       0.0965        0.098
    162  1000       0.0074      0.00587     0.000169      0.00136         0.63        0.846       0.0926        0.144        0.381        0.407
    162  1100      0.00245      0.00136     7.03e-05      0.00102        0.314        0.408        0.062       0.0927        0.285        0.352
    162  1200      0.00674      0.00638     7.79e-05     0.000282        0.484        0.882       0.0644       0.0975        0.139        0.186
    162  1300       0.0292       0.0286     0.000108     0.000432         1.14         1.87       0.0733        0.115        0.187         0.23
    162  1400       0.0116       0.0115     5.51e-05     8.44e-05        0.646         1.18       0.0537        0.082       0.0796        0.101
    162  1500      0.00323      0.00263      5.7e-05     0.000544        0.377        0.566       0.0588       0.0834        0.231        0.258
    162  1600       0.0034      0.00252     0.000104     0.000767        0.374        0.555       0.0617        0.113        0.248        0.306
    162  1700       0.0138       0.0134     0.000109     0.000355        0.738         1.28         0.07        0.116        0.174        0.208
    162  1800     0.000868     0.000644     5.95e-05     0.000164        0.199         0.28       0.0571       0.0852       0.0938        0.142
    162  1900       0.0129       0.0123     8.14e-05     0.000559        0.749         1.22       0.0668       0.0997        0.248        0.261
    162  2000       0.0487        0.048     0.000108     0.000616         1.23         2.42       0.0789        0.115        0.212        0.274
    162  2039       0.0202       0.0198     7.74e-05     0.000337        0.815         1.55       0.0702       0.0972        0.167        0.203

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    162   100       0.0078       0.0065      5.6e-05      0.00124        0.584        0.891       0.0557       0.0827        0.287         0.39
    162   182        0.137        0.137     5.33e-05     8.99e-09         2.59         4.09       0.0528       0.0807      0.00105      0.00105


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             162 16047.590    0.001       0.0192     0.000142     0.000475       0.0199        0.743         1.53       0.0722        0.132        0.185        0.241
! Validation        162 16047.590    0.001         0.02     0.000141     0.000463       0.0206        0.781         1.54       0.0721        0.131        0.188        0.238
Wall time: 16047.591574117541
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    163   100      0.00411      0.00354     0.000219     0.000343        0.438        0.658       0.0918        0.164        0.176        0.205
    163   200       0.0303       0.0275     6.09e-05      0.00273        0.802         1.83       0.0562       0.0863        0.531        0.577
    163   300        0.109        0.108     0.000188     0.000287         1.71         3.64        0.081        0.151        0.142        0.187
    163   400       0.0333       0.0325      0.00034     0.000468         1.08         1.99        0.113        0.204        0.207        0.239
    163   500      0.00346      0.00276     0.000101     0.000598        0.388        0.581       0.0659        0.111         0.25         0.27
    163   600        0.018       0.0178     6.38e-05     0.000146        0.869         1.47       0.0672       0.0883        0.123        0.134
    163   700       0.0137       0.0131     0.000169     0.000457        0.671         1.26       0.0994        0.144        0.212        0.236
    163   800       0.0267       0.0263     0.000132     0.000236         1.04         1.79       0.0847        0.127        0.158         0.17
    163   900      0.00461      0.00299     5.27e-05      0.00157        0.388        0.604       0.0529       0.0802        0.347        0.438
    163  1000        0.029        0.028     0.000453     0.000626         1.01         1.85       0.0907        0.235        0.238        0.277
    163  1100       0.0183       0.0176     0.000132     0.000571        0.703         1.47        0.085        0.127        0.234        0.264
    163  1200       0.0566       0.0563     5.81e-05     0.000262         1.46         2.62       0.0582       0.0842        0.117        0.179
    163  1300      0.00553       0.0051      4.5e-05      0.00038        0.428        0.789       0.0518       0.0741        0.159        0.215
    163  1400      0.00506      0.00489     2.03e-05     0.000149        0.495        0.773        0.034       0.0497       0.0959        0.135
    163  1500      0.00353      0.00273     0.000108     0.000683        0.401        0.578       0.0773        0.115        0.231        0.289
    163  1600       0.0307       0.0295     0.000205      0.00106         1.01          1.9       0.0843        0.158        0.321         0.36
    163  1700       0.0141      0.00935     0.000134      0.00466        0.548         1.07       0.0795        0.128        0.505        0.754
    163  1800        0.012       0.0118     7.17e-05     0.000156        0.768          1.2       0.0593       0.0936        0.114        0.138
    163  1900       0.0286       0.0277     0.000288     0.000607         0.83         1.84        0.088        0.187        0.223        0.272
    163  2000      0.00703      0.00627     9.22e-05     0.000674        0.469        0.875       0.0693        0.106        0.217        0.287
    163  2039       0.0127       0.0123     0.000116     0.000301         0.81         1.22       0.0784        0.119        0.157        0.192

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    163   100      0.00462      0.00389     9.76e-05     0.000629        0.479        0.689       0.0658        0.109        0.236        0.277
    163   182        0.161        0.161     0.000116      4.2e-05         2.75         4.44       0.0602        0.119       0.0716       0.0716


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             163 16147.514    0.001        0.019     0.000147     0.000502       0.0197        0.747         1.52       0.0721        0.134         0.19        0.248
! Validation        163 16147.514    0.001       0.0197     0.000148      0.00034       0.0202        0.767         1.52       0.0763        0.134        0.158        0.204
Wall time: 16147.514805063605
! Best model      163    0.020
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    164   100      0.00579      0.00544     7.88e-05     0.000262         0.52        0.815       0.0655       0.0981        0.157        0.179
    164   200       0.0234       0.0225     0.000417     0.000546        0.882         1.66       0.0957        0.226        0.218        0.258
    164   300       0.0414       0.0412     8.32e-05     8.55e-05         1.21         2.24       0.0653        0.101       0.0833        0.102
    164   400      0.00315      0.00257     6.35e-05     0.000518        0.403         0.56       0.0635        0.088         0.24        0.251
    164   500      0.00204      0.00147     0.000332     0.000245        0.347        0.423        0.083        0.201        0.159        0.173
    164   600       0.0377       0.0371     3.14e-05      0.00053        0.795         2.13       0.0412       0.0619        0.241        0.254
    164   700       0.0259       0.0256     5.02e-05     0.000254        0.873         1.77       0.0549       0.0783        0.165        0.176
    164   800       0.0223       0.0219     0.000226     0.000258         1.03         1.63       0.0973        0.166        0.174        0.177
    164   900      0.00343      0.00335     5.48e-05     2.44e-05        0.406         0.64       0.0569       0.0818       0.0435       0.0545
    164  1000      0.00853      0.00721     9.59e-05      0.00122        0.666        0.938       0.0707        0.108        0.319        0.386
    164  1100       0.0105       0.0102     4.62e-05      0.00021        0.506         1.12       0.0497       0.0751        0.133         0.16
    164  1200       0.0041      0.00288     7.49e-05      0.00115        0.367        0.593       0.0642       0.0956        0.331        0.374
    164  1300      0.00521      0.00471     4.04e-05     0.000465        0.448        0.758       0.0499       0.0702        0.225        0.238
    164  1400      0.00455      0.00414     0.000111     0.000292        0.443        0.711       0.0793        0.117        0.167        0.189
    164  1500       0.0161       0.0154     0.000141     0.000523        0.901         1.37       0.0768        0.131        0.188        0.253
    164  1600      0.00551      0.00526     0.000103     0.000142          0.4        0.802       0.0614        0.112        0.117        0.132
    164  1700       0.0396        0.038     0.000143      0.00143        0.991         2.15       0.0837        0.132        0.271        0.418
    164  1800       0.0123       0.0117     0.000173     0.000441        0.741          1.2       0.0878        0.145        0.208        0.232
    164  1900      0.00175      0.00134     6.82e-05     0.000349        0.301        0.404        0.061       0.0913        0.195        0.206
    164  2000      0.00298      0.00167     0.000127      0.00118         0.36        0.452       0.0812        0.124        0.329         0.38
    164  2039      0.00239      0.00106     4.39e-05      0.00129        0.278        0.359       0.0424       0.0732        0.387        0.396

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    164   100      0.00658      0.00542     0.000109      0.00105        0.484        0.813       0.0636        0.115        0.292        0.358
    164   182        0.231        0.231     0.000255      1.4e-10         3.24         5.31       0.0738        0.176     0.000131     0.000131


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             164 16246.605    0.001       0.0189     0.000148      0.00044       0.0195        0.744         1.52       0.0732        0.134        0.179        0.232
! Validation        164 16246.605    0.001       0.0208     0.000171     0.000525       0.0215        0.773         1.56       0.0731        0.144        0.205        0.254
Wall time: 16246.605976983905
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    165   100      0.00205      0.00169     0.000146     0.000221        0.341        0.454        0.078        0.133        0.157        0.164
    165   200      0.00249      0.00196     8.35e-05     0.000444        0.323        0.489       0.0594        0.101        0.166        0.233
    165   300      0.00637      0.00534     0.000864     0.000167        0.459        0.808        0.102        0.325         0.12        0.143
    165   400        0.019       0.0186     5.81e-05      0.00034        0.683         1.51       0.0603       0.0842        0.177        0.204
    165   500      0.00343      0.00306     0.000104     0.000267        0.476        0.611        0.074        0.113        0.149         0.18
    165   600       0.0357       0.0344     0.000391     0.000921         1.18         2.05        0.125        0.218        0.253        0.335
    165   700      0.00587      0.00508     9.98e-05     0.000688        0.529        0.788       0.0758         0.11        0.169         0.29
    165   800      0.00216      0.00192     0.000172     6.83e-05        0.336        0.484       0.0731        0.145       0.0855       0.0913
    165   900        0.028       0.0273     7.94e-05     0.000615         1.04         1.83       0.0677       0.0984        0.226        0.274
    165  1000       0.0181        0.017     0.000242     0.000894        0.843         1.44       0.0824        0.172          0.3         0.33
    165  1100       0.0137       0.0128     0.000162     0.000651        0.765         1.25       0.0802        0.141        0.269        0.282
    165  1200      0.00889      0.00851     0.000111     0.000272        0.654         1.02       0.0714        0.117        0.166        0.182
    165  1300      0.00682      0.00661     4.38e-05     0.000163        0.535        0.899       0.0494       0.0731        0.135        0.141
    165  1400      0.00727      0.00632     0.000169     0.000783        0.632        0.878       0.0728        0.144         0.28        0.309
    165  1500      0.00342      0.00293     0.000158     0.000333        0.399        0.598       0.0712        0.139         0.12        0.202
    165  1600       0.0327       0.0316     0.000168     0.000978         1.15         1.96       0.0851        0.143        0.327        0.346
    165  1700       0.0123       0.0112     8.79e-05      0.00107        0.714         1.17       0.0667        0.104        0.323        0.362
    165  1800      0.00171      0.00159     8.53e-05     4.23e-05        0.295         0.44       0.0663        0.102       0.0611       0.0718
    165  1900       0.0193       0.0191     5.91e-05     0.000107        0.781         1.53       0.0587        0.085       0.0901        0.114
    165  2000       0.0163       0.0162     9.57e-05     3.71e-05        0.804         1.41       0.0705        0.108       0.0631       0.0673
    165  2039       0.0255       0.0242     0.000817     0.000479         1.06         1.72        0.112        0.316        0.191        0.242

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    165   100      0.00416      0.00379     7.65e-05     0.000297        0.416         0.68       0.0643       0.0966        0.143        0.191
    165   182        0.167        0.166     0.000145     0.000108         2.69         4.51       0.0656        0.133        0.115        0.115


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             165 16346.222    0.001        0.019     0.000141     0.000476       0.0196        0.742         1.52       0.0715        0.131        0.184        0.241
! Validation        165 16346.222    0.001       0.0191     0.000155     0.000314       0.0196         0.74          1.5       0.0759        0.137        0.151        0.196
Wall time: 16346.223031125963
! Best model      165    0.020
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    166   100      0.00717      0.00627     6.28e-05     0.000839        0.593        0.875       0.0601       0.0876        0.259         0.32
    166   200      0.00669      0.00634     8.48e-05     0.000261          0.6         0.88       0.0665        0.102        0.104        0.179
    166   300       0.0423       0.0418     8.49e-05     0.000459         1.25         2.26       0.0728        0.102        0.214        0.237
    166   400       0.0128       0.0121     0.000299     0.000412        0.825         1.21       0.0975        0.191        0.182        0.224
    166   500       0.0102      0.00975     6.21e-05     0.000358        0.578         1.09       0.0552        0.087        0.195        0.209
    166   600       0.0135       0.0132     8.09e-05      0.00023        0.632         1.27       0.0652       0.0994        0.101        0.168
    166   700       0.0052      0.00483     0.000214     0.000154        0.518        0.768       0.0781        0.162        0.132        0.137
    166   800        0.107        0.106     6.74e-05     0.000611         1.86          3.6        0.065       0.0907        0.229        0.273
    166   900       0.0185       0.0174     0.000323     0.000733        0.686         1.46       0.0961        0.198        0.292        0.299
    166  1000       0.0238       0.0214     0.000119      0.00228         0.89         1.62       0.0734        0.121        0.384        0.528
    166  1100       0.0308       0.0305     8.51e-05     0.000167        0.981         1.93       0.0654        0.102        0.107        0.143
    166  1200      0.00932      0.00898     4.56e-05     0.000294        0.633         1.05       0.0534       0.0746        0.164        0.189
    166  1300       0.0018      0.00154     7.58e-05     0.000185        0.325        0.434       0.0647       0.0962        0.126         0.15
    166  1400       0.0264       0.0261     0.000105     0.000112        0.834         1.79        0.078        0.113        0.102        0.117
    166  1500      0.00266      0.00237     5.08e-05     0.000234        0.378        0.538       0.0534       0.0787        0.138        0.169
    166  1600       0.0202       0.0196        8e-05     0.000545        0.878         1.55       0.0678       0.0988        0.228        0.258
    166  1700      0.00311      0.00257     8.84e-05     0.000452        0.466         0.56       0.0692        0.104        0.179        0.235
    166  1800       0.0141       0.0135     0.000246     0.000387         0.76         1.28       0.0825        0.173        0.159        0.217
    166  1900      0.00407      0.00401     4.06e-05     1.85e-05        0.383          0.7       0.0503       0.0704       0.0452       0.0476
    166  2000       0.0692       0.0688     0.000143     0.000283          1.7          2.9       0.0754        0.132        0.183        0.186
    166  2039       0.0014       0.0013      3.6e-05     7.23e-05        0.276        0.398       0.0471       0.0663       0.0939        0.094

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    166   100      0.00818      0.00673     6.86e-05      0.00138        0.477        0.906       0.0579       0.0915        0.361         0.41
    166   182        0.142        0.142     7.65e-05     2.84e-05         2.51         4.16       0.0543       0.0966       0.0589       0.0589


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             166 16445.900    0.001       0.0191     0.000154     0.000437       0.0197        0.745         1.53       0.0735        0.137        0.178        0.231
! Validation        166 16445.900    0.001         0.02     0.000142     0.000595       0.0207        0.764         1.54         0.07        0.132        0.218         0.27
Wall time: 16445.901136904955
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    167   100      0.00199      0.00177     6.86e-05     0.000147        0.338        0.465       0.0613       0.0915        0.106        0.134
    167   200       0.0244       0.0243      7.9e-05     4.23e-05        0.857         1.72        0.068       0.0982       0.0575       0.0718
    167   300       0.0107      0.00998     0.000461     0.000308        0.754          1.1        0.116        0.237        0.181        0.194
    167   400      0.00193      0.00173     7.27e-05     0.000127         0.32         0.46        0.067       0.0942        0.113        0.125
    167   500       0.0506       0.0494     0.000171      0.00109         1.59         2.46       0.0858        0.145        0.338        0.365
    167   600       0.0853       0.0848     0.000133     0.000406         1.59         3.22       0.0728        0.127        0.193        0.223
    167   700       0.0316       0.0314     5.53e-05     0.000189         1.24         1.96       0.0617       0.0822        0.103        0.152
    167   800       0.0146       0.0141      0.00016     0.000315        0.777         1.31       0.0827         0.14        0.183        0.196
    167   900       0.0211       0.0194      0.00014      0.00153        0.894         1.54       0.0893        0.131        0.299        0.432
    167  1000      0.00273      0.00254     7.24e-05     0.000116         0.37        0.557       0.0618        0.094       0.0988        0.119
    167  1100       0.0156       0.0152     0.000334     8.87e-05        0.769         1.36       0.0955        0.202       0.0815        0.104
    167  1200      0.00676      0.00573     0.000303     0.000729        0.684        0.836        0.098        0.192        0.215        0.298
    167  1300       0.0141      0.00896      0.00012      0.00505         0.58         1.05       0.0779        0.121        0.531        0.785
    167  1400       0.0276       0.0273     0.000174     0.000181         1.08         1.82       0.0797        0.146        0.122        0.149
    167  1500       0.0169       0.0161     0.000554     0.000278        0.809          1.4        0.103         0.26        0.164        0.184
    167  1600      0.00607      0.00539     3.29e-05     0.000656        0.435        0.811       0.0407       0.0634        0.268        0.283
    167  1700      0.00688      0.00657     5.59e-05     0.000255        0.507        0.895        0.054       0.0826        0.135        0.176
    167  1800       0.0387       0.0357     0.000164      0.00292        0.953         2.09       0.0965        0.141        0.361        0.597
    167  1900       0.0408       0.0406     9.53e-05     0.000103         1.09         2.23       0.0728        0.108          0.1        0.112
    167  2000       0.0106      0.00971     0.000107     0.000762        0.735         1.09       0.0769        0.114        0.218        0.305
    167  2039      0.00268      0.00217      6.8e-05     0.000441        0.413        0.515       0.0655       0.0911        0.216        0.232

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    167   100      0.00422      0.00327     5.95e-05     0.000889         0.38        0.632       0.0584       0.0853        0.194         0.33
    167   182        0.159        0.158     0.000132     0.000114         2.71          4.4       0.0604        0.127        0.118        0.118


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             167 16545.735    0.001       0.0185     0.000154     0.000446       0.0191        0.737          1.5       0.0735        0.137         0.18        0.233
! Validation        167 16545.735    0.001       0.0187     0.000137     0.000552       0.0194         0.71         1.48       0.0678        0.129          0.2         0.26
Wall time: 16545.73597948253
! Best model      167    0.019
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    168   100       0.0103      0.00861     0.000346      0.00134         0.75         1.02        0.101        0.206        0.275        0.405
    168   200      0.00303      0.00264     6.73e-05     0.000323        0.396        0.567       0.0593       0.0906        0.159        0.198
    168   300       0.0135       0.0132     0.000137     0.000148        0.616         1.27       0.0885        0.129        0.103        0.135
    168   400      0.00271      0.00177     0.000126      0.00082        0.326        0.464       0.0701        0.124        0.277        0.316
    168   500      0.00355       0.0016      0.00108     0.000876        0.325        0.442       0.0909        0.363        0.274        0.327
    168   600       0.0282        0.028     0.000103     0.000102         1.16         1.85       0.0774        0.112        0.107        0.112
    168   700       0.0862       0.0856     5.72e-05     0.000519         1.58         3.23       0.0589       0.0836        0.233        0.252
    168   800       0.0305       0.0302      0.00012     0.000134        0.842         1.92       0.0615        0.121       0.0957        0.128
    168   900      0.00853      0.00792      0.00012     0.000492        0.421        0.983       0.0696        0.121        0.222        0.245
    168  1000        0.011       0.0106     8.37e-05     0.000333        0.716         1.14       0.0689        0.101        0.156        0.202
    168  1100        0.053       0.0528      9.1e-05     7.97e-05        0.961         2.54       0.0665        0.105       0.0895       0.0986
    168  1200      0.00254      0.00211      4.6e-05      0.00038        0.363        0.507       0.0504        0.075        0.171        0.215
    168  1300       0.0142       0.0132     0.000249     0.000801        0.801         1.27          0.1        0.174        0.267        0.313
    168  1400       0.0029      0.00241     6.13e-05     0.000436        0.361        0.542        0.055       0.0865         0.19        0.231
    168  1500      0.00942      0.00907      7.7e-05     0.000276        0.636         1.05       0.0647        0.097        0.144        0.183
    168  1600       0.0165       0.0163     4.91e-05     0.000183        0.716         1.41       0.0543       0.0774        0.139         0.15
    168  1700       0.0893       0.0883     0.000128     0.000896         1.55         3.28       0.0774        0.125         0.26        0.331
    168  1800        0.125        0.123     0.000238      0.00116         2.26         3.88        0.101         0.17        0.322        0.377
    168  1900       0.0341       0.0339     8.69e-05     0.000146        0.996         2.03       0.0625        0.103        0.122        0.133
    168  2000       0.0298        0.029     0.000674     0.000137        0.996         1.88        0.124        0.287        0.118        0.129
    168  2039      0.00472      0.00423     0.000124     0.000365        0.448        0.718       0.0822        0.123         0.21        0.211

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    168   100      0.00938      0.00885     6.93e-05     0.000459        0.691         1.04       0.0626        0.092         0.21        0.237
    168   182        0.194        0.194     0.000207     9.85e-09         2.92         4.86       0.0783        0.159       0.0011       0.0011


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             168 16645.145    0.001       0.0185     0.000152     0.000447       0.0191        0.733          1.5       0.0727        0.136        0.181        0.234
! Validation        168 16645.145    0.001       0.0203      0.00018     0.000338       0.0208        0.771         1.54       0.0807        0.148        0.157        0.204
Wall time: 16645.14655210823
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    169   100       0.0334       0.0333     6.65e-05     5.72e-05         1.11         2.02        0.066       0.0901       0.0764       0.0835
    169   200       0.0147        0.014     9.74e-05     0.000604        0.806         1.31       0.0693        0.109        0.257        0.272
    169   300      0.00753      0.00695     0.000235      0.00034        0.562        0.921       0.0925        0.169        0.176        0.204
    169   400       0.0137       0.0124     8.68e-05      0.00118        0.651         1.23       0.0671        0.103        0.366        0.379
    169   500      0.00359      0.00302     4.41e-05      0.00052        0.401        0.608       0.0496       0.0734        0.195        0.252
    169   600       0.0021      0.00197     4.99e-05     8.02e-05        0.339        0.491       0.0505       0.0781       0.0871       0.0989
    169   700      0.00797      0.00703     0.000154     0.000781        0.524        0.927       0.0784        0.137        0.295        0.309
    169   800       0.0107       0.0095     0.000561     0.000679         0.69         1.08       0.0973        0.262        0.284        0.288
    169   900      0.00533      0.00519     0.000109     2.95e-05        0.523        0.796       0.0675        0.115       0.0503         0.06
    169  1000      0.00426      0.00387     0.000222     0.000168        0.463        0.687       0.0947        0.165        0.118        0.143
    169  1100      0.00828      0.00783     0.000147     0.000303        0.579        0.978       0.0752        0.134         0.15        0.192
    169  1200       0.0164       0.0163     6.25e-05     4.13e-05        0.642         1.41       0.0604       0.0873       0.0559        0.071
    169  1300      0.00287      0.00229     0.000104      0.00048         0.37        0.528       0.0676        0.113        0.165        0.242
    169  1400      0.00109     0.000561     9.35e-05     0.000436        0.209        0.262       0.0669        0.107        0.209        0.231
    169  1500       0.0278       0.0266     0.000282        0.001         1.02          1.8       0.0929        0.186        0.284         0.35
    169  1600       0.0176       0.0158     8.65e-05       0.0017         0.78         1.39       0.0721        0.103        0.381        0.456
    169  1700      0.00559      0.00478     5.82e-05      0.00075        0.515        0.764       0.0568       0.0843        0.256        0.303
    169  1800       0.0139       0.0136     9.13e-05     0.000144        0.679         1.29       0.0706        0.106        0.123        0.132
    169  1900       0.0317       0.0313     0.000295     0.000198         1.03         1.95        0.102         0.19        0.124        0.156
    169  2000      0.00757      0.00543     0.000343      0.00179        0.547        0.814       0.0996        0.205        0.428        0.468
    169  2039       0.0849       0.0847     9.43e-05     9.39e-05         1.75         3.22       0.0726        0.107       0.0828        0.107

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    169   100      0.00578      0.00509     6.81e-05      0.00063         0.47        0.788       0.0597       0.0912        0.238        0.277
    169   182        0.147        0.147     4.78e-05      9.9e-05          2.6         4.23       0.0504       0.0764         0.11         0.11


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             169 16744.327    0.001       0.0188     0.000156     0.000433       0.0194         0.74         1.51       0.0737        0.138        0.177         0.23
! Validation        169 16744.327    0.001       0.0194     0.000147     0.000353       0.0199        0.748         1.52        0.074        0.134        0.162        0.208
Wall time: 16744.328119792044
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    170   100      0.00683      0.00624     6.17e-05     0.000521        0.533        0.873       0.0579       0.0868        0.234        0.252
    170   200      0.00355      0.00326     5.35e-05     0.000231         0.41        0.631       0.0555       0.0808        0.159        0.168
    170   300       0.0183       0.0182     6.93e-05     3.79e-05         0.83         1.49       0.0574        0.092       0.0576        0.068
    170   400       0.0109       0.0107      0.00011     0.000135        0.585         1.14       0.0758        0.116        0.114        0.128
    170   500       0.0141       0.0139     8.22e-05     7.42e-05        0.588          1.3       0.0649          0.1       0.0775       0.0952
    170   600      0.00197      0.00148     0.000183     0.000307        0.301        0.425       0.0708        0.149        0.147        0.194
    170   700       0.0365       0.0361     0.000298     0.000115         1.01          2.1       0.0904        0.191        0.106        0.118
    170   800      0.00869      0.00837      7.4e-05      0.00024        0.511         1.01       0.0622       0.0951        0.144        0.171
    170   900       0.0205       0.0199     0.000602     4.48e-05        0.912         1.56        0.112        0.271       0.0584       0.0739
    170  1000      0.00593      0.00529      0.00011     0.000533        0.524        0.804       0.0763        0.116        0.229        0.255
    170  1100      0.00816      0.00761     7.79e-05     0.000471        0.547        0.964       0.0661       0.0975        0.218         0.24
    170  1200       0.0316       0.0301     0.000754     0.000727          1.2         1.92        0.125        0.303        0.249        0.298
    170  1300        0.022       0.0205     0.000688     0.000745        0.859         1.58         0.12         0.29        0.272        0.302
    170  1400      0.00381       0.0029     0.000332     0.000579        0.425        0.595       0.0986        0.201         0.21        0.266
    170  1500      0.00478      0.00417     0.000131     0.000481        0.485        0.714       0.0662        0.126        0.223        0.242
    170  1600        0.016       0.0155     0.000245     0.000254        0.795         1.38       0.0786        0.173        0.139        0.176
    170  1700      0.00921      0.00889     0.000161     0.000161        0.665         1.04       0.0793         0.14        0.111         0.14
    170  1800       0.0138       0.0134     0.000216     0.000175        0.797         1.28        0.083        0.162        0.112        0.146
    170  1900      0.00167      0.00123     0.000122      0.00032        0.307        0.387       0.0631        0.122        0.157        0.198
    170  2000      0.00167      0.00137     9.36e-05     0.000212        0.277        0.408       0.0639        0.107         0.12        0.161
    170  2039      0.00668      0.00645     8.77e-05     0.000145        0.567        0.887       0.0643        0.103        0.133        0.133

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    170   100      0.00521      0.00454     7.26e-05     0.000601        0.517        0.745       0.0615       0.0942        0.212        0.271
    170   182        0.138        0.137     5.71e-05     0.000553         2.43         4.09       0.0527       0.0835         0.26         0.26


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             170 16844.085    0.001       0.0186     0.000161     0.000436       0.0192        0.739         1.51       0.0742         0.14        0.179        0.231
! Validation        170 16844.085    0.001         0.02     0.000144     0.000466       0.0206        0.759         1.54       0.0727        0.133         0.19        0.238
Wall time: 16844.08576450497
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    171   100      0.00541      0.00462     0.000176     0.000613        0.484        0.751       0.0781        0.147          0.2        0.274
    171   200       0.0145       0.0135     0.000159     0.000822         0.73         1.28       0.0878         0.14        0.235        0.317
    171   300      0.00412      0.00367      6.7e-05     0.000383        0.499         0.67       0.0623       0.0904        0.175        0.216
    171   400        0.035       0.0346     0.000154     0.000232        0.892         2.06       0.0782        0.137        0.146        0.168
    171   500        0.041       0.0406     0.000117     0.000266         1.03         2.23       0.0743         0.12        0.113         0.18
    171   600      0.00468      0.00412     8.38e-05     0.000483        0.467        0.709        0.055        0.101        0.219        0.243
    171   700       0.0125       0.0117     0.000117     0.000741        0.803         1.19       0.0822         0.12        0.204        0.301
    171   800       0.0018      0.00155     6.72e-05      0.00019        0.281        0.434        0.065       0.0906        0.133        0.152
    171   900      0.00239      0.00212     6.51e-05     0.000198        0.385        0.509       0.0579       0.0892        0.126        0.155
    171  1000       0.0227       0.0222     5.56e-05     0.000436        0.886         1.65       0.0581       0.0824        0.201        0.231
    171  1100       0.0062      0.00576     5.83e-05     0.000384        0.374        0.839        0.054       0.0844        0.196        0.217
    171  1200       0.0426       0.0422     6.11e-05     0.000356         1.18         2.27         0.05       0.0864        0.173        0.208
    171  1300      0.00457      0.00332     0.000138      0.00112        0.393        0.636       0.0821         0.13         0.33        0.369
    171  1400       0.0327       0.0326     7.27e-05     2.69e-05        0.811         1.99       0.0666       0.0942       0.0336       0.0573
    171  1500      0.00511      0.00315     0.000247      0.00172        0.459         0.62       0.0926        0.174        0.421        0.458
    171  1600       0.0052      0.00396     7.44e-05      0.00116        0.484        0.695       0.0628       0.0953         0.31        0.377
    171  1700      0.00228       0.0019     0.000103     0.000272        0.339        0.482       0.0613        0.112        0.158        0.182
    171  1800       0.0182       0.0175     9.24e-05     0.000646        0.945         1.46       0.0725        0.106        0.244        0.281
    171  1900      0.00739      0.00572      0.00033      0.00134         0.59        0.836       0.0962        0.201        0.366        0.405
    171  2000       0.0217       0.0209      5.3e-05     0.000812        0.817          1.6        0.055       0.0804        0.276        0.315
    171  2039      0.00587      0.00542     6.36e-05     0.000386        0.529        0.814       0.0611       0.0881        0.214        0.217

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    171   100       0.0069      0.00587      4.9e-05     0.000984        0.582        0.846       0.0513       0.0773        0.231        0.347
    171   182       0.0915       0.0914     6.89e-05     1.33e-05         1.96         3.34       0.0519       0.0917       0.0403       0.0403


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             171 16943.670    0.001       0.0183     0.000151     0.000452       0.0189        0.732         1.49       0.0731        0.136        0.181        0.235
! Validation        171 16943.670    0.001       0.0214     0.000126     0.000483        0.022        0.793         1.61       0.0676        0.124        0.188        0.243
Wall time: 16943.671182781458
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    172   100      0.00495      0.00399     5.92e-05     0.000901        0.429        0.698       0.0532        0.085        0.254        0.332
    172   200       0.0365       0.0357     0.000155     0.000626         1.13         2.09       0.0806        0.138        0.191        0.276
    172   300      0.00312      0.00282     4.77e-05     0.000257        0.398        0.587       0.0509       0.0763        0.156        0.177
    172   400      0.00367      0.00298      0.00025     0.000442        0.454        0.603       0.0849        0.175        0.231        0.232
    172   500      0.00242      0.00171     6.72e-05      0.00064        0.341        0.458        0.062       0.0906        0.245         0.28
    172   600      0.00291      0.00234     0.000185     0.000386        0.383        0.534        0.086         0.15        0.163        0.217
    172   700      0.00299      0.00251     0.000103     0.000378        0.427        0.554       0.0792        0.112        0.176        0.215
    172   800      0.00708      0.00671     8.26e-05     0.000288        0.481        0.905       0.0678          0.1        0.147        0.188
    172   900       0.0185       0.0178     8.55e-05     0.000545        0.904         1.48       0.0716        0.102        0.208        0.258
    172  1000       0.0486       0.0478     5.58e-05     0.000754         1.06         2.42       0.0546       0.0826        0.276        0.303
    172  1100      0.00417      0.00384     2.78e-05     0.000304        0.457        0.685       0.0442       0.0583         0.15        0.192
    172  1200       0.0318       0.0314     0.000318      0.00016         1.08         1.96       0.0909        0.197        0.118         0.14
    172  1300       0.0393        0.039     6.79e-05     0.000206        0.879         2.18        0.058        0.091        0.136        0.159
    172  1400       0.0343       0.0338     0.000127     0.000368         1.19         2.03       0.0765        0.125        0.193        0.212
    172  1500      0.00603      0.00585     0.000156     1.78e-05        0.617        0.845       0.0824        0.138       0.0365       0.0466
    172  1600       0.0402       0.0392     0.000188     0.000779         1.09         2.19       0.0911        0.152        0.274        0.308
    172  1700      0.00273      0.00208     9.39e-05     0.000551        0.401        0.504       0.0695        0.107        0.235        0.259
    172  1800       0.0111       0.0109     5.64e-05     0.000156        0.541         1.15        0.057        0.083        0.117        0.138
    172  1900      0.00141      0.00116      7.6e-05     0.000175         0.28        0.376       0.0614       0.0963        0.126        0.146
    172  2000       0.0101      0.00964     0.000123     0.000353        0.732         1.08       0.0803        0.122        0.176        0.208
    172  2039       0.0114       0.0106     8.55e-05     0.000669        0.909         1.14       0.0687        0.102        0.263        0.286

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    172   100       0.0035      0.00308     0.000105     0.000307        0.403        0.614       0.0609        0.113         0.17        0.194
    172   182        0.225        0.225     0.000102     0.000205          3.2         5.24       0.0668        0.112        0.158        0.158


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             172 17043.151    0.001       0.0185     0.000154     0.000456       0.0191        0.732          1.5       0.0737        0.137        0.182        0.236
! Validation        172 17043.151    0.001       0.0219     0.000203     0.000262       0.0224        0.784          1.6       0.0763        0.157        0.137        0.179
Wall time: 17043.152087293565
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    173   100       0.0322       0.0316     0.000398      0.00021          1.1         1.96        0.093         0.22        0.146         0.16
    173   200       0.0451       0.0448     0.000161     0.000175          1.2         2.34       0.0861         0.14        0.135        0.146
    173   300       0.0372       0.0291     0.000142      0.00797         1.06         1.89       0.0831        0.131        0.755        0.986
    173   400       0.0182       0.0179     6.85e-05     0.000217        0.882         1.48       0.0644       0.0914        0.123        0.163
    173   500      0.00719      0.00694     7.44e-05     0.000176        0.617        0.921        0.058       0.0953        0.129        0.146
    173   600      0.00542      0.00509     9.07e-05     0.000244        0.461        0.788        0.071        0.105        0.153        0.173
    173   700       0.0743        0.073     0.000261      0.00111         1.26         2.98        0.103        0.178        0.315        0.368
    173   800      0.00771      0.00659     0.000228     0.000892        0.557        0.897        0.104        0.167        0.274         0.33
    173   900       0.0203       0.0192     6.24e-05      0.00107        0.946         1.53        0.062       0.0873        0.354        0.361
    173  1000       0.0157       0.0154      0.00011     0.000151        0.863         1.37       0.0805        0.116        0.113        0.136
    173  1100         0.09       0.0881     0.000139       0.0017         1.92         3.28       0.0783         0.13         0.43        0.455
    173  1200        0.017       0.0162     9.95e-05      0.00067        0.785         1.41       0.0731         0.11        0.242        0.286
    173  1300       0.0103       0.0103     6.16e-05        7e-06        0.685         1.12       0.0543       0.0867       0.0251       0.0292
    173  1400       0.0058      0.00537     0.000243     0.000193        0.507        0.809       0.0866        0.172        0.153        0.153
    173  1500       0.0102      0.00876     8.34e-05      0.00134        0.682         1.03       0.0644        0.101        0.342        0.404
    173  1600      0.00573      0.00413     0.000102       0.0015        0.423         0.71       0.0648        0.112        0.376        0.427
    173  1700      0.00309      0.00287     0.000144     8.29e-05        0.409        0.591       0.0724        0.133       0.0842        0.101
    173  1800      0.00431      0.00403      8.8e-05     0.000192        0.479        0.701       0.0614        0.104         0.11        0.153
    173  1900       0.0118        0.011     0.000173     0.000694        0.577         1.16        0.086        0.145        0.283        0.291
    173  2000       0.0124        0.012     6.91e-05     0.000252         0.65         1.21       0.0622       0.0918        0.131        0.176
    173  2039      0.00353      0.00312     0.000135     0.000284        0.468        0.617       0.0941        0.128        0.139        0.186

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    173   100      0.00665        0.006      8.1e-05     0.000573         0.53        0.855       0.0618       0.0994        0.223        0.264
    173   182        0.155        0.155     0.000304     7.49e-05          2.7         4.34       0.0803        0.192       0.0956       0.0956


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             173 17142.271    0.001       0.0186     0.000156     0.000465       0.0192        0.736         1.51       0.0738        0.138        0.183        0.238
! Validation        173 17142.271    0.001       0.0193     0.000161     0.000298       0.0198        0.758         1.51       0.0767         0.14        0.148        0.191
Wall time: 17142.272201932967
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    174   100       0.0134       0.0127     8.77e-05     0.000585         0.76         1.25       0.0693        0.103         0.22        0.267
    174   200      0.00751      0.00665     0.000467     0.000397        0.552        0.901       0.0967        0.239        0.173         0.22
    174   300       0.0303       0.0294     0.000105     0.000746        0.863          1.9       0.0667        0.113        0.231        0.302
    174   400      0.00236      0.00178     0.000273     0.000306        0.361        0.467       0.0846        0.182        0.159        0.193
    174   500      0.00541      0.00525     0.000115     3.93e-05        0.563        0.801       0.0755        0.118       0.0554       0.0693
    174   600        0.031       0.0305     7.38e-05     0.000454            1         1.93       0.0606       0.0949        0.223        0.235
    174   700      0.00609      0.00591     5.22e-05     0.000121        0.515         0.85       0.0569       0.0798        0.096        0.122
    174   800       0.0625       0.0616     8.05e-05     0.000745         1.32         2.74       0.0619       0.0992        0.284        0.302
    174   900      0.00896      0.00811     7.75e-05     0.000771        0.608        0.995       0.0637       0.0973         0.27        0.307
    174  1000       0.0509       0.0507     0.000134     7.88e-05         1.35         2.49       0.0755        0.128        0.079       0.0981
    174  1100      0.00333      0.00272     0.000411     0.000202        0.408        0.576       0.0941        0.224         0.12        0.157
    174  1200       0.0254       0.0252     7.27e-05     8.36e-05        0.838         1.76       0.0505       0.0942       0.0849        0.101
    174  1300       0.0018      0.00143     8.81e-05     0.000282        0.355        0.418       0.0743        0.104         0.15        0.185
    174  1400      0.00813      0.00785     6.69e-05     0.000211        0.554        0.979       0.0635       0.0904        0.116         0.16
    174  1500      0.00491      0.00466     0.000113      0.00014        0.488        0.754       0.0709        0.117        0.105        0.131
    174  1600      0.00799      0.00692     0.000489     0.000579        0.603        0.919        0.111        0.244        0.228        0.266
    174  1700       0.0192       0.0187     0.000103     0.000336         0.93         1.51       0.0725        0.112        0.172        0.203
    174  1800      0.00663      0.00626     0.000136     0.000234        0.451        0.874        0.069        0.129        0.161        0.169
    174  1900       0.0338       0.0331      8.6e-05     0.000614         1.08         2.01       0.0722        0.102         0.23        0.274
    174  2000      0.00531      0.00462     9.48e-05     0.000587        0.478        0.751       0.0649        0.108        0.209        0.268
    174  2039     0.000799     0.000743     4.76e-05     8.85e-06        0.201        0.301       0.0432       0.0762       0.0311       0.0329

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    174   100      0.00521      0.00453       0.0001     0.000578        0.503        0.744       0.0568        0.111         0.23        0.266
    174   182        0.142        0.141     0.000138     0.000592         2.46         4.15       0.0559         0.13        0.269        0.269


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             174 17241.895    0.001        0.018     0.000156     0.000437       0.0186        0.729         1.48       0.0738        0.138        0.179        0.231
! Validation        174 17241.895    0.001       0.0201     0.000139     0.000354       0.0206        0.747         1.54       0.0678         0.13        0.162        0.208
Wall time: 17241.895949803293
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    175   100      0.00563      0.00547     9.82e-05     5.72e-05        0.476        0.817       0.0693        0.109       0.0758       0.0835
    175   200       0.0106       0.0104     8.54e-05     0.000187         0.69         1.12       0.0697        0.102        0.122        0.151
    175   300       0.0876       0.0874     0.000118     0.000127         1.32         3.27       0.0749         0.12          0.1        0.125
    175   400       0.0709       0.0705     8.26e-05     0.000249         1.22         2.93       0.0643          0.1        0.121        0.174
    175   500      0.00836      0.00788     0.000134     0.000355        0.594         0.98       0.0778        0.128        0.176        0.208
    175   600      0.00198       0.0018     7.87e-05     0.000104        0.299        0.468       0.0592        0.098       0.0947        0.113
    175   700       0.0116       0.0107     6.39e-05     0.000866        0.579         1.14       0.0573       0.0883        0.291        0.325
    175   800       0.0116       0.0112     9.09e-05     0.000298        0.686         1.17       0.0637        0.105        0.177        0.191
    175   900       0.0239       0.0236      0.00015      0.00022        0.888          1.7       0.0832        0.135        0.152        0.164
    175  1000       0.0317       0.0313      0.00012     0.000264         1.13         1.96       0.0819        0.121        0.149         0.18
    175  1100       0.0215       0.0208     8.17e-05     0.000607        0.869         1.59       0.0687       0.0999        0.207        0.272
    175  1200      0.00567        0.005     0.000189     0.000487         0.52        0.781       0.0912        0.152        0.205        0.244
    175  1300       0.0107       0.0102     0.000247     0.000233        0.653         1.12       0.0894        0.174        0.144        0.169
    175  1400       0.0239       0.0238     5.08e-05     4.93e-05        0.736          1.7       0.0539       0.0787       0.0713       0.0776
    175  1500      0.00526      0.00452     0.000103     0.000631        0.499        0.743       0.0726        0.112        0.214        0.278
    175  1600       0.0285       0.0283     6.24e-05     0.000218        0.769         1.86       0.0535       0.0873        0.123        0.163
    175  1700       0.0249       0.0245     7.15e-05     0.000347         1.05         1.73       0.0611       0.0935        0.174        0.206
    175  1800       0.0327       0.0322     6.93e-05     0.000427         0.94         1.98       0.0662        0.092        0.162        0.228
    175  1900      0.00561      0.00523     8.12e-05     0.000305        0.527        0.799       0.0639       0.0996        0.152        0.193
    175  2000       0.0164       0.0153     0.000532     0.000538        0.802         1.37       0.0887        0.255        0.205        0.256
    175  2039      0.00917      0.00912     4.48e-05     1.09e-05        0.733         1.05       0.0524        0.074       0.0321       0.0365

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    175   100      0.00609      0.00542     6.72e-05     0.000598        0.479        0.814       0.0585       0.0906        0.216         0.27
    175   182        0.146        0.146     0.000173     0.000326         2.64         4.22       0.0656        0.145        0.199        0.199


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             175 17341.133    0.001       0.0181     0.000154     0.000447       0.0187        0.726         1.48       0.0731        0.137         0.18        0.234
! Validation        175 17341.133    0.001       0.0194     0.000144     0.000361       0.0199        0.744         1.52       0.0715        0.133        0.154         0.21
Wall time: 17341.133804418147
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    176   100       0.0112       0.0109     6.91e-05     0.000169        0.711         1.15       0.0623       0.0918        0.108        0.144
    176   200      0.00566       0.0047     0.000369     0.000585        0.523        0.758        0.114        0.212        0.189        0.267
    176   300       0.0303       0.0301     0.000144     0.000112        0.902         1.92       0.0912        0.132       0.0964        0.117
    176   400        0.011       0.0102     0.000631     0.000163        0.832         1.12       0.0997        0.278        0.104        0.141
    176   500       0.0118       0.0116      6.9e-05     0.000205        0.542         1.19       0.0598       0.0918        0.133        0.158
    176   600      0.00963      0.00921     0.000112     0.000301        0.591         1.06       0.0733        0.117        0.185        0.192
    176   700        0.027       0.0262     0.000369     0.000438        0.971         1.79        0.105        0.212        0.179        0.231
    176   800      0.00309      0.00269     8.89e-05     0.000312        0.391        0.573       0.0679        0.104        0.194        0.195
    176   900       0.0164       0.0157     0.000261     0.000457         0.72         1.38       0.0818        0.178        0.201        0.236
    176  1000       0.0118       0.0112     9.17e-05     0.000538        0.709         1.17       0.0686        0.106         0.22        0.256
    176  1100       0.0532       0.0528     8.65e-05     0.000336         1.49         2.54       0.0689        0.103        0.165        0.203
    176  1200      0.00303      0.00217     0.000104     0.000758        0.402        0.515       0.0713        0.113        0.264        0.304
    176  1300        0.114        0.114     8.41e-05     0.000445         1.31         3.72       0.0627        0.101        0.222        0.233
    176  1400       0.0256       0.0253     0.000128     0.000172         1.03         1.76       0.0767        0.125        0.116        0.145
    176  1500         0.01       0.0091     0.000213     0.000694        0.696         1.05       0.0868        0.161        0.244        0.291
    176  1600       0.0561        0.056     5.82e-05     4.18e-05         1.26         2.61       0.0576       0.0843       0.0683       0.0715
    176  1700      0.00178       0.0013     6.73e-05      0.00041        0.261        0.398       0.0647       0.0906        0.142        0.224
    176  1800      0.00904      0.00876     6.67e-05     0.000211          0.6         1.03       0.0615       0.0902        0.117        0.161
    176  1900       0.0386       0.0383     0.000102     0.000155        0.902         2.16       0.0655        0.112        0.111        0.137
    176  2000      0.00373      0.00328     5.73e-05     0.000397        0.436        0.633       0.0564       0.0837        0.183         0.22
    176  2039       0.0203         0.02     0.000199     5.94e-05        0.861         1.56       0.0784        0.156       0.0784       0.0852

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    176   100      0.00423      0.00369      8.6e-05     0.000448        0.435        0.671       0.0559        0.102        0.202        0.234
    176   182        0.192        0.192     0.000188      0.00027         2.95         4.84       0.0689        0.151        0.182        0.182


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             176 17440.822    0.001       0.0183     0.000155     0.000419       0.0188        0.733         1.49       0.0742        0.137        0.174        0.226
! Validation        176 17440.822    0.001       0.0203     0.000157     0.000341       0.0208        0.749         1.54       0.0705        0.138        0.161        0.204
Wall time: 17440.82266431302
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    177   100       0.0726       0.0718     0.000123     0.000708         1.24         2.96       0.0721        0.122        0.252        0.294
    177   200       0.0141       0.0128     0.000285      0.00104        0.666         1.25       0.0809        0.187        0.341        0.356
    177   300       0.0084      0.00791     0.000104     0.000383        0.601        0.983       0.0805        0.113        0.209        0.216
    177   400        0.028       0.0272     0.000448     0.000337        0.899         1.82       0.0964        0.234        0.198        0.203
    177   500       0.0127       0.0124      4.2e-05     0.000316        0.609         1.23       0.0533       0.0716        0.184        0.196
    177   600       0.0185        0.018     7.51e-05     0.000421        0.723         1.48       0.0604       0.0957        0.185        0.227
    177   700       0.0564       0.0551     0.000303        0.001         1.19         2.59       0.0942        0.192        0.269         0.35
    177   800       0.0161       0.0148     6.46e-05      0.00118        0.702         1.35         0.06       0.0888        0.363        0.379
    177   900      0.00467      0.00434     0.000224     9.75e-05        0.562        0.728       0.0866        0.166        0.102        0.109
    177  1000      0.00442      0.00396     8.15e-05     0.000374        0.363        0.696       0.0626       0.0998         0.18        0.214
    177  1100       0.0142        0.014     8.43e-05     0.000143        0.653         1.31       0.0634        0.101        0.109        0.132
    177  1200      0.00811      0.00702     9.74e-05     0.000993        0.525        0.926       0.0638        0.109        0.285        0.348
    177  1300       0.0468       0.0463     0.000139     0.000306         1.18         2.38       0.0792         0.13        0.149        0.193
    177  1400       0.0365        0.036     0.000313     0.000197         1.02          2.1       0.0867        0.195        0.134        0.155
    177  1500       0.0181       0.0177     0.000119     0.000193        0.949         1.47       0.0787         0.12        0.127        0.153
    177  1600        0.019       0.0186     8.91e-05     0.000352        0.755         1.51       0.0698        0.104         0.17        0.207
    177  1700       0.0598       0.0587     0.000197      0.00094         1.33         2.68        0.083        0.155        0.311        0.339
    177  1800       0.0136       0.0131     6.11e-05     0.000422        0.694         1.27       0.0566       0.0864          0.2        0.227
    177  1900       0.0329       0.0318     0.000137     0.000977         1.18         1.97       0.0808        0.129        0.324        0.345
    177  2000      0.00179      0.00132     0.000233     0.000237        0.329        0.401        0.086        0.169        0.148         0.17
    177  2039       0.0799       0.0793     8.58e-05      0.00051         1.58         3.11       0.0617        0.102        0.246         0.25

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    177   100      0.00464      0.00379     6.13e-05     0.000784        0.496        0.681       0.0567       0.0865        0.226        0.309
    177   182        0.194        0.194     0.000207     0.000311         2.99         4.87       0.0715        0.159        0.195        0.195


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             177 17540.032    0.001       0.0179      0.00016     0.000463       0.0185        0.723         1.48       0.0739         0.14        0.182        0.238
! Validation        177 17540.032    0.001       0.0206     0.000199     0.000595       0.0214        0.777         1.56        0.076        0.156        0.212         0.27
Wall time: 17540.033024959266
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    178   100      0.00851      0.00823     4.11e-05     0.000238        0.642            1       0.0493       0.0709        0.154        0.171
    178   200      0.00218      0.00177     8.42e-05     0.000327        0.306        0.464         0.07        0.101        0.125          0.2
    178   300        0.029       0.0282     0.000147     0.000605        0.805         1.86        0.077        0.134        0.226        0.272
    178   400       0.0068      0.00653     0.000109     0.000159        0.586        0.893       0.0794        0.116        0.104        0.139
    178   500      0.00726      0.00686     8.18e-05     0.000323        0.537        0.915       0.0591       0.0999        0.153        0.199
    178   600      0.00806      0.00771     0.000127     0.000228        0.543         0.97        0.072        0.124        0.138        0.167
    178   700      0.00541      0.00515     8.24e-05     0.000181        0.498        0.793       0.0686          0.1        0.101        0.149
    178   800      0.00164     0.000958     6.12e-05     0.000624        0.251        0.342       0.0536       0.0864        0.253        0.276
    178   900       0.0109       0.0103     0.000123     0.000515         0.62         1.12       0.0778        0.123        0.235        0.251
    178  1000      0.00775      0.00679     0.000459     0.000506        0.538         0.91        0.103        0.237        0.195        0.249
    178  1100       0.0407       0.0405     0.000126     2.04e-05         1.15         2.22       0.0831        0.124       0.0368       0.0498
    178  1200       0.0119       0.0117     0.000113     0.000134        0.648         1.19       0.0707        0.118        0.104        0.128
    178  1300        0.003      0.00183     0.000151      0.00103        0.346        0.472       0.0784        0.136        0.336        0.354
    178  1400       0.0131       0.0124     5.32e-05      0.00069        0.659         1.23        0.054       0.0806        0.188         0.29
    178  1500       0.0303         0.03     4.89e-05     0.000284        0.807         1.91       0.0529       0.0772        0.159        0.186
    178  1600       0.0125       0.0121        6e-05     0.000283        0.682         1.22       0.0599       0.0856        0.155        0.186
    178  1700       0.0132       0.0128      5.5e-05     0.000375         0.78         1.25       0.0578       0.0819        0.162        0.214
    178  1800      0.00563      0.00524     9.56e-05     0.000297        0.485          0.8        0.072        0.108        0.157        0.191
    178  1900      0.00831      0.00681     0.000192      0.00131        0.565        0.912       0.0738        0.153        0.309        0.399
    178  2000      0.00772      0.00733     4.72e-05     0.000344        0.471        0.946       0.0508       0.0759        0.197        0.205
    178  2039       0.0102      0.00976     7.59e-05     0.000352        0.626         1.09       0.0565       0.0962        0.207        0.207

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    178   100        0.003      0.00258     0.000113     0.000304        0.376        0.562       0.0647        0.117        0.161        0.192
    178   182        0.171        0.171     0.000102     0.000178         2.74         4.57       0.0596        0.112        0.147        0.147


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             178 17639.470    0.001       0.0177     0.000161     0.000439       0.0183        0.724         1.47       0.0749         0.14        0.177        0.231
! Validation        178 17639.470    0.001       0.0203     0.000165      0.00037       0.0208        0.755         1.55       0.0739        0.142        0.168        0.213
Wall time: 17639.471363820136
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    179   100       0.0514       0.0508     0.000414      0.00014         1.08         2.49       0.0958        0.225        0.106        0.131
    179   200      0.00705       0.0066     5.54e-05     0.000396        0.526        0.898       0.0568       0.0822        0.203         0.22
    179   300       0.0131       0.0125     0.000243     0.000409        0.766         1.23       0.0888        0.172        0.168        0.223
    179   400      0.00359      0.00319      0.00011     0.000292        0.454        0.624       0.0738        0.116        0.159        0.189
    179   500       0.0254        0.024       0.0011      0.00031        0.998         1.71        0.128        0.366        0.147        0.195
    179   600        0.011       0.0108       0.0001     0.000103        0.641         1.15       0.0757        0.111       0.0758        0.112
    179   700       0.0179       0.0173     0.000149     0.000459        0.918         1.45       0.0836        0.135        0.213        0.237
    179   800       0.0399       0.0396     5.38e-05     0.000248        0.891          2.2       0.0523       0.0811        0.126        0.174
    179   900       0.0195       0.0191     0.000243     0.000179         1.03         1.53       0.0982        0.172        0.119        0.148
    179  1000        0.102        0.101     0.000235      0.00126         1.91         3.51        0.108         0.17        0.304        0.392
    179  1100        0.079        0.078      7.8e-05     0.000927          1.3         3.08       0.0703       0.0976        0.277        0.336
    179  1200       0.0117      0.00935     0.000121      0.00226        0.654         1.07       0.0808        0.121        0.372        0.526
    179  1300      0.00529      0.00452     8.26e-05     0.000689        0.482        0.743       0.0662          0.1        0.274         0.29
    179  1400       0.0199       0.0194     9.52e-05     0.000432        0.924         1.54       0.0694        0.108        0.164         0.23
    179  1500      0.00122     0.000835      8.8e-05     0.000295        0.246        0.319       0.0613        0.104        0.157         0.19
    179  1600      0.00291      0.00249     9.16e-05     0.000335        0.385        0.551       0.0704        0.106         0.18        0.202
    179  1700      0.00151      0.00086     5.62e-05     0.000595        0.233        0.324       0.0567       0.0828        0.225         0.27
    179  1800       0.0199       0.0195     9.07e-05     0.000309         1.03         1.54       0.0656        0.105         0.18        0.194
    179  1900      0.00182      0.00157     4.07e-05     0.000213         0.31        0.437       0.0486       0.0704        0.151        0.161
    179  2000       0.0512       0.0506     9.96e-05     0.000453         1.25         2.49       0.0699         0.11        0.217        0.235
    179  2039       0.0261       0.0259     6.66e-05     0.000195         1.14         1.78       0.0632       0.0902        0.115        0.154

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    179   100      0.00539      0.00511     6.69e-05     0.000216        0.504         0.79       0.0552       0.0904        0.125        0.163
    179   182        0.177        0.176     0.000127      0.00111         2.71         4.63       0.0606        0.125        0.368        0.368


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             179 17738.886    0.001       0.0178     0.000168     0.000433       0.0184        0.724         1.47       0.0752        0.143        0.176         0.23
! Validation        179 17738.886    0.001       0.0189     0.000128     0.000465       0.0195         0.72         1.49       0.0664        0.125        0.192        0.238
Wall time: 17738.886743836105
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    180   100      0.00834        0.007     0.000272      0.00107        0.594        0.924        0.105        0.182        0.338        0.361
    180   200      0.00715      0.00632     0.000425     0.000402        0.657        0.879         0.12        0.228         0.17        0.222
    180   300      0.00149      0.00137     3.34e-05     8.81e-05         0.31        0.409       0.0475       0.0639       0.0831        0.104
    180   400       0.0239       0.0236     8.99e-05     0.000214        0.772          1.7       0.0715        0.105        0.137        0.162
    180   500      0.00647      0.00588     9.59e-05     0.000488        0.578        0.847       0.0744        0.108         0.23        0.244
    180   600      0.00315       0.0022     0.000462     0.000486        0.353        0.518       0.0896        0.237         0.16        0.244
    180   700       0.0161       0.0159     5.98e-05     0.000189        0.857         1.39       0.0563       0.0855        0.129        0.152
    180   800      0.00484      0.00456     8.81e-05     0.000195        0.473        0.746        0.066        0.104        0.112        0.154
    180   900       0.0384       0.0367     0.000286      0.00141         1.02         2.12       0.0978        0.187        0.377        0.416
    180  1000       0.0259       0.0256     0.000112     0.000215        0.878         1.77       0.0696        0.117        0.119        0.162
    180  1100       0.0073        0.007     0.000115     0.000182        0.551        0.925       0.0818        0.119        0.123        0.149
    180  1200      0.00345      0.00301     0.000151     0.000295        0.386        0.606        0.078        0.136        0.175         0.19
    180  1300       0.0244       0.0238     0.000268     0.000346        0.976          1.7       0.0931        0.181         0.17        0.205
    180  1400      0.00538       0.0049     0.000147     0.000333        0.449        0.773       0.0755        0.134        0.146        0.202
    180  1500       0.0084      0.00778     7.52e-05     0.000538        0.522        0.975       0.0616       0.0958        0.246        0.256
    180  1600      0.00368      0.00277     6.17e-05      0.00085        0.371        0.581       0.0591       0.0868        0.293        0.322
    180  1700       0.0112       0.0101     5.94e-05      0.00104        0.624         1.11       0.0574       0.0852        0.284        0.356
    180  1800        0.034        0.033     0.000114     0.000944        0.948         2.01       0.0778        0.118         0.23         0.34
    180  1900       0.0246       0.0237     8.91e-05     0.000852        0.839          1.7       0.0663        0.104        0.277        0.322
    180  2000      0.00155      0.00139     6.88e-05     9.07e-05         0.29        0.412       0.0556       0.0917       0.0972        0.105
    180  2039        0.159        0.159     0.000123     0.000343         2.15          4.4       0.0827        0.123        0.184        0.205

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    180   100      0.00544      0.00445     6.09e-05     0.000931        0.432        0.737       0.0545       0.0862         0.22        0.337
    180   182        0.164        0.164     4.75e-05     5.05e-05          2.7         4.47       0.0521       0.0761       0.0785       0.0785


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             180 17838.532    0.001       0.0178     0.000158      0.00045       0.0184        0.722         1.47       0.0738        0.139        0.181        0.234
! Validation        180 17838.532    0.001       0.0197     0.000146     0.000616       0.0205        0.757         1.53       0.0728        0.134        0.216        0.275
Wall time: 17838.533336751163
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    181   100      0.00647      0.00607     7.96e-05     0.000315        0.562        0.861       0.0655       0.0986        0.137        0.196
    181   200      0.00539      0.00514     0.000104     0.000154        0.565        0.792       0.0799        0.113         0.12        0.137
    181   300       0.0172       0.0162     0.000243      0.00075        0.781         1.41       0.0897        0.172        0.222        0.303
    181   400      0.00659      0.00641     7.58e-05     9.94e-05        0.505        0.885       0.0602       0.0962        0.105         0.11
    181   500       0.0229       0.0227     6.71e-05     0.000111        0.908         1.67       0.0559       0.0905        0.103        0.117
    181   600       0.0113        0.011     0.000111     0.000232        0.623         1.16       0.0726        0.117        0.141        0.168
    181   700       0.0253       0.0244     5.99e-05     0.000787        0.814         1.73       0.0597       0.0855        0.302         0.31
    181   800       0.0296       0.0291     6.69e-05     0.000412         1.05         1.89       0.0619       0.0904        0.197        0.224
    181   900      0.00752      0.00704     0.000172     0.000309        0.547        0.927       0.0693        0.145        0.137        0.194
    181  1000        0.016       0.0156     0.000132     0.000201        0.737         1.38       0.0775        0.127       0.0956        0.156
    181  1100       0.0187       0.0183     5.61e-05     0.000324        0.681         1.49       0.0562       0.0828        0.148        0.199
    181  1200       0.0296       0.0292     5.39e-05     0.000314        0.925         1.89        0.055       0.0812        0.178        0.196
    181  1300      0.00262      0.00168     8.83e-05     0.000852        0.289        0.453       0.0727        0.104        0.229        0.323
    181  1400       0.0139       0.0119     0.000205      0.00182        0.633          1.2       0.0852        0.158        0.397        0.471
    181  1500      0.00139      0.00111     6.45e-05     0.000224        0.255        0.367       0.0624       0.0887        0.111        0.166
    181  1600      0.00309       0.0029     0.000117     7.56e-05        0.372        0.595       0.0755        0.119       0.0807       0.0961
    181  1700       0.0198       0.0194     7.23e-05     0.000364        0.807         1.54       0.0687       0.0939        0.203        0.211
    181  1800        0.018       0.0178     6.46e-05     0.000179        0.596         1.47       0.0536       0.0888        0.129        0.148
    181  1900      0.00134     0.000721     0.000369     0.000255        0.239        0.297       0.0896        0.212        0.129        0.176
    181  2000       0.0148        0.013     9.64e-05      0.00164        0.792         1.26       0.0753        0.108        0.346        0.447
    181  2039       0.0075      0.00733     4.69e-05     0.000124        0.577        0.946       0.0461       0.0757        0.123        0.123

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    181   100      0.00613      0.00579     8.29e-05     0.000264        0.498         0.84        0.061        0.101         0.15         0.18
    181   182        0.123        0.123     0.000149     0.000242         2.37         3.87        0.066        0.135        0.172        0.172


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             181 17938.040    0.001       0.0177     0.000161     0.000421       0.0183        0.724         1.47       0.0752         0.14        0.174        0.227
! Validation        181 17938.040    0.001       0.0201     0.000153     0.000254       0.0205         0.75         1.55       0.0736        0.137        0.137        0.176
Wall time: 17938.04081197083
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    182   100      0.00437      0.00414     0.000164     6.73e-05        0.542        0.711       0.0877        0.141       0.0723       0.0906
    182   200       0.0369       0.0362     0.000111     0.000569         1.13          2.1       0.0767        0.116        0.194        0.264
    182   300      0.00692       0.0067     9.24e-05     0.000131        0.625        0.904       0.0742        0.106         0.11        0.126
    182   400       0.0822        0.081     0.000122      0.00103         1.46         3.15       0.0844        0.122        0.297        0.354
    182   500       0.0649       0.0638     6.75e-05      0.00109        0.954         2.79       0.0687       0.0908        0.287        0.365
    182   600       0.0906       0.0892      0.00038      0.00108         1.83          3.3       0.0895        0.215        0.307        0.363
    182   700      0.00478      0.00429     7.32e-05     0.000422        0.438        0.724       0.0668       0.0945        0.218        0.227
    182   800        0.015       0.0148     7.72e-05     6.27e-05        0.835         1.35       0.0671        0.097       0.0714       0.0875
    182   900      0.00777      0.00713     0.000322     0.000314        0.587        0.933        0.104        0.198        0.157        0.196
    182  1000       0.0104      0.00978     0.000162     0.000422        0.692         1.09       0.0767        0.141        0.197        0.227
    182  1100      0.00269      0.00183     0.000518     0.000342        0.351        0.473        0.116        0.252        0.195        0.204
    182  1200       0.0086      0.00813     0.000111      0.00036        0.545        0.996       0.0798        0.117        0.192         0.21
    182  1300      0.00208      0.00188      6.5e-05     0.000132        0.345        0.479       0.0554       0.0891        0.101        0.127
    182  1400       0.0044     0.000909      4.5e-05      0.00344        0.246        0.333        0.046       0.0741        0.581        0.648
    182  1500      0.00981      0.00951     8.65e-05      0.00021        0.689         1.08       0.0697        0.103        0.141         0.16
    182  1600        0.038       0.0378     8.98e-05     0.000162         1.07         2.15       0.0663        0.105         0.12        0.141
    182  1700       0.0176       0.0174     3.24e-05     0.000175        0.734         1.46       0.0436       0.0628        0.124        0.146
    182  1800       0.0185       0.0184     6.95e-05     5.12e-05        0.876          1.5       0.0611       0.0921       0.0523       0.0791
    182  1900       0.0352       0.0338     3.72e-05      0.00129         1.09         2.03       0.0501       0.0674        0.372        0.398
    182  2000       0.0202       0.0195     0.000242     0.000501        0.901         1.54        0.097        0.172        0.215        0.247
    182  2039        0.039       0.0378     0.000468       0.0007         1.41         2.15        0.116        0.239         0.29        0.292

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    182   100      0.00491      0.00406     6.64e-05     0.000778        0.453        0.704       0.0569       0.0901        0.261        0.308
    182   182        0.127        0.127     3.74e-05     7.51e-05         2.37         3.94       0.0487       0.0676       0.0958       0.0958


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             182 18037.272    0.001       0.0173     0.000162     0.000415       0.0179        0.718         1.45       0.0751         0.14        0.172        0.225
! Validation        182 18037.272    0.001       0.0194     0.000149     0.000506         0.02        0.727         1.52       0.0715        0.135        0.199        0.249
Wall time: 18037.27270063758
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    183   100      0.00338      0.00304     0.000138     0.000207        0.372        0.609       0.0829         0.13        0.137        0.159
    183   200       0.0127       0.0125     7.55e-05      0.00011        0.768         1.23       0.0611        0.096       0.0988        0.116
    183   300      0.00674      0.00641     8.65e-05     0.000249         0.49        0.885       0.0648        0.103        0.135        0.174
    183   400       0.0488       0.0474     0.000121      0.00119         1.27         2.41       0.0789        0.122        0.374        0.381
    183   500      0.00333      0.00234     0.000122     0.000872        0.339        0.534       0.0753        0.122        0.319        0.326
    183   600       0.0107       0.0103     5.45e-05     0.000337        0.614         1.12        0.053       0.0816        0.182        0.203
    183   700       0.0143       0.0135     0.000469     0.000307        0.782         1.28        0.121        0.239        0.118        0.193
    183   800      0.00626      0.00594     6.72e-05     0.000254        0.509        0.852       0.0611       0.0906        0.134        0.176
    183   900        0.012       0.0117     0.000284     3.43e-05        0.897          1.2        0.101        0.186       0.0586       0.0647
    183  1000      0.00113     0.000904     0.000116     0.000112        0.263        0.332       0.0793        0.119        0.115        0.117
    183  1100       0.0173       0.0166     0.000181     0.000532        0.832         1.42       0.0833        0.149         0.25        0.255
    183  1200      0.00385      0.00353     0.000188     0.000127        0.509        0.657       0.0899        0.152        0.102        0.125
    183  1300       0.0198       0.0192     8.79e-05     0.000474        0.766         1.53        0.069        0.104        0.207         0.24
    183  1400       0.0249       0.0241     8.24e-05     0.000698        0.791         1.72       0.0682          0.1        0.163        0.292
    183  1500      0.00162      0.00106     3.32e-05     0.000523        0.235        0.361       0.0434       0.0636        0.214        0.253
    183  1600      0.00937      0.00859     0.000388     0.000392         0.75         1.02        0.095        0.218        0.201        0.219
    183  1700      0.00788       0.0074     0.000376     0.000102        0.619        0.951       0.0976        0.214       0.0994        0.111
    183  1800       0.0101      0.00973     0.000172     0.000235        0.758         1.09       0.0853        0.145        0.149        0.169
    183  1900       0.0257       0.0252      0.00022     0.000245         1.02         1.75       0.0996        0.164        0.148        0.173
    183  2000      0.00369      0.00325     4.61e-05       0.0004        0.428         0.63       0.0531        0.075         0.21        0.221
    183  2039       0.0135       0.0133     8.33e-05     0.000112        0.719         1.27       0.0611        0.101        0.113        0.117

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    183   100       0.0063      0.00549     7.09e-05     0.000739         0.52        0.818       0.0641        0.093        0.242          0.3
    183   182        0.146        0.145     9.14e-05     0.000184         2.49         4.21       0.0605        0.106         0.15         0.15


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             183 18136.515    0.001       0.0175     0.000161     0.000421       0.0181        0.724         1.46       0.0748         0.14        0.173        0.227
! Validation        183 18136.515    0.001       0.0214     0.000161     0.000457        0.022        0.789          1.6       0.0754         0.14        0.173        0.237
Wall time: 18136.516387298703
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    184   100      0.00291      0.00255     0.000137     0.000227        0.411        0.558       0.0737         0.13         0.14        0.167
    184   200       0.0132        0.013     6.45e-05     0.000228        0.666         1.26        0.062       0.0888        0.135        0.167
    184   300       0.0082      0.00797     0.000104     0.000121        0.708        0.986       0.0614        0.113        0.106        0.121
    184   400       0.0099      0.00961     7.62e-05     0.000211        0.484         1.08       0.0627       0.0965        0.151        0.161
    184   500       0.0163       0.0161     9.29e-05     0.000139        0.717          1.4        0.068        0.107        0.096         0.13
    184   600      0.00191     0.000845     0.000102     0.000963        0.253        0.321       0.0748        0.112        0.321        0.343
    184   700      0.00488      0.00449     0.000105     0.000277        0.459        0.741       0.0713        0.113        0.162        0.184
    184   800      0.00475      0.00446     0.000163     0.000122        0.577        0.738       0.0868        0.141        0.106        0.122
    184   900       0.0938       0.0934      7.6e-05      0.00025         1.59         3.38       0.0588       0.0963        0.165        0.175
    184  1000       0.0229       0.0225     0.000112     0.000271        0.944         1.66        0.078        0.117        0.167        0.182
    184  1100      0.00546      0.00414     6.54e-05      0.00126        0.487        0.711       0.0563       0.0894        0.319        0.392
    184  1200        0.023       0.0228     7.42e-05     0.000125         0.76         1.67       0.0615       0.0952        0.117        0.123
    184  1300       0.0254       0.0251     0.000206     7.91e-05        0.852         1.75       0.0824        0.159       0.0883       0.0982
    184  1400       0.0389       0.0374     0.000427      0.00114          1.1         2.14         0.12        0.228        0.351        0.372
    184  1500      0.00318       0.0027     0.000112     0.000369         0.38        0.574       0.0673        0.117          0.2        0.212
    184  1600      0.00606      0.00584     0.000171     4.63e-05        0.556        0.845        0.082        0.144       0.0568       0.0751
    184  1700       0.0346       0.0342      0.00023     0.000169         1.02         2.04       0.0871        0.168        0.127        0.144
    184  1800      0.00913      0.00893     7.81e-05     0.000126        0.606         1.04       0.0667       0.0977       0.0883        0.124
    184  1900        0.014       0.0131     5.28e-05     0.000899        0.757         1.26       0.0551       0.0803        0.323        0.331
    184  2000       0.0208       0.0207     6.97e-05     6.08e-05        0.872         1.59        0.063       0.0923       0.0769       0.0862
    184  2039       0.0149       0.0133     0.000733     0.000915        0.777         1.27        0.125        0.299        0.253        0.334

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    184   100      0.00864      0.00829     8.15e-05     0.000268        0.615         1.01        0.062       0.0997        0.163        0.181
    184   182         0.12         0.12     5.46e-05      0.00022          2.3         3.83       0.0528       0.0817        0.164        0.164


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             184 18235.821    0.001       0.0183     0.000163     0.000443       0.0189        0.733         1.49        0.076        0.141        0.178        0.233
! Validation        184 18235.821    0.001       0.0218     0.000179     0.000372       0.0223        0.803         1.61        0.076        0.148        0.166        0.213
Wall time: 18235.8219813779
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    185   100       0.0222       0.0216     0.000149     0.000443        0.943         1.63       0.0844        0.135        0.217        0.232
    185   200       0.0261       0.0255     0.000177      0.00041        0.955         1.76       0.0906        0.147        0.204        0.224
    185   300      0.00919      0.00835     8.73e-05     0.000752        0.665         1.01       0.0653        0.103        0.218        0.303
    185   400      0.00308      0.00298     9.68e-05     4.77e-06        0.317        0.603       0.0664        0.109       0.0213       0.0241
    185   500        0.018       0.0177     0.000139     0.000185        0.871         1.47       0.0743         0.13        0.118         0.15
    185   600       0.0161        0.016     8.37e-05     7.24e-05        0.702          1.4       0.0661        0.101       0.0855        0.094
    185   700       0.0158       0.0145     0.000724     0.000521         0.85         1.33         0.12        0.297        0.232        0.252
    185   800      0.00561      0.00521     3.38e-05     0.000373        0.455        0.797       0.0447       0.0642        0.191        0.213
    185   900       0.0151       0.0147     9.21e-05     0.000258        0.812         1.34       0.0708        0.106         0.14        0.178
    185  1000       0.0131       0.0124     0.000476     0.000196        0.886         1.23        0.103        0.241        0.134        0.155
    185  1100      0.00272       0.0011     0.000546      0.00107        0.236        0.367       0.0859        0.258        0.268        0.362
    185  1200      0.00602      0.00514     0.000172     0.000704        0.472        0.792       0.0646        0.145        0.264        0.293
    185  1300      0.00161      0.00138     5.87e-05     0.000172        0.243         0.41       0.0554       0.0847        0.117        0.145
    185  1400      0.00649      0.00602     0.000148      0.00032        0.603        0.857       0.0758        0.134        0.177        0.197
    185  1500      0.00609      0.00517     6.81e-05     0.000857        0.477        0.794       0.0599       0.0912         0.29        0.324
    185  1600      0.00268       0.0023     0.000163     0.000218        0.354         0.53       0.0822        0.141         0.13        0.163
    185  1700      0.00562      0.00517     5.39e-05     0.000396        0.508        0.795       0.0547       0.0811        0.206         0.22
    185  1800        0.003      0.00207     8.46e-05     0.000846        0.376        0.502        0.063        0.102        0.305        0.321
    185  1900       0.0155       0.0148     9.38e-05     0.000531        0.617         1.35       0.0642        0.107        0.248        0.255
    185  2000      0.00953      0.00919     7.59e-05     0.000273        0.526         1.06       0.0572       0.0963        0.142        0.182
    185  2039       0.0955       0.0931     0.000112      0.00223         2.13         3.37       0.0805        0.117        0.414        0.522

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    185   100      0.00681      0.00576     0.000171     0.000882        0.483        0.839       0.0686        0.144        0.259        0.328
    185   182         0.15        0.149     0.000161     0.000164         2.51         4.27       0.0644         0.14        0.141        0.141


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             185 18335.440    0.001       0.0182     0.000161     0.000442       0.0188        0.732         1.49       0.0741         0.14        0.178        0.232
! Validation        185 18335.440    0.001       0.0195     0.000172     0.000489       0.0201        0.747         1.52       0.0764        0.145        0.187        0.245
Wall time: 18335.441061638296
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    186   100      0.00158      0.00145     5.74e-05     7.54e-05        0.266         0.42       0.0528       0.0837        0.086       0.0959
    186   200      0.00158      0.00132     5.23e-05     0.000205        0.311        0.402       0.0545       0.0799        0.125        0.158
    186   300       0.0112       0.0109     0.000138     0.000146        0.721         1.15       0.0735         0.13        0.127        0.134
    186   400       0.0014     0.000937     5.79e-05     0.000401        0.235        0.338       0.0552       0.0841        0.173        0.221
    186   500       0.0192       0.0178     0.000202      0.00124        0.793         1.47       0.0982        0.157        0.302         0.39
    186   600      0.00123      0.00108     6.02e-05     9.71e-05        0.281        0.362       0.0614       0.0857        0.077        0.109
    186   700       0.0127       0.0111     0.000747     0.000831        0.763         1.17         0.14        0.302        0.219        0.319
    186   800       0.0141       0.0126     0.000345      0.00111        0.838         1.24        0.118        0.205        0.286        0.368
    186   900       0.0327       0.0323     0.000124     0.000239         1.24         1.99       0.0771        0.123        0.134        0.171
    186  1000       0.0262       0.0256      0.00013     0.000469         1.07         1.77       0.0793        0.126        0.178        0.239
    186  1100       0.0211       0.0208     0.000111     0.000177        0.898         1.59       0.0807        0.116        0.139        0.147
    186  1200       0.0136       0.0126     8.87e-05     0.000936        0.722         1.24        0.066        0.104        0.308        0.338
    186  1300      0.00352      0.00302     6.55e-05     0.000433        0.425        0.607       0.0604       0.0894        0.164         0.23
    186  1400        0.037       0.0359     0.000261     0.000918         1.03         2.09       0.0971        0.179        0.254        0.335
    186  1500       0.0281       0.0278     0.000145     0.000199        0.892         1.84       0.0874        0.133        0.115        0.156
    186  1600      0.00876      0.00845     6.15e-05     0.000246        0.559         1.02       0.0608       0.0866        0.138        0.173
    186  1700      0.00213      0.00165      2.7e-05     0.000455        0.331        0.449       0.0413       0.0574        0.226        0.236
    186  1800       0.0199       0.0191     0.000629     0.000221        0.982         1.53        0.132        0.277        0.152        0.164
    186  1900       0.0313       0.0311        8e-05     0.000163        0.959         1.95       0.0643       0.0988         0.12        0.141
    186  2000       0.0182        0.018     9.46e-05     0.000118        0.699         1.48       0.0675        0.107        0.109         0.12
    186  2039      0.00609      0.00443     0.000593      0.00106        0.438        0.736        0.123        0.269        0.345         0.36

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    186   100      0.00516      0.00485     6.48e-05     0.000251        0.484        0.769       0.0558       0.0889        0.139        0.175
    186   182        0.129        0.128     4.92e-05     0.000128         2.36         3.96       0.0523       0.0775        0.125        0.125


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             186 18435.137    0.001        0.018     0.000162     0.000432       0.0186        0.728         1.48       0.0759        0.141        0.176         0.23
! Validation        186 18435.137    0.001       0.0203     0.000127     0.000409       0.0208        0.745         1.56        0.069        0.125        0.167        0.224
Wall time: 18435.138181962073
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    187   100       0.0162       0.0155     5.17e-05     0.000653        0.655         1.38       0.0566       0.0794        0.276        0.282
    187   200       0.0062       0.0059     9.22e-05     0.000212        0.487        0.848       0.0661        0.106        0.153        0.161
    187   300      0.00208      0.00162     8.26e-05     0.000384        0.331        0.444       0.0638          0.1        0.167        0.217
    187   400      0.00308      0.00292     7.94e-05     7.89e-05        0.353        0.598       0.0673       0.0984       0.0969       0.0982
    187   500      0.00318      0.00232     0.000261     0.000592         0.37        0.533       0.0823        0.179         0.24        0.269
    187   600       0.0203         0.02     0.000201     9.24e-05         0.85         1.56       0.0853        0.157       0.0868        0.106
    187   700      0.00555      0.00492     0.000245     0.000376        0.588        0.775       0.0985        0.173        0.155        0.214
    187   800      0.00782      0.00717     7.94e-05     0.000572        0.447        0.936       0.0634       0.0984        0.241        0.264
    187   900      0.00795      0.00712     0.000443     0.000381        0.546        0.932        0.103        0.232        0.126        0.216
    187  1000       0.0218         0.02     0.000477      0.00127        0.922         1.56        0.111        0.241        0.336        0.394
    187  1100       0.0621       0.0602      0.00128     0.000597         1.57         2.71         0.14        0.396        0.251         0.27
    187  1200      0.00931      0.00866     0.000367     0.000284        0.607         1.03        0.097        0.212        0.153        0.186
    187  1300       0.0136       0.0121     0.000107      0.00136        0.622         1.22       0.0694        0.114        0.357        0.407
    187  1400       0.0248       0.0228     0.000133      0.00188        0.924         1.67        0.084        0.127        0.313        0.479
    187  1500      0.00436      0.00413     5.83e-05     0.000174        0.418         0.71       0.0594       0.0844        0.115        0.146
    187  1600      0.00503      0.00461      0.00024     0.000174        0.535        0.751        0.077        0.171        0.123        0.146
    187  1700       0.0227       0.0219     6.56e-05     0.000795        0.963         1.63       0.0588       0.0895        0.236        0.311
    187  1800      0.00254      0.00223     5.31e-05     0.000251        0.346        0.522       0.0554       0.0805         0.15        0.175
    187  1900      0.00316      0.00265     0.000104     0.000407        0.398        0.568       0.0684        0.112        0.217        0.223
    187  2000      0.00326      0.00238     9.99e-05     0.000778        0.333        0.539        0.069         0.11        0.238        0.308
    187  2039      0.00831      0.00668      0.00052      0.00111        0.703        0.903       0.0988        0.252        0.287        0.368

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    187   100      0.00612      0.00558     8.89e-05     0.000446        0.547        0.826       0.0613        0.104        0.189        0.233
    187   182        0.155        0.155     8.84e-05     0.000127          2.6         4.35       0.0616        0.104        0.124        0.124


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             187 18534.200    0.001       0.0175     0.000162     0.000433       0.0181        0.721         1.46       0.0758        0.141        0.177         0.23
! Validation        187 18534.200    0.001       0.0209      0.00018      0.00037       0.0214        0.772         1.57       0.0783        0.149        0.165        0.213
Wall time: 18534.200727544725
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    188   100        0.008      0.00764     7.09e-05     0.000285        0.583        0.966       0.0626        0.093        0.154        0.186
    188   200      0.00254      0.00226     6.43e-05     0.000217        0.353        0.526       0.0591       0.0886        0.133        0.163
    188   300      0.00446      0.00337     0.000111      0.00097        0.412        0.642       0.0775        0.117        0.274        0.344
    188   400       0.0504       0.0499     0.000155     0.000334         1.27         2.47       0.0868        0.138        0.174        0.202
    188   500       0.0198       0.0188     7.07e-05      0.00096         0.86         1.52       0.0632       0.0929        0.251        0.342
    188   600      0.00769      0.00741      4.5e-05     0.000233        0.569        0.951        0.055       0.0741        0.161        0.169
    188   700       0.0201       0.0195     0.000107     0.000434        0.921         1.54       0.0744        0.114        0.187         0.23
    188   800      0.00463      0.00425     8.47e-05     0.000297        0.464         0.72       0.0688        0.102        0.149         0.19
    188   900       0.0151       0.0143     5.02e-05     0.000728        0.564         1.32       0.0549       0.0783        0.278        0.298
    188  1000       0.0349       0.0347     8.67e-05     0.000124        0.839         2.06       0.0658        0.103        0.111        0.123
    188  1100       0.0322        0.032     0.000109     0.000159        0.902         1.98       0.0774        0.115        0.127        0.139
    188  1200      0.00153      0.00116       0.0001     0.000268        0.285        0.376       0.0721        0.111        0.137        0.181
    188  1300      0.00142      0.00122     8.66e-05     0.000115        0.291        0.385       0.0658        0.103        0.101        0.118
    188  1400       0.0343       0.0332     0.000233     0.000857         1.13         2.01       0.0872        0.169        0.259        0.323
    188  1500      0.00631      0.00591     0.000314      8.9e-05        0.643         0.85       0.0966        0.196       0.0696        0.104
    188  1600       0.0177       0.0172     8.21e-05     0.000366        0.776         1.45        0.071          0.1        0.179        0.211
    188  1700      0.00321      0.00294        6e-05     0.000217        0.428        0.599       0.0594       0.0856        0.134        0.163
    188  1800       0.0282       0.0276     0.000133      0.00048        0.956         1.83       0.0805        0.127        0.192        0.242
    188  1900       0.0544       0.0537     0.000137     0.000514         1.16         2.56       0.0712        0.129        0.189         0.25
    188  2000      0.00856      0.00817     4.51e-05     0.000342          0.5        0.999       0.0536       0.0742        0.164        0.204
    188  2039      0.00857      0.00849     5.48e-05     1.95e-05        0.763         1.02       0.0563       0.0818       0.0469       0.0488

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    188   100      0.00346      0.00297     9.32e-05     0.000392        0.384        0.602       0.0615        0.107        0.178        0.219
    188   182        0.186        0.186     5.39e-05     2.67e-05         2.82         4.76       0.0523       0.0811       0.0571       0.0571


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             188 18633.524    0.001       0.0177     0.000162     0.000457       0.0183        0.727         1.47       0.0762        0.141         0.18        0.236
! Validation        188 18633.524    0.001       0.0224     0.000162     0.000402       0.0229        0.819         1.62       0.0741        0.141         0.17        0.222
Wall time: 18633.524928815663
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    189   100      0.00461      0.00407     8.26e-05     0.000453        0.403        0.705       0.0648          0.1        0.181        0.235
    189   200       0.0147       0.0144     5.38e-05     0.000172        0.655         1.33       0.0555        0.081        0.109        0.145
    189   300      0.00291      0.00282     5.56e-05     3.21e-05        0.372        0.587       0.0602       0.0824       0.0586       0.0626
    189   400      0.00849      0.00791     0.000165      0.00042        0.654        0.983       0.0911        0.142        0.202        0.226
    189   500      0.00898      0.00796     0.000218     0.000805        0.643        0.986        0.097        0.163        0.276        0.313
    189   600      0.00515      0.00439     0.000238     0.000518        0.481        0.732        0.111         0.17        0.221        0.252
    189   700      0.00789      0.00747     0.000367     5.53e-05        0.736        0.955        0.109        0.212       0.0671       0.0822
    189   800      0.00737       0.0072     0.000129     3.45e-05        0.546        0.938       0.0886        0.125       0.0481       0.0649
    189   900       0.0365        0.036     0.000128     0.000393         1.15          2.1       0.0748        0.125        0.213        0.219
    189  1000      0.00737      0.00722      5.9e-05      9.1e-05        0.575        0.939       0.0558       0.0849        0.081        0.105
    189  1100       0.0138       0.0133     9.35e-05      0.00032        0.842         1.28        0.074        0.107        0.174        0.198
    189  1200       0.0104      0.00999     5.95e-05     0.000342         0.54          1.1       0.0557       0.0852          0.2        0.204
    189  1300       0.0045      0.00403     8.69e-05     0.000385        0.449        0.701       0.0703        0.103        0.187        0.217
    189  1400      0.00736      0.00718     0.000101     7.49e-05        0.566        0.936       0.0639        0.111       0.0816       0.0956
    189  1500      0.00637      0.00507      0.00023      0.00107        0.504        0.787       0.0846        0.168        0.356        0.361
    189  1600      0.00437      0.00368     0.000146      0.00055         0.45         0.67       0.0718        0.133        0.216        0.259
    189  1700       0.0274       0.0272     6.32e-05      0.00014        0.972         1.82       0.0582       0.0879        0.109        0.131
    189  1800        0.012       0.0112     0.000139     0.000642        0.758         1.17       0.0898         0.13        0.189         0.28
    189  1900      0.00252      0.00208      5.2e-05     0.000389        0.352        0.504       0.0552       0.0796        0.178        0.218
    189  2000      0.00235      0.00147     0.000127     0.000748        0.306        0.424       0.0828        0.124        0.285        0.302
    189  2039      0.00486      0.00449     8.61e-05      0.00028        0.613        0.741       0.0735        0.103        0.156        0.185

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    189   100      0.00579      0.00534     6.33e-05     0.000389        0.501        0.807       0.0593       0.0879        0.199        0.218
    189   182        0.306        0.306     0.000326     0.000299         3.67         6.11       0.0917          0.2        0.191        0.191


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             189 18732.551    0.001       0.0172     0.000162     0.000406       0.0178        0.715         1.45       0.0754         0.14        0.172        0.223
! Validation        189 18732.551    0.001       0.0214     0.000159     0.000324       0.0219         0.78         1.57       0.0751        0.139        0.155        0.199
Wall time: 18732.552597090602
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    190   100      0.00349      0.00304     0.000103     0.000343        0.488        0.609       0.0681        0.112        0.156        0.205
    190   200       0.0206         0.02     7.35e-05     0.000506        0.857         1.56       0.0672       0.0947         0.24        0.249
    190   300      0.00241      0.00219      8.4e-05     0.000137        0.376        0.516       0.0688        0.101        0.116        0.129
    190   400       0.0171       0.0156     8.07e-05      0.00144        0.706         1.38       0.0635       0.0993        0.372         0.42
    190   500       0.0361       0.0353     0.000135      0.00069         1.03         2.07       0.0778        0.128        0.278         0.29
    190   600      0.00992      0.00921     0.000472     0.000237        0.723         1.06        0.121         0.24         0.14         0.17
    190   700       0.0365        0.036      0.00034     0.000198         1.14          2.1        0.093        0.204        0.145        0.156
    190   800      0.00399      0.00345       0.0001     0.000438        0.505        0.649       0.0771         0.11        0.167        0.231
    190   900      0.00656      0.00605     8.65e-05     0.000424        0.434         0.86       0.0685        0.103        0.185        0.227
    190  1000     0.000771     0.000608     8.29e-05     7.99e-05        0.205        0.272       0.0647        0.101       0.0752       0.0988
    190  1100      0.00562      0.00511     0.000328      0.00018        0.611         0.79          0.1          0.2        0.137        0.148
    190  1200       0.0299       0.0294     0.000206     0.000274         1.14         1.89       0.0931        0.159        0.168        0.183
    190  1300      0.00485      0.00444     0.000268     0.000142        0.479        0.736       0.0994        0.181        0.114        0.132
    190  1400      0.00472       0.0043     6.63e-05     0.000361        0.467        0.724       0.0621         0.09        0.198         0.21
    190  1500       0.0113       0.0111     7.32e-05     9.68e-05        0.611         1.16       0.0588       0.0946       0.0972        0.109
    190  1600      0.00825      0.00803     0.000175     4.09e-05        0.706         0.99       0.0975        0.146       0.0574       0.0706
    190  1700      0.00474      0.00446     6.39e-05     0.000211        0.481        0.738       0.0651       0.0883        0.156         0.16
    190  1800       0.0191        0.019     7.77e-05     2.07e-05        0.887         1.52       0.0665       0.0974       0.0408       0.0502
    190  1900      0.00473      0.00412     0.000102     0.000506        0.486        0.709       0.0657        0.111        0.223        0.249
    190  2000       0.0225       0.0224      4.9e-05     0.000113        0.719         1.65       0.0558       0.0773        0.101        0.117
    190  2039       0.0214       0.0209     0.000314     0.000121        0.962          1.6        0.123        0.196        0.122        0.122

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    190   100      0.00434      0.00383     0.000138     0.000373        0.438        0.683       0.0666         0.13        0.163        0.214
    190   182        0.204        0.204     0.000255     8.48e-05         3.07         4.99       0.0795        0.176        0.102        0.102


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             190 18831.493    0.001       0.0171     0.000161     0.000396       0.0177        0.718         1.45       0.0764         0.14         0.17         0.22
! Validation        190 18831.493    0.001       0.0205     0.000159     0.000343        0.021        0.763         1.55       0.0768        0.139        0.158        0.205
Wall time: 18831.493860684335
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    191   100       0.0612       0.0595     0.000438      0.00125         1.13          2.7        0.115        0.231        0.295        0.391
    191   200      0.00842      0.00781      7.5e-05      0.00053        0.603        0.977       0.0639       0.0957        0.246        0.254
    191   300       0.0266       0.0261     0.000135     0.000278        0.894         1.79       0.0852        0.128         0.16        0.184
    191   400       0.0382       0.0372     0.000502     0.000499        0.919         2.13       0.0967        0.248        0.203        0.247
    191   500       0.0609       0.0584      0.00158     0.000871         1.41         2.67        0.138         0.44        0.276        0.326
    191   600      0.00102     0.000951     4.11e-05      2.7e-05        0.239        0.341       0.0509       0.0709       0.0532       0.0574
    191   700      0.00707      0.00669     0.000172     0.000211        0.568        0.904       0.0724        0.145        0.159        0.161
    191   800      0.00779      0.00756     7.42e-05     0.000153        0.618        0.961       0.0623       0.0952        0.131        0.137
    191   900      0.00377      0.00342     8.45e-05     0.000265        0.381        0.646       0.0611        0.102        0.154         0.18
    191  1000      0.00544      0.00432     0.000604     0.000517        0.474        0.726        0.111        0.271        0.248        0.251
    191  1100      0.00239      0.00216     0.000109     0.000121        0.329        0.514       0.0724        0.115       0.0992        0.122
    191  1200      0.00255      0.00234     0.000126     9.07e-05        0.322        0.534       0.0707        0.124       0.0773        0.105
    191  1300       0.0274        0.027     0.000156     0.000305        0.989         1.81       0.0775        0.138        0.171        0.193
    191  1400        0.033       0.0324      0.00025     0.000354         1.22         1.99        0.107        0.175        0.177        0.208
    191  1500      0.00341      0.00275     8.68e-05     0.000576         0.45        0.579       0.0681        0.103        0.178        0.265
    191  1600       0.0141       0.0134     0.000118     0.000491        0.702         1.28       0.0733         0.12        0.214        0.245
    191  1700       0.0031      0.00261     0.000102     0.000393        0.393        0.565       0.0727        0.111        0.182        0.219
    191  1800       0.0101      0.00968     7.59e-05     0.000386         0.64         1.09       0.0607       0.0962        0.137        0.217
    191  1900       0.0278       0.0274     0.000221     0.000142         0.79         1.83       0.0813        0.164        0.122        0.132
    191  2000      0.00649      0.00549     0.000122      0.00088        0.543        0.819       0.0815        0.122        0.265        0.328
    191  2039       0.0046      0.00438     0.000157      5.9e-05        0.475        0.731       0.0869        0.139       0.0779       0.0849

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    191   100      0.00411      0.00357     5.75e-05     0.000481        0.448         0.66       0.0532       0.0838        0.201        0.242
    191   182        0.157        0.157      6.8e-05      1.8e-05         2.62         4.37       0.0527       0.0911       0.0469       0.0469


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             191 18930.865    0.001       0.0174     0.000162      0.00042        0.018        0.721         1.46        0.076        0.141        0.174        0.226
! Validation        191 18930.865    0.001         0.02     0.000152     0.000304       0.0204        0.749         1.54       0.0722        0.136        0.149        0.193
Wall time: 18930.865451157093
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    192   100       0.0213       0.0198     0.000647     0.000849        0.846         1.55        0.129        0.281        0.317        0.322
    192   200       0.0041      0.00332     0.000133     0.000651        0.391        0.636       0.0782        0.128        0.181        0.282
    192   300       0.0142       0.0138     0.000114     0.000279        0.609          1.3       0.0792        0.118        0.142        0.184
    192   400      0.00139      0.00131     7.43e-05     8.26e-06        0.251          0.4       0.0664       0.0952       0.0264       0.0317
    192   500      0.00537      0.00526     5.63e-05     5.24e-05        0.441        0.802       0.0567       0.0829       0.0607         0.08
    192   600       0.0332       0.0322      0.00043     0.000538        0.937         1.98       0.0904        0.229        0.236        0.256
    192   700        0.015       0.0141     0.000148     0.000737        0.842         1.31        0.076        0.135        0.248          0.3
    192   800       0.0141       0.0137     7.13e-05     0.000307        0.658         1.29       0.0597       0.0933        0.179        0.194
    192   900        0.147        0.146     0.000301     0.000365         2.37         4.22        0.122        0.192         0.18        0.211
    192  1000       0.0219       0.0201     0.000724      0.00104        0.955         1.57        0.117        0.297        0.335        0.357
    192  1100      0.00446      0.00326     0.000478     0.000725        0.406        0.631       0.0939        0.242        0.231        0.298
    192  1200       0.0107       0.0102     6.21e-05     0.000482        0.557         1.12       0.0631       0.0871        0.237        0.243
    192  1300       0.0121       0.0118     0.000162     0.000141        0.811          1.2       0.0869        0.141        0.111        0.131
    192  1400       0.0224       0.0222     6.65e-05     0.000125        0.963         1.65       0.0564       0.0901        0.117        0.123
    192  1500      0.00785      0.00714     8.08e-05     0.000635        0.542        0.933       0.0676       0.0993        0.242        0.278
    192  1600       0.0103      0.00974     0.000375     0.000178        0.645         1.09       0.0952        0.214        0.117        0.147
    192  1700      0.00707      0.00666     6.69e-05     0.000338        0.407        0.902       0.0591       0.0903        0.183        0.203
    192  1800      0.00527      0.00439     0.000459     0.000424        0.493        0.732        0.104        0.237        0.197        0.227
    192  1900      0.00648      0.00614     0.000176     0.000158        0.559        0.866       0.0817        0.147        0.124        0.139
    192  2000      0.00832      0.00798     0.000266      7.4e-05        0.681        0.987        0.085         0.18        0.088        0.095
    192  2039       0.0139       0.0137     7.85e-05     6.86e-05        0.869          1.3       0.0629       0.0979       0.0812       0.0915

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    192   100      0.00435       0.0038     6.49e-05     0.000483        0.438        0.681       0.0569        0.089        0.179        0.243
    192   182        0.179        0.179     7.94e-05     7.51e-05         2.97         4.67        0.062       0.0984       0.0957       0.0957


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             192 19030.304    0.001       0.0171     0.000164     0.000406       0.0176        0.716         1.44       0.0758        0.142        0.172        0.223
! Validation        192 19030.304    0.001       0.0202     0.000145     0.000444       0.0208         0.74         1.54       0.0726        0.133        0.186        0.233
Wall time: 19030.30443457514
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    193   100       0.0265       0.0255     0.000151     0.000859        0.875         1.76       0.0824        0.136        0.235        0.324
    193   200       0.0116       0.0109     6.65e-05     0.000597        0.634         1.15       0.0597       0.0901        0.202         0.27
    193   300      0.00397      0.00379     6.97e-05     0.000112        0.449         0.68       0.0632       0.0922       0.0821        0.117
    193   400      0.00591      0.00541     0.000184     0.000313        0.462        0.813       0.0824         0.15        0.159        0.195
    193   500      0.00231       0.0014     0.000101     0.000808        0.307        0.414       0.0718        0.111        0.279        0.314
    193   600      0.00546      0.00519     8.51e-05     0.000181        0.577        0.796       0.0677        0.102        0.125        0.149
    193   700       0.0164       0.0162     4.93e-05     0.000124        0.812         1.41       0.0551       0.0776        0.109        0.123
    193   800        0.064        0.063     0.000174     0.000824         1.58         2.77       0.0967        0.146         0.24        0.317
    193   900      0.00836      0.00817      5.4e-05     0.000134         0.52        0.999       0.0562       0.0812        0.117        0.128
    193  1000       0.0136       0.0133     9.88e-05     0.000187        0.746         1.27        0.069         0.11        0.128        0.151
    193  1100      0.00161      0.00111     0.000146     0.000357        0.286        0.367       0.0692        0.133        0.158        0.209
    193  1200      0.00432      0.00238     0.000115      0.00183         0.42        0.539       0.0696        0.119        0.385        0.472
    193  1300      0.00583      0.00501     8.68e-05     0.000737        0.473        0.782       0.0664        0.103        0.234          0.3
    193  1400       0.0107      0.00994      0.00025     0.000517        0.596          1.1        0.102        0.175        0.209        0.251
    193  1500       0.0131       0.0128     7.45e-05     0.000186         0.58         1.25       0.0627       0.0953        0.108        0.151
    193  1600      0.00508      0.00452     0.000367     0.000193        0.515        0.743        0.082        0.212        0.126        0.153
    193  1700        0.135        0.135     7.08e-05     5.03e-05         1.36         4.05       0.0688       0.0929        0.062       0.0784
    193  1800      0.00893      0.00856      0.00021     0.000168        0.591         1.02       0.0933         0.16         0.13        0.143
    193  1900       0.0223       0.0215     0.000633     0.000188        0.866         1.62        0.106        0.278        0.115        0.151
    193  2000       0.0259       0.0249     0.000119     0.000898        0.812         1.74       0.0769        0.121        0.285        0.331
    193  2039       0.0293        0.029     0.000192     8.81e-05         1.07         1.88       0.0956        0.153        0.104        0.104

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    193   100      0.00482       0.0043     6.45e-05      0.00046        0.457        0.724       0.0576       0.0887         0.17        0.237
    193   182        0.197        0.196      0.00028     0.000167         3.11         4.89       0.0791        0.185        0.143        0.143


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             193 19129.865    0.001        0.017      0.00016     0.000402       0.0175        0.708         1.44       0.0751         0.14        0.171        0.221
! Validation        193 19129.865    0.001       0.0199     0.000157     0.000433       0.0205        0.752         1.53       0.0753        0.138        0.176         0.23
Wall time: 19129.866395391524
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    194   100      0.00279      0.00251     8.16e-05     0.000203          0.4        0.553       0.0633       0.0998        0.128        0.158
    194   200       0.0183       0.0178     8.79e-05     0.000333        0.798         1.48       0.0736        0.104        0.146        0.202
    194   300      0.00205      0.00165     0.000172     0.000224        0.302        0.449       0.0807        0.145        0.122        0.165
    194   400      0.00297      0.00282     8.47e-05     6.76e-05         0.39        0.587       0.0613        0.102       0.0868       0.0908
    194   500      0.00104     0.000762     7.77e-05     0.000205        0.239        0.305       0.0616       0.0974         0.13        0.158
    194   600       0.0698        0.069      0.00027     0.000549         1.38          2.9       0.0878        0.181        0.235        0.259
    194   700       0.0181       0.0177     8.34e-05     0.000316         0.66         1.47       0.0642        0.101        0.177        0.196
    194   800       0.0284       0.0276     0.000616     0.000177         1.09         1.84        0.115        0.274        0.132        0.147
    194   900       0.0127       0.0122     0.000202     0.000252        0.838         1.22        0.103        0.157        0.143        0.175
    194  1000       0.0231       0.0229       0.0001     7.75e-05        0.725         1.67       0.0643        0.111       0.0806       0.0972
    194  1100      0.00459      0.00321     0.000244      0.00113        0.446        0.626        0.101        0.172        0.338        0.372
    194  1200      0.00283      0.00206     0.000132     0.000642         0.39        0.501       0.0829        0.127         0.23         0.28
    194  1300       0.0189       0.0184     0.000428     0.000137        0.913          1.5       0.0931        0.229        0.114        0.129
    194  1400      0.00861      0.00841     5.26e-05     0.000142         0.51         1.01       0.0559       0.0801        0.117        0.132
    194  1500      0.00397       0.0037     0.000102     0.000168        0.458        0.672       0.0702        0.112        0.122        0.143
    194  1600       0.0479       0.0472     0.000108     0.000548         1.28          2.4        0.077        0.115        0.214        0.259
    194  1700       0.0315       0.0311      0.00011     0.000286         1.06         1.95       0.0706        0.116        0.162        0.187
    194  1800       0.0102      0.00992     0.000212      3.9e-05        0.653          1.1       0.0765        0.161       0.0678        0.069
    194  1900       0.0076      0.00715     0.000102     0.000351        0.558        0.934       0.0635        0.111        0.141        0.207
    194  2000      0.00713      0.00703     6.56e-05     3.43e-05        0.531        0.927       0.0499       0.0895       0.0553       0.0648
    194  2039      0.00539      0.00444     0.000213     0.000733        0.465        0.736       0.0852        0.161        0.282        0.299

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    194   100      0.00516      0.00445     7.37e-05     0.000629        0.439        0.737       0.0577       0.0948        0.236        0.277
    194   182        0.149        0.149     3.82e-05     8.17e-06         2.57         4.27       0.0465       0.0683       0.0316       0.0316


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             194 19229.706    0.001       0.0166     0.000161     0.000393       0.0172        0.707         1.42       0.0762         0.14        0.169        0.219
! Validation        194 19229.706    0.001       0.0203      0.00015     0.000337       0.0208         0.76         1.55        0.069        0.136        0.155        0.203
Wall time: 19229.70688070357
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    195   100       0.0148        0.014     7.14e-05     0.000697         0.61         1.31       0.0625       0.0934        0.236        0.292
    195   200      0.00376      0.00349     8.11e-05     0.000193        0.369        0.652       0.0656       0.0995        0.119        0.154
    195   300      0.00962      0.00919     0.000101     0.000325        0.657         1.06       0.0703        0.111        0.175        0.199
    195   400      0.00491      0.00424     7.29e-05     0.000601        0.422         0.72       0.0667       0.0944        0.217        0.271
    195   500      0.00421      0.00379     0.000156      0.00027        0.497         0.68       0.0632        0.138        0.121        0.181
    195   600       0.0125       0.0102      0.00118      0.00104         0.77         1.12        0.144        0.379        0.243        0.355
    195   700       0.0208       0.0197     0.000472     0.000628        0.866         1.55        0.103         0.24        0.232        0.277
    195   800      0.00802      0.00737     0.000159     0.000498        0.641        0.948       0.0804        0.139        0.195        0.247
    195   900      0.00636      0.00603     3.66e-05     0.000297        0.564        0.858        0.045       0.0668        0.178         0.19
    195  1000       0.0087      0.00855     6.91e-05     8.45e-05        0.619         1.02       0.0532       0.0918       0.0819        0.102
    195  1100       0.0545       0.0539     0.000179     0.000446          1.4         2.57       0.0861        0.148        0.162        0.233
    195  1200      0.00605       0.0059     0.000126     2.77e-05        0.427        0.849       0.0727        0.124       0.0558       0.0581
    195  1300      0.00164      0.00142     9.63e-05     0.000131        0.335        0.416       0.0685        0.108       0.0976        0.127
    195  1400       0.0365       0.0353     0.000366     0.000821         1.21         2.08        0.105        0.211        0.293        0.317
    195  1500      0.00758      0.00736     0.000104     0.000114        0.577        0.948        0.075        0.112        0.111        0.118
    195  1600      0.00132     0.000834     9.09e-05     0.000395        0.254        0.319       0.0697        0.105        0.189        0.219
    195  1700      0.00286      0.00256     6.22e-05     0.000238         0.34        0.559       0.0563       0.0871        0.128         0.17
    195  1800      0.00496      0.00421     9.57e-05     0.000649        0.467        0.717        0.066        0.108        0.235        0.281
    195  1900        0.034       0.0336     0.000231     0.000108        0.916         2.03       0.0879        0.168       0.0973        0.115
    195  2000       0.0425       0.0415     0.000418     0.000581         1.25         2.25        0.121        0.226        0.256        0.266
    195  2039       0.0332       0.0328     5.01e-05      0.00034         1.03            2       0.0532       0.0782        0.204        0.204

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    195   100      0.00608       0.0052      0.00011     0.000771        0.577        0.796       0.0652        0.116        0.246        0.307
    195   182         0.19        0.189     0.000144     0.000648         2.92          4.8        0.068        0.132        0.281        0.281


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             195 19328.867    0.001       0.0166     0.000166     0.000417       0.0172        0.704         1.42       0.0753        0.142        0.173        0.226
! Validation        195 19328.867    0.001       0.0206     0.000164     0.000333       0.0211        0.756         1.56       0.0765        0.142        0.161        0.201
Wall time: 19328.868577100337
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    196   100       0.0413       0.0409     0.000165     0.000256         1.16         2.23       0.0943        0.142        0.119        0.177
    196   200        0.015       0.0145     0.000108     0.000464        0.595         1.33       0.0631        0.115        0.183        0.238
    196   300      0.00486      0.00414     7.96e-05     0.000635        0.396        0.711       0.0666       0.0986        0.172        0.278
    196   400       0.0197       0.0181     0.000414      0.00121        0.837         1.49       0.0961        0.225        0.336        0.384
    196   500        0.012       0.0112     0.000366     0.000385        0.724         1.17        0.111        0.211        0.183        0.217
    196   600       0.0283        0.027     0.000164      0.00116         1.05         1.82       0.0772        0.141        0.353        0.377
    196   700       0.0063      0.00612     6.06e-05     0.000121        0.513        0.864       0.0572        0.086        0.117        0.121
    196   800      0.00886      0.00843     0.000291     0.000146        0.738         1.01       0.0956        0.189        0.125        0.134
    196   900      0.00319      0.00276     8.33e-05     0.000343        0.366        0.581       0.0648        0.101         0.17        0.205
    196  1000       0.0102      0.00957     0.000145     0.000453        0.636         1.08       0.0817        0.133        0.211        0.235
    196  1100      0.00927      0.00911     5.29e-05     0.000101        0.544         1.05       0.0536       0.0804        0.101        0.111
    196  1200       0.0133       0.0127     0.000452     9.49e-05        0.701         1.25       0.0983        0.235       0.0827        0.108
    196  1300      0.00937      0.00919     7.25e-05     0.000102        0.656         1.06       0.0638       0.0941       0.0997        0.112
    196  1400      0.00134      0.00118     4.21e-05     0.000114        0.294         0.38        0.047       0.0717        0.104        0.118
    196  1500       0.0136        0.013     0.000154      0.00048        0.728         1.26        0.084        0.137        0.203        0.242
    196  1600      0.00548      0.00512     0.000107     0.000247        0.602        0.791       0.0777        0.114        0.132        0.174
    196  1700       0.0436       0.0434     5.76e-05     7.23e-05        0.993          2.3        0.061       0.0839       0.0913       0.0939
    196  1800        0.011       0.0108     9.68e-05     8.98e-05        0.708         1.15       0.0731        0.109       0.0945        0.105
    196  1900       0.0305       0.0302     8.26e-05     0.000205         1.01         1.92       0.0673          0.1        0.151        0.158
    196  2000       0.0166       0.0142      0.00132      0.00113        0.802         1.31        0.127        0.402        0.272        0.372
    196  2039      0.00198      0.00155     7.55e-05     0.000351         0.28        0.435       0.0608        0.096        0.154        0.207

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    196   100      0.00345      0.00292     7.67e-05     0.000451         0.41        0.597       0.0567       0.0968        0.201        0.235
    196   182        0.133        0.133     0.000371     4.98e-05         2.42         4.03       0.0774        0.213       0.0779       0.0779


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             196 19428.122    0.001       0.0167     0.000164      0.00045       0.0174        0.711         1.43       0.0764        0.141        0.179        0.234
! Validation        196 19428.122    0.001       0.0196     0.000161      0.00035       0.0201        0.748         1.53       0.0729         0.14        0.153        0.207
Wall time: 19428.123332202435
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    197   100       0.0155       0.0149     0.000474     8.56e-05        0.828         1.35        0.101        0.241       0.0819        0.102
    197   200        0.018       0.0169      0.00017     0.000947         1.06         1.44       0.0939        0.144        0.302         0.34
    197   300      0.00174      0.00138      6.2e-05     0.000297        0.305        0.411       0.0612        0.087        0.158        0.191
    197   400      0.00447      0.00424     0.000112     0.000119        0.463         0.72       0.0702        0.117        0.108         0.12
    197   500       0.0131       0.0129     5.75e-05     0.000174        0.706         1.25       0.0556       0.0838        0.135        0.146
    197   600      0.00362       0.0032     0.000255     0.000165        0.482        0.625        0.105        0.177         0.11        0.142
    197   700      0.00578      0.00549     8.74e-05     0.000199        0.528        0.819       0.0661        0.103        0.138        0.156
    197   800       0.0101      0.00918     0.000106     0.000775        0.635         1.06       0.0775        0.114        0.272        0.307
    197   900       0.0241       0.0239     7.14e-05     0.000149         0.77         1.71       0.0625       0.0934        0.106        0.135
    197  1000       0.0175       0.0172     9.84e-05     0.000175        0.725         1.45       0.0625         0.11        0.124        0.146
    197  1100       0.0133       0.0129     0.000183      0.00018        0.745         1.25       0.0862         0.15        0.139        0.148
    197  1200       0.0025      0.00234     4.89e-05     0.000115         0.37        0.534       0.0508       0.0773       0.0876        0.118
    197  1300       0.0188       0.0182      0.00015     0.000413        0.946         1.49       0.0877        0.135        0.173        0.225
    197  1400      0.00939      0.00922     0.000124     4.92e-05        0.619         1.06       0.0754        0.123       0.0647       0.0775
    197  1500       0.0172        0.017     6.68e-05      0.00012        0.664         1.44         0.06       0.0903        0.101        0.121
    197  1600       0.0243        0.024     9.83e-05     0.000196         1.05         1.71       0.0665         0.11        0.134        0.155
    197  1700        0.009      0.00823     0.000297     0.000474        0.715            1        0.109         0.19        0.231        0.241
    197  1800      0.00296      0.00242     8.76e-05     0.000448        0.397        0.544       0.0722        0.103        0.179        0.234
    197  1900      0.00885      0.00859     7.21e-05     0.000189        0.574         1.02       0.0581       0.0938         0.13        0.152
    197  2000       0.0232       0.0231     8.59e-05      2.4e-05        0.854         1.68       0.0673        0.102       0.0496       0.0541
    197  2039      0.00147      0.00138     3.61e-05     5.99e-05        0.312         0.41       0.0487       0.0664       0.0611       0.0855

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    197   100      0.00389      0.00353     8.43e-05     0.000273        0.416        0.656       0.0603        0.101        0.145        0.182
    197   182        0.155        0.154     0.000104     0.000417         2.66         4.34       0.0611        0.112        0.226        0.226


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             197 19527.820    0.001       0.0165     0.000168     0.000393       0.0171        0.704         1.42       0.0765        0.143         0.17        0.219
! Validation        197 19527.820    0.001       0.0196      0.00016     0.000263         0.02         0.74         1.52       0.0737         0.14         0.14        0.179
Wall time: 19527.820602454245
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    198   100      0.00363      0.00285     0.000242     0.000538        0.385         0.59       0.0938        0.172        0.241        0.256
    198   200      0.00962      0.00801     0.000109      0.00151         0.57        0.989       0.0739        0.116        0.316        0.429
    198   300      0.00727       0.0069     7.69e-05     0.000295        0.594        0.918       0.0659       0.0969        0.158         0.19
    198   400       0.0121       0.0119     8.27e-05     0.000146        0.701         1.21       0.0627          0.1        0.097        0.134
    198   500        0.019       0.0187     7.71e-05     0.000253        0.759         1.51       0.0651        0.097        0.163        0.176
    198   600      0.00703      0.00654     9.98e-05      0.00039        0.549        0.893       0.0742         0.11        0.172        0.218
    198   700       0.0139       0.0137     9.81e-05     3.74e-05        0.671          1.3       0.0728        0.109       0.0566       0.0676
    198   800      0.00266      0.00237     7.06e-05     0.000219        0.356        0.538       0.0639       0.0929         0.14        0.164
    198   900      0.00513      0.00475     0.000146     0.000232          0.5        0.762       0.0649        0.133        0.132        0.168
    198  1000      0.00505      0.00473     9.41e-05     0.000226         0.56         0.76       0.0728        0.107        0.142        0.166
    198  1100      0.00176      0.00114     7.24e-05     0.000548        0.273        0.373       0.0622        0.094        0.223        0.259
    198  1200      0.00644      0.00563     0.000145     0.000667        0.514        0.829       0.0796        0.133        0.243        0.285
    198  1300        0.017        0.016     0.000147     0.000808         0.83          1.4       0.0623        0.134        0.187        0.314
    198  1400       0.0319       0.0315     0.000101     0.000298        0.966         1.96       0.0781        0.111        0.171        0.191
    198  1500         0.12        0.119     9.33e-05     0.000922          1.5         3.81       0.0657        0.107         0.29        0.335
    198  1600       0.0381       0.0375      0.00019      0.00041         1.36         2.14       0.0915        0.152        0.158        0.224
    198  1700       0.0293       0.0288     0.000191     0.000385         1.04         1.87        0.088        0.153        0.194        0.217
    198  1800      0.00438      0.00393     0.000178      0.00027        0.442        0.693       0.0808        0.148        0.157        0.182
    198  1900       0.0181       0.0179     5.16e-05       0.0002        0.889         1.48        0.054       0.0794        0.134        0.156
    198  2000        0.002      0.00148     7.73e-05     0.000444        0.321        0.425       0.0572       0.0971        0.189        0.233
    198  2039       0.0126       0.0116     8.66e-05     0.000848         0.77         1.19       0.0717        0.103         0.32        0.322

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    198   100      0.00767       0.0071        7e-05     0.000495        0.531        0.931       0.0587       0.0925        0.201        0.246
    198   182         0.27        0.269     0.000179     0.000904         3.58         5.73       0.0739        0.148        0.332        0.332


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             198 19626.979    0.001       0.0163     0.000165     0.000384       0.0169        0.699         1.41       0.0761        0.142        0.167        0.217
! Validation        198 19626.979    0.001       0.0215     0.000166     0.000441       0.0221        0.776         1.58       0.0739        0.142        0.185        0.232
Wall time: 19626.979734815657
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    199   100       0.0227       0.0219      0.00052     0.000342        0.891         1.63       0.0991        0.252        0.175        0.204
    199   200       0.0063      0.00619     7.15e-05     4.04e-05        0.437        0.869       0.0591       0.0934       0.0618       0.0702
    199   300      0.00958      0.00931     7.36e-05     0.000199         0.49         1.07       0.0587       0.0948        0.127        0.156
    199   400      0.00269      0.00212     6.46e-05     0.000496        0.388        0.509       0.0618       0.0888         0.23        0.246
    199   500       0.0696       0.0691     0.000112     0.000446         1.38          2.9         0.07        0.117         0.18        0.233
    199   600      0.00644      0.00633      8.7e-05     2.38e-05        0.576        0.879       0.0636        0.103       0.0484        0.054
    199   700       0.0205       0.0202     5.22e-05     0.000233        0.805         1.57       0.0546       0.0798        0.142        0.169
    199   800       0.0338       0.0336     7.42e-05     8.46e-05        0.895         2.03       0.0573       0.0952       0.0879        0.102
    199   900       0.0294       0.0289     0.000127     0.000397        0.916         1.88        0.066        0.125        0.149         0.22
    199  1000       0.0172       0.0162     0.000329      0.00073        0.968          1.4        0.107          0.2        0.229        0.299
    199  1100      0.00483      0.00452      0.00013     0.000181        0.507        0.743       0.0801        0.126        0.133        0.148
    199  1200       0.0223       0.0216     0.000618     9.89e-05        0.678         1.62       0.0986        0.275       0.0921         0.11
    199  1300       0.0133       0.0131      0.00011      3.9e-05        0.763         1.26       0.0851        0.116       0.0602        0.069
    199  1400       0.0376       0.0367     0.000107     0.000759         1.22         2.12       0.0737        0.114         0.29        0.304
    199  1500       0.0101      0.00967     0.000299     0.000139        0.675         1.09       0.0746        0.191        0.117         0.13
    199  1600      0.00734      0.00714     5.32e-05     0.000145        0.452        0.934       0.0552       0.0806        0.117        0.133
    199  1700       0.0229       0.0226     0.000157     0.000123         1.03         1.66       0.0793        0.139        0.107        0.123
    199  1800      0.00252      0.00234     7.96e-05     9.17e-05        0.347        0.535       0.0671       0.0986        0.089        0.106
    199  1900      0.00375      0.00359     5.42e-05     0.000109        0.378        0.662       0.0557       0.0814        0.113        0.115
    199  2000      0.00466      0.00445     6.99e-05     0.000144        0.488        0.737        0.063       0.0924        0.122        0.133
    199  2039      0.00382      0.00348     0.000101     0.000239        0.466        0.652       0.0795        0.111        0.149        0.171

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    199   100      0.00897      0.00846     0.000168     0.000343        0.737         1.02       0.0726        0.143        0.184        0.205
    199   182        0.148        0.148      7.8e-05     9.02e-07         2.61         4.25       0.0612       0.0976       0.0105       0.0105


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             199 19726.031    0.001       0.0163     0.000167     0.000383       0.0169        0.702         1.41       0.0764        0.143        0.167        0.216
! Validation        199 19726.031    0.001       0.0216     0.000193     0.000306       0.0221        0.809          1.6       0.0789        0.154        0.151        0.194
Wall time: 19726.03224262595
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth

training
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    200   100       0.0101      0.00939     0.000219     0.000495        0.704         1.07       0.0898        0.164        0.224        0.246
    200   200       0.0119       0.0113     0.000182     0.000454        0.732         1.18       0.0875        0.149        0.196        0.235
    200   300       0.0121       0.0116     0.000233     0.000322         0.65         1.19       0.0796        0.169        0.153        0.198
    200   400       0.0217       0.0206     8.53e-05     0.000982        0.926         1.59       0.0706        0.102        0.272        0.346
    200   500       0.0146       0.0144     9.11e-05     0.000117        0.651         1.33       0.0701        0.105       0.0895        0.119
    200   600      0.00185      0.00159     0.000169     9.26e-05         0.34         0.44        0.072        0.143       0.0839        0.106
    200   700      0.00722      0.00682     0.000102     0.000295        0.611        0.913       0.0735        0.112        0.158         0.19
    200   800      0.00421      0.00345     0.000113     0.000653        0.407        0.649       0.0726        0.118        0.259        0.282
    200   900       0.0114       0.0112     7.42e-05     0.000186         0.78         1.17       0.0639       0.0952        0.149        0.151
    200  1000       0.0177       0.0175     9.91e-05     7.33e-05        0.784         1.46       0.0666         0.11       0.0752       0.0946
    200  1100       0.0379       0.0371     6.78e-05     0.000664         0.94         2.13       0.0613        0.091        0.262        0.285
    200  1200       0.0255       0.0248     0.000309     0.000375        0.989         1.74        0.087        0.194        0.186        0.214
    200  1300       0.0163       0.0158      0.00011     0.000335        0.655         1.39       0.0733        0.116        0.168        0.202
    200  1400      0.00728      0.00713     9.09e-05      6.3e-05        0.584        0.933       0.0691        0.105       0.0718       0.0877
    200  1500      0.00793      0.00763     9.89e-05     0.000201        0.594        0.965       0.0716         0.11        0.151        0.156
    200  1600       0.0112      0.00991     0.000846      0.00041        0.622          1.1         0.11        0.321        0.199        0.224
    200  1700       0.0273       0.0265     0.000134     0.000586        0.879          1.8       0.0831        0.128        0.231        0.267
    200  1800       0.0165       0.0154     0.000443     0.000652        0.786         1.37        0.114        0.233        0.224        0.282
    200  1900       0.0709       0.0701     0.000266     0.000543          1.5         2.93       0.0882         0.18        0.237        0.257
    200  2000      0.00918      0.00859     7.07e-05     0.000525        0.597         1.02       0.0594       0.0929        0.247        0.253
    200  2039      0.00568      0.00497     0.000237     0.000465        0.526        0.779        0.099         0.17        0.223        0.238

validation
# Epoch batch         loss  loss_virial       loss_f       loss_e   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
    200   100      0.00442      0.00389     8.89e-05     0.000436        0.411        0.689       0.0655        0.104        0.201        0.231
    200   182        0.185        0.185     0.000186     5.85e-06         2.82         4.75       0.0728        0.151       0.0267       0.0267


  Train      #    Epoch      wal       LR  loss_virial       loss_f       loss_e         loss   virial_mae  virial_rmse        f_mae       f_rmse        e_mae       e_rmse
! Train             200 19825.100    0.001       0.0162     0.000166     0.000416       0.0168        0.697         1.41       0.0759        0.142        0.171        0.225
! Validation        200 19825.100    0.001        0.021     0.000169     0.000405       0.0215        0.773         1.57       0.0799        0.144        0.176        0.223
Wall time: 19825.10126812011
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth
! Stop training: max epochs
Wall time: 19825.3655430004
Cumulative wall time: 19825.3655430004
Saved trainer to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/trainer.pth
Saved last model to to results/vcrtiwzr/vcrtiwzr_vac_small_model_big_data/last_model.pth
