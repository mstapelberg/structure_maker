{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a basic Cluster Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'phonopy'\n",
      "No module named 'phonopy'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from monty.serialization import loadfn, dumpfn\n",
    "from pymatgen.core.structure import Structure\n",
    "from smol.cofe import ClusterSubspace, StructureWrangler, ClusterExpansion, RegressionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the prim structure\n",
    "prim_path = '/Users/myless/Dropbox (MIT)/Research/2024/Spring_2024/Computation/structure_maker/v4cr4ti_prim_cell.json'\n",
    "lno_prim = loadfn(prim_path)\n",
    "    \n",
    "# load the fitting data\n",
    "entry_path = '/Users/myless/Dropbox (MIT)/Research/2024/Spring_2024/Computation/structure_maker/vcrti_fixed_entries.json'\n",
    "lno_entries = loadfn(entry_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) The prim structure\n",
    "The prim structure defines the **configurational space** for the Cluster Expansion. \n",
    "The **configurational space** is defined by the site **compositional spaces** and the crystal symetries of the prim structure.\n",
    "The occupancy of the sites determine site **compositional spaces**. Sites are **active** if they have compositional degrees of freedom.\n",
    "\n",
    "\n",
    "Active sites have fractional compositions. Vacancies are allowed in sites where the composition does not sum to one.\n",
    "\n",
    "0. Is active. The allowed species are: Li+ and vacancies.\n",
    "1. Is active. The allowed species are: Ni3+ and Ni4+.\n",
    "2. Is not active. Only O2- is allowed.\n",
    "3. Is not active. Only O2- is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Formula (Ti0.09375 V1.8125 Cr0.09375)\n",
      "Reduced Formula: Ti0.09375V1.8125Cr0.09375\n",
      "abc   :   3.010000   3.010000   3.010000\n",
      "angles:  90.000000  90.000000  90.000000\n",
      "pbc   :       True       True       True\n",
      "Sites (2)\n",
      "  #  SP                             a    b    c\n",
      "---  ---------------------------  ---  ---  ---\n",
      "  0  Ti:0.047, V:0.906, Cr:0.047  0    0    0\n",
      "  1  Ti:0.047, V:0.906, Cr:0.047  0.5  0.5  0.5\n"
     ]
    }
   ],
   "source": [
    "print(lno_prim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) The cluster subspace\n",
    "The `ClusterSubspace` represents all the orbits (groups of equivalent clusters) that will be considered when fitting the cluster expansion. Its main purpose is to compute the **correlations functions** for each included orbit given a structure in the compositional space defined by the prim.\n",
    "\n",
    "In order to do be able to compute the correlation functions, the given structure must match the prim structure in a \"crystallographic\" sense but allowing for compositional degrees of freedom in the \"active\" sites.\n",
    "\n",
    "A cluster subspace most easily created by providing:\n",
    "1. The prim structure representing the configurational space.\n",
    "2. A set of diameter cutoffs for each size of orbit we want to consider.\n",
    "3. A type of site basis function to use.\n",
    "\n",
    "There are more options allowed by the code to fine grain and tune. See other notebooks for advanced use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basis/Orthogonal/Orthonormal : sinusoid/True/False\n",
      "       Unit Cell Composition : V1.8125 Cr0.09375 Ti0.09375\n",
      "            Number of Orbits : 7\n",
      "No. of Correlation Functions : 21\n",
      "             Cluster Cutoffs : 2: 4.99, 3: 3.01\n",
      "              External Terms : []\n",
      "Orbit Summary\n",
      " ------------------------------------------------------------------------\n",
      " |  ID     Degree    Cluster Diameter    Multiplicity    No. Functions  |\n",
      " |   0       0             NA                 0                1        |\n",
      " |   1       1            0.0000              2                2        |\n",
      " |   2       2            2.6067              8                3        |\n",
      " |   3       2            3.0100              6                3        |\n",
      " |   4       2            4.2568              12               3        |\n",
      " |   5       2            4.9915              24               3        |\n",
      " |   6       3            3.0100              24               6        |\n",
      " ------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "subspace = ClusterSubspace.from_cutoffs(\n",
    "    lno_prim,\n",
    "    cutoffs={2: 5, 3: 4.1}, # will include orbits of 2 and 3 sites.\n",
    "    basis='sinusoid', # sets the site basis type, default is indicator\n",
    "    supercell_size='num_sites'\n",
    ")\n",
    "\n",
    "# supercell_size specifies the method to determine the supercell size\n",
    "# when trying to match a structure.\n",
    "# (See pymatgen.structure_matcher.StructureMatcher for more info)\n",
    "\n",
    "print(subspace) # single site and empty orbits are always included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1) Computing a correlation vector.\n",
    "A correlation vector for a specific structure (represents the feature vector) used to train and predict target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation vector for a structure with composition Cr3 V58 Ti3 is: \n",
      "[ 1.          0.4296875  -0.74424058  0.1796875  -0.32137661  0.55078125\n",
      "  0.1796875  -0.3179937   0.5625      0.18554688 -0.3179937   0.54492188\n",
      "  0.18554688 -0.31968516  0.5546875   0.07226562 -0.13362501 -0.13531647\n",
      "  0.23730469  0.24023437 -0.41271523]\n"
     ]
    }
   ],
   "source": [
    "structure = lno_entries[1].structure\n",
    "corr = subspace.corr_from_structure(structure)\n",
    "\n",
    "print(f'The correlation vector for a structure with'\n",
    "      f' composition {structure.composition} is: '\n",
    "      f'\\n{corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) The structure wrangler\n",
    "The `StructureWrangler` is a class that will is used to create and organize the data that will be used to train (and possibly test) the cluster expansion. It makes sure that all the supplied structures appropriately match the prim structure, and obtains the necessary information to correctly normalize target properties (such as energy) necessary for training.\n",
    "\n",
    "Training data is added to a `StructureWrangler` using `ComputedStructureEntry` instances from `pymatgen`.\n",
    "\n",
    "Matching relaxed structures can be a tricky problem, especially for ionic systems with vacancies. See the notebook on structure matching for tips on how to tweak parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total structures that match 30/30\n"
     ]
    }
   ],
   "source": [
    "wrangler = StructureWrangler(subspace)\n",
    "\n",
    "# the energy is taken directly from the ComputedStructureEntry\n",
    "# any additional properties can also be added, see notebook on\n",
    "# training data preparation for an example.\n",
    "for entry in lno_entries:\n",
    "    wrangler.add_entry(entry, verbose=True)\n",
    "# The verbose flag will print structures that fail to match.\n",
    "\n",
    "print(f'\\nTotal structures that match {wrangler.num_structures}/{len(lno_entries)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Training\n",
    "\n",
    "Training a cluster expansion is one of the most critical steps. This is how you get **effective cluster interactions (ECI's)**. To do so you need an estimator class that implements some form of regression model. In this case we will use simple least squares regression using the `LinearRegression` estimator from `scikit-learn`.\n",
    "\n",
    "In `smol` the coefficients from the fit are not exactly the ECI's but the ECI times the multiplicity of their orbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Set fit_intercept to False because we already do this using\n",
    "# the empty cluster.\n",
    "estimator = LinearRegression(fit_intercept=False)\n",
    "estimator.fit(wrangler.feature_matrix, wrangler.get_property_vector('energy'))\n",
    "coefs = estimator.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) Check the quality of the fit\n",
    "There are many ways to evaluate the quality of a fit. The simplest involve stadard training set prediction error metrics. But when evaluating a CE more seriously we need to consider further metrics and how the CE will be used.\n",
    "Here we will just look at in sample mean squared error and max error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.125699734784017 meV/prim\n",
      "MAX 0.33066046893992507 meV/prim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/smol/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, max_error\n",
    "\n",
    "train_predictions = np.dot(wrangler.feature_matrix, coefs)\n",
    "\n",
    "rmse = mean_squared_error(\n",
    "    wrangler.get_property_vector('energy'), train_predictions, squared=False\n",
    ")\n",
    "maxer = max_error(wrangler.get_property_vector('energy'), train_predictions)\n",
    "\n",
    "print(f'RMSE {1E3 * rmse} meV/prim')\n",
    "print(f'MAX {1E3 * maxer} meV/prim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) The cluster expansion\n",
    "Now we can use the above work to create the `ClusterExpansion`. The cluster expansion can be used to predict the fitted property for new structures, either for testing quality or for simulations such as in Monte Carlo.\n",
    "Note that when using the `predict` function, the cluster expansion will have to match the given structure if it has not seen it before.\n",
    "We will also store the details of the regression model used to fit the cluster expansion by using a `RegressionData` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted energy for a structure with composition V58 Ti3 Cr3 is -17.819349896464626 eV/prim.\n",
      "\n",
      "The fitted coefficients are:\n",
      "[-1.01826989e+01 -4.37537843e+00  7.57837775e+00 -9.22415845e-01\n",
      "  3.86165493e-02  1.53056130e-01 -5.00751375e-01 -6.27154603e-03\n",
      "  4.84660551e-02 -1.28216469e-01 -3.55059591e-02  1.51277609e-03\n",
      " -3.39008406e-01 -3.76788231e-01 -7.96106246e-02  8.35904929e-01\n",
      " -7.22871861e-02  9.65403884e-02  6.40630363e-02 -5.39126514e-02\n",
      "  5.59509575e-02]\n",
      "\n",
      "The effective cluster interactions are:\n",
      "[-1.01826989e+01 -2.18768922e+00  3.78918887e+00 -1.15301981e-01\n",
      "  2.41353433e-03  1.91320162e-02 -8.34585626e-02 -5.22628836e-04\n",
      "  8.07767585e-03 -1.06847058e-02 -1.47941496e-03  1.26064674e-04\n",
      " -1.41253503e-02 -7.84975481e-03 -3.31710936e-03  3.48293720e-02\n",
      " -1.50598304e-03  4.02251618e-03  1.33464659e-03 -2.24636047e-03\n",
      "  2.33128990e-03]\n",
      "\n",
      "Basis/Orthogonal/Orthonormal : sinusoid/True/False\n",
      "       Unit Cell Composition : V1.8125 Cr0.09375 Ti0.09375\n",
      "            Number of Orbits : 7\n",
      "No. of Correlation Functions : 21\n",
      "             Cluster Cutoffs : 2: 4.99, 3: 3.01\n",
      "              External Terms : []\n",
      "Regression Data : estimator=LinearRegression\n",
      "                  module=sklearn.linear_model._base\n",
      "                  parameters={'copy_X': True, 'fit_intercept': False, 'n_jobs': None, 'positive': False}\n",
      "Target Property    : mean=-17.8189  std=0.0012\n",
      "ECI-based Property : mean=-10.1827  std=6.2031\n",
      "Fit Summary\n",
      " ----------------------------------------------------------------------------------------------------\n",
      " |  ID    Orbit ID    Degree    Cluster Diameter    ECI    Feature AVG    Feature STD    ECI * STD  |\n",
      " |  0        0          0              NA         -10.183     1.000          0.000        -0.000    |\n",
      " |  1        1          1            0.0000       -2.188      0.430          0.000        -0.000    |\n",
      " |  2        1          1            0.0000        3.789     -0.744          0.000         0.000    |\n",
      " |  3        2          2            2.6067       -0.115      0.183          0.005        -0.001    |\n",
      " |  4        2          2            2.6067        0.002     -0.319          0.006         0.000    |\n",
      " |  5        2          2            2.6067        0.019      0.552          0.007         0.000    |\n",
      " |  6        3          2            3.0100       -0.083      0.183          0.006        -0.001    |\n",
      " |  7        3          2            3.0100       -0.001     -0.318          0.006        -0.000    |\n",
      " |  8        3          2            3.0100        0.008      0.549          0.010         0.000    |\n",
      " |  9        4          2            4.2568       -0.011      0.183          0.005        -0.000    |\n",
      " |  10       4          2            4.2568       -0.001     -0.320          0.005        -0.000    |\n",
      " |  11       4          2            4.2568        0.000      0.552          0.009         0.000    |\n",
      " |  12       5          2            4.9915       -0.014      0.184          0.002        -0.000    |\n",
      " |  13       5          2            4.9915       -0.008     -0.319          0.003        -0.000    |\n",
      " |  14       5          2            4.9915       -0.003      0.552          0.004        -0.000    |\n",
      " |  15       6          3            3.0100        0.035      0.077          0.005         0.000    |\n",
      " |  16       6          3            3.0100       -0.002     -0.135          0.006        -0.000    |\n",
      " |  17       6          3            3.0100        0.004     -0.135          0.007         0.000    |\n",
      " |  18       6          3            3.0100        0.001      0.235          0.009         0.000    |\n",
      " |  19       6          3            3.0100       -0.002      0.235          0.010        -0.000    |\n",
      " |  20       6          3            3.0100        0.002     -0.405          0.013         0.000    |\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "reg_data = RegressionData.from_sklearn(\n",
    "    estimator, wrangler.feature_matrix,\n",
    "    wrangler.get_property_vector('energy')\n",
    ")\n",
    "\n",
    "\n",
    "expansion = ClusterExpansion(\n",
    "    subspace, coefficients=coefs, regression_data=reg_data\n",
    ")\n",
    "\n",
    "structure = random.choice(wrangler.structures)\n",
    "prediction = expansion.predict(structure, normalized=True)\n",
    "\n",
    "print(\n",
    "    f'The predicted energy for a structure with composition '\n",
    "    f'{structure.composition} is {prediction} eV/prim.\\n'\n",
    ")\n",
    "print(f'The fitted coefficients are:\\n{expansion.coefs}\\n')\n",
    "print(f'The effective cluster interactions are:\\n{expansion.eci}\\n')\n",
    "print(expansion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Saving your work\n",
    "All core classes in `smol` are `MSONables` and so can be saved using their `as_dict` methods or better yet with `monty.serialization.dumpfn`.\n",
    "\n",
    "Currently there is also a convenience function in `smol` that will nicely save all of your work for you in a standardized way. Work saved with the `save_work` function is saved as a dictionary with standardized names for the classes. Since a work flow should only contain 1 of each core classes the function will complain if you give it two of the same class (i.e. two wranglers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smol.io import save_work\n",
    "\n",
    "file_path = 'v4cr4ti_fin_work.mson'\n",
    "# we can save the subspace as well, but since both the wrangler\n",
    "# and the expansion have it, there is no need to do so.\n",
    "save_work(file_path, wrangler, expansion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1) Loading previously saved work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructureWrangler: <class 'smol.cofe.wrangling.wrangler.StructureWrangler'>\n",
      "\n",
      "ClusterExpansion: <class 'smol.cofe.expansion.ClusterExpansion'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from smol.io import load_work\n",
    "\n",
    "work = load_work(file_path)\n",
    "for name, obj in work.items():\n",
    "    print(f'{name}: {type(obj)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
